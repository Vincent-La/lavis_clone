WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0, world 8): env://
| distributed init (rank 2, world 8): env://
| distributed init (rank 4, world 8): env://
| distributed init (rank 7, world 8): env://
| distributed init (rank 5, world 8): env://
| distributed init (rank 6, world 8): env://
| distributed init (rank 1, world 8): env://
| distributed init (rank 3, world 8): env://
2024-07-06 20:22:09,519 [INFO] 
=====  Running Parameters    =====
2024-07-06 20:22:09,520 [INFO] {
    "batch_size_eval": 64,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_backend": "nccl",
    "dist_url": "env://",
    "distributed": true,
    "evaluate": true,
    "gpu": 0,
    "inference_method": "generate",
    "max_len": 10,
    "min_len": 1,
    "num_beams": 5,
    "num_workers": 4,
    "output_dir": "output/BLIP2/VQA",
    "prompt": "Question: {} Short answer:",
    "rank": 0,
    "seed": 42,
    "task": "vqa",
    "test_splits": [
        "val"
    ],
    "world_size": 8
}
2024-07-06 20:22:09,520 [INFO] 
======  Dataset Attributes  ======
2024-07-06 20:22:09,520 [INFO] 
======== coco_vqa =======
2024-07-06 20:22:09,520 [INFO] {
    "build_info": {
        "annotations": {
            "val": {
                "storage": [
                    "coco/annotations/vqa_val_eval.json",
                    "coco/annotations/answer_list.json",
                    "coco/annotations/v2_OpenEnded_mscoco_val2014_questions.json",
                    "coco/annotations/v2_mscoco_val2014_annotations.json"
                ],
                "url": [
                    "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/vqa_val_eval.json",
                    "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/answer_list.json",
                    "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/v2_OpenEnded_mscoco_val2014_questions.json",
                    "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/vqav2/v2_mscoco_val2014_annotations.json"
                ]
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "text_processor": {
        "eval": {
            "name": "blip_question"
        }
    },
    "type": "eval",
    "vis_processor": {
        "eval": {
            "image_size": 224,
            "name": "blip_image_eval"
        }
    }
}
2024-07-06 20:22:09,520 [INFO] 
======  Model Attributes  ======
2024-07-06 20:22:09,520 [INFO] {
    "arch": "blip2_t5",
    "drop_path_rate": 0,
    "finetuned": "",
    "freeze_vit": true,
    "image_size": 224,
    "load_finetuned": false,
    "model_type": "pretrain_flant5xl",
    "num_query_token": 32,
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth",
    "prompt": "",
    "t5_model": "google/flan-t5-xl",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}
CACHE_ROOT:/fs/nexus-scratch/vla/.cache
STORAGE_PATH:/fs/nexus-scratch/vla/.cache/coco/annotations/vqa_val_eval.json
Using downloaded and verified file: /fs/nexus-scratch/vla/.cache/coco/annotations/vqa_val_eval.json
STORAGE_PATH:/fs/nexus-scratch/vla/.cache/coco/annotations/answer_list.json
Using downloaded and verified file: /fs/nexus-scratch/vla/.cache/coco/annotations/answer_list.json
STORAGE_PATH:/fs/nexus-scratch/vla/.cache/coco/annotations/v2_OpenEnded_mscoco_val2014_questions.json
Using downloaded and verified file: /fs/nexus-scratch/vla/.cache/coco/annotations/v2_OpenEnded_mscoco_val2014_questions.json
STORAGE_PATH:/fs/nexus-scratch/vla/.cache/coco/annotations/v2_mscoco_val2014_annotations.json
Using downloaded and verified file: /fs/nexus-scratch/vla/.cache/coco/annotations/v2_mscoco_val2014_annotations.json
2024-07-06 20:22:09,565 [INFO] Building datasets...
2024-07-06 20:22:19,166 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,167 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,169 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,170 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,171 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,172 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,185 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

2024-07-06 20:22:19,188 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

MODEL_NAME: eva_clip_g
2024-07-06 20:24:35,071 [INFO] freeze vision encoder
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.61s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.70s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.72s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.71s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.21s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.25s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 12.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 12.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.74s/it]
2024-07-06 20:27:12,429 [INFO] load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained_flant5xl.pth
Blip2T5(
  (visual_encoder): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (blocks): ModuleList(
      (0-38): 39 x Block(
        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1408, out_features=4224, bias=False)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1408, out_features=1408, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1408, out_features=6144, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=6144, out_features=1408, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
  )
  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)
  (Qformer): BertLMHeadModel(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): None
        (position_embeddings): None
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=1408, out_features=768, bias=True)
                (value): Linear(in_features=1408, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=1408, out_features=768, bias=True)
                (value): Linear(in_features=1408, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=1408, out_features=768, bias=True)
                (value): Linear(in_features=1408, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=1408, out_features=768, bias=True)
                (value): Linear(in_features=1408, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=1408, out_features=768, bias=True)
                (value): Linear(in_features=1408, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (crossattention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=1408, out_features=768, bias=True)
                (value): Linear(in_features=1408, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): None
            (output): None
            (intermediate_query): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output_query): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (cls): None
  )
  (t5_model): T5ForConditionalGeneration(
    (shared): Embedding(32128, 2048)
    (encoder): T5Stack(
      (embed_tokens): Embedding(32128, 2048)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=2048, out_features=2048, bias=False)
                (k): Linear(in_features=2048, out_features=2048, bias=False)
                (v): Linear(in_features=2048, out_features=2048, bias=False)
                (o): Linear(in_features=2048, out_features=2048, bias=False)
                (relative_attention_bias): Embedding(32, 32)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)
                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)
                (wo): Linear(in_features=5120, out_features=2048, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): GELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-23): 23 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=2048, out_features=2048, bias=False)
                (k): Linear(in_features=2048, out_features=2048, bias=False)
                (v): Linear(in_features=2048, out_features=2048, bias=False)
                (o): Linear(in_features=2048, out_features=2048, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)
                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)
                (wo): Linear(in_features=5120, out_features=2048, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): GELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (decoder): T5Stack(
      (embed_tokens): Embedding(32128, 2048)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=2048, out_features=2048, bias=False)
                (k): Linear(in_features=2048, out_features=2048, bias=False)
                (v): Linear(in_features=2048, out_features=2048, bias=False)
                (o): Linear(in_features=2048, out_features=2048, bias=False)
                (relative_attention_bias): Embedding(32, 32)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=2048, out_features=2048, bias=False)
                (k): Linear(in_features=2048, out_features=2048, bias=False)
                (v): Linear(in_features=2048, out_features=2048, bias=False)
                (o): Linear(in_features=2048, out_features=2048, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)
                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)
                (wo): Linear(in_features=5120, out_features=2048, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): GELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-23): 23 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=2048, out_features=2048, bias=False)
                (k): Linear(in_features=2048, out_features=2048, bias=False)
                (v): Linear(in_features=2048, out_features=2048, bias=False)
                (o): Linear(in_features=2048, out_features=2048, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=2048, out_features=2048, bias=False)
                (k): Linear(in_features=2048, out_features=2048, bias=False)
                (v): Linear(in_features=2048, out_features=2048, bias=False)
                (o): Linear(in_features=2048, out_features=2048, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=2048, out_features=5120, bias=False)
                (wi_1): Linear(in_features=2048, out_features=5120, bias=False)
                (wo): Linear(in_features=5120, out_features=2048, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): GELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (lm_head): Linear(in_features=2048, out_features=32128, bias=False)
  )
  (t5_proj): Linear(in_features=768, out_features=2048, bias=True)
)
2024-07-06 20:27:12,573 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,577 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,587 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,598 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,615 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,625 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,636 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2024-07-06 20:27:12,642 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2024-07-06 20:27:12,642 [INFO] Loaded 214354 records for val split from the dataset.
2024-07-06 20:27:12,642 [INFO] Empty train splits.
2024-07-06 20:27:12,643 [WARNING] /fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

Evaluation  [  0/419]  eta: 7:09:22    time: 61.4857  data: 38.2504  max mem: 19641
Evaluation  [ 10/419]  eta: 1:34:04    time: 13.8012  data: 3.4996  max mem: 21330
Evaluation  [ 20/419]  eta: 1:14:32    time: 8.6952  data: 0.0171  max mem: 21330
Evaluation  [ 30/419]  eta: 1:07:37    time: 8.5774  data: 0.0227  max mem: 21330
Evaluation  [ 40/419]  eta: 1:03:17    time: 8.7713  data: 0.0300  max mem: 21330
[rank1]: Traceback (most recent call last):
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/evaluate.py", line 108, in <module>
[rank1]:     main()
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/evaluate.py", line 104, in main
[rank1]:     runner.evaluate(skip_reload=True)
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/lavis/runners/runner_base.py", line 441, in evaluate
[rank1]:     test_logs[split_name] = self.eval_epoch(
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/lavis/runners/runner_base.py", line 489, in eval_epoch
[rank1]:     results = self.task.evaluation(model, data_loader)
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/lavis/tasks/base_task.py", line 96, in evaluation
[rank1]:     eval_output = self.valid_step(model=model, samples=samples)
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/lavis/tasks/vqa.py", line 133, in valid_step
[rank1]:     answers = model.predict_answers(
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/lavis/models/blip2_models/blip2_t5.py", line 296, in predict_answers
[rank1]:     outputs = self.t5_model.generate(
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/transformers/generation/utils.py", line 1681, in generate
[rank1]:     return self.beam_search(
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/transformers/generation/utils.py", line 3020, in beam_search
[rank1]:     outputs = self(
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/vla/LAVIS/lavis/models/blip2_models/modeling_t5.py", line 1870, in forward
[rank1]:     lm_logits = self.lm_head(sequence_output)
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 116, in forward
[rank1]:     return F.linear(input, self.weight, self.bias)
[rank1]: torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 198.00 MiB. GPU  has a total capacity of 23.67 GiB of which 107.12 MiB is free. Including non-PyTorch memory, this process has 23.56 GiB memory in use. Of the allocated memory 21.89 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0706 20:34:43.144000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486952 closing signal SIGTERM
W0706 20:34:43.144000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486954 closing signal SIGTERM
W0706 20:34:43.144000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486955 closing signal SIGTERM
W0706 20:34:43.144000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486956 closing signal SIGTERM
W0706 20:34:43.145000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486957 closing signal SIGTERM
W0706 20:34:43.145000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486958 closing signal SIGTERM
W0706 20:34:43.145000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:851] Sending process 2486959 closing signal SIGTERM
E0706 20:34:48.540000 139968914507584 torch/distributed/elastic/multiprocessing/api.py:826] failed (exitcode: 1) local_rank: 1 (pid: 2486953) of binary: /fs/nexus-scratch/vla/micromamba/envs/LAVIS/bin/python
Traceback (most recent call last):
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/distributed/run.py", line 883, in <module>
    main()
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/distributed/run.py", line 879, in main
    run(args)
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/distributed/run.py", line 870, in run
    elastic_launch(
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/vla/micromamba/envs/LAVIS/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 263, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
evaluate.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-07-06_20:34:43
  host      : vulcan34.umiacs.umd.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2486953)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
