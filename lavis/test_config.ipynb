{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import lavis.tasks as tasks\n",
    "from lavis.common.config import Config\n",
    "from lavis.common.dist_utils import get_rank, init_distributed_mode\n",
    "from lavis.common.logger import setup_logger\n",
    "from lavis.common.optims import (\n",
    "    LinearWarmupCosineLRScheduler,\n",
    "    LinearWarmupStepLRScheduler,\n",
    ")\n",
    "from lavis.common.utils import now\n",
    "\n",
    "# imports modules for registration\n",
    "from lavis.datasets.builders import *\n",
    "from lavis.models import *\n",
    "from lavis.processors import *\n",
    "from lavis.runners.runner_base import RunnerBase\n",
    "from lavis.tasks import *\n",
    "from layers.nbitlineardynamic import NBitLinearDynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cfg_path': '/nfshomes/vla/scratch/LAVIS/ret_flickr_eval.yaml',\n",
       " 'options': None,\n",
       " 'visual_encoder_blocks': ['qkv', 'fc1'],\n",
       " 'visual_encoder_block_indices': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38]}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Training\")\n",
    "\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    \n",
    "    # parser.add_argument('--img-submodule-FF-weight_bits', required = False, default = None, type = int)\n",
    "    # parser.add_argument('--img-submodule-FF-activation_bits', required = False, default = None, type = int)\n",
    "    \n",
    "    # parser.add_argument('--text-submodule-FF-weight_bits', required = False, default = None)\n",
    "    # parser.add_argument('--text-submodule-FF-activation_bits', required = False, default = None)\n",
    "    \n",
    "    parser.add_argument('--visual-encoder-blocks', \n",
    "                        required=False,\n",
    "                        nargs=\"*\",\n",
    "                        choices= ['qkv', 'proj', 'fc1', 'fc2'],\n",
    "                        default=None,                         \n",
    "                        help='modules of visual-encoder blocks to quantize')\n",
    "    \n",
    "    parser.add_argument('--visual-encoder-block-indices',\n",
    "                         required=False,\n",
    "                         nargs='*',\n",
    "                         type=int,\n",
    "                         choices= [i for i in range(39)],   # NOTE: hard-coded number of possible blocks for ViT\n",
    "                         default=None,      \n",
    "                         help = 'indices of visual-encoder blocks to quantize'\n",
    "                         )                         \n",
    "\n",
    "\n",
    "    CLI_INPUT = f'''\n",
    "                --cfg-path /nfshomes/vla/scratch/LAVIS/ret_flickr_eval.yaml \\\n",
    "                --visual-encoder-blocks qkv fc1\n",
    "                --visual-encoder-block-indices {' '.join([str(i) for i in range(39)])}\n",
    "                \n",
    "                '''\n",
    "                \n",
    "    \n",
    "    args = parser.parse_args(CLI_INPUT.split())\n",
    "    # if 'LOCAL_RANK' not in os.environ:\n",
    "    #     os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "    \n",
    "    args_dict = vars(args)\n",
    "    \n",
    "    if bool(args_dict['visual_encoder_blocks']) ^ bool(args_dict['visual_encoder_block_indices']):\n",
    "        parser.error('--visual-encoder-blocks and --visual-encoder-block-indices must be given together')\n",
    "    \n",
    "\n",
    "    return args\n",
    "\n",
    "args = vars(parse_args())\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lavis.common.config.Config at 0x7fc7fa6f18a0>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = Config(parse_args())\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lavis.tasks.retrieval.RetrievalTask at 0x7fc7fa853520>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = tasks.setup_task(cfg)\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/nexus-scratch/vla/micromamba/envs/BLIP/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position interpolate from 16x16 to 26x26\n"
     ]
    }
   ],
   "source": [
    "model = task.build_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_parts = {name:m.__class__.__name__ for name,m in model.named_children()}\n",
    "# print(model_parts)\n",
    "\n",
    "'''\n",
    "Takes in nn.Linear and returns equivalent NBitLinearDynamic replacement\n",
    "'''\n",
    "def quantize_layer(module:nn.Linear, weight_bits = 32, activation_bits=32):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        bias = True if module.bias != None else False\n",
    "        \n",
    "        Q_layer = NBitLinearDynamic(module.in_features, \n",
    "                    module.out_features, \n",
    "                    bias=bias,\n",
    "                    weight_bits = weight_bits,\n",
    "                    activation_bits = activation_bits)\n",
    "\n",
    "        # copy over weights\n",
    "        Q_layer.weight.copy_(module.weight)\n",
    "        if bias:\n",
    "            Q_layer.bias.copy_(module.bias)\n",
    "\n",
    "    return Q_layer\n",
    "\n",
    "\n",
    "def quantize_visual_encoder_block(module_parent):\n",
    "    for name, module in module_parent.named_children():\n",
    "        if name in args['visual_encoder_blocks']:\n",
    "            print('parent: ', module_parent)\n",
    "            print('child: ', name)\n",
    "            print(quantize_layer(module))\n",
    "            setattr(module_parent, name, quantize_layer(module))\n",
    "        else:\n",
    "            quantize_visual_encoder_block(module)\n",
    "            \n",
    "\n",
    "def quantize_visual_encoder_blocks(blocks):\n",
    "    for name, module in blocks.named_children():\n",
    "        # print(name)\n",
    "        if int(name) in args['visual_encoder_block_indices']:\n",
    "            # print('here')\n",
    "            quantize_visual_encoder_block(module)\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "# def apply_quant_to_selected_modules(model: nn.Module, target_modules: List[str], bits: int = 4, apply=None):\n",
    "    \n",
    "#     for name, module in model.named_children():\n",
    "#         if (apply is None):\n",
    "#             if name in target_modules:\n",
    "#                 print(f\"Applying GPTQ to {name} module\")\n",
    "#                 apply_quant_to_selected-modules(module, target_modules, bits, True)\n",
    "#             else:\n",
    "#                 apply_quant_to_selected-modules(module, target_modules, bits, False)\n",
    "#         else:\n",
    "#             if isinstance(module, nn.Linear):\n",
    "#                 print(f\"Found a layer to quantize {name}\")\n",
    "#                 gptq_quantize_layer(module, bits)\n",
    "#             elif isinstance(module, nn.Module):\n",
    "#                 apply_quant_to_selected-modules(module, target_modules, bits, apply)\n",
    "#     return model\n",
    "\n",
    "# quantized_model = apply_quant_to_selected-modules(model, target_modules, bits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
      "parent:  Linear(in_features=1408, out_features=4224, bias=False)\n",
      "child:  qkv\n",
      "NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
      "parent:  Linear(in_features=1408, out_features=6144, bias=True)\n",
      "child:  fc1\n",
      "NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n"
     ]
    }
   ],
   "source": [
    "quantize_visual_encoder_blocks(model.visual_encoder.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-38): 39 x Block(\n",
       "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(\n",
       "        in_features=1408, out_features=4224, bias=False\n",
       "        (qkv): NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
       "      )\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(\n",
       "        in_features=1408, out_features=6144, bias=True\n",
       "        (fc1): NBitLinearDynamic(in_features=1408, out_features=6144, bias=True)\n",
       "      )\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual_encoder.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qkv', 'proj', 'fc1', 'fc2']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['visual_encoder_blocks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "module_cur = model.visual_encoder.blocks\n",
    "\n",
    "for name, module in module_cur.named_children():\n",
    "    if int(name) in args['visual_encoder_blocks']:\n",
    "        print(name)\n",
    "        print(module)\n",
    "        print(quantize_layer(module))\n",
    "        setattr(module_cur, name, quantize_layer(module))\n",
    "    print(name)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Block(\n",
       "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): NBitLinearDynamic(in_features=1408, out_features=4224, bias=False)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): NBitLinearDynamic(in_features=1408, out_features=1408, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (1-38): 38 x Block(\n",
       "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "    (attn): Attention(\n",
       "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (drop_path): Identity()\n",
       "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "    (mlp): Mlp(\n",
       "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'attn_drop',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_heads',\n",
       " 'parameters',\n",
       " 'proj',\n",
       " 'proj_drop',\n",
       " 'q_bias',\n",
       " 'qkv',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'relative_position_bias_table',\n",
       " 'relative_position_index',\n",
       " 'requires_grad_',\n",
       " 'scale',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'v_bias',\n",
       " 'window_size',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.visual_encoder.blocks[0].attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('patch_embed', PatchEmbed(\n",
      "  (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      "))\n",
      "('pos_drop', Dropout(p=0.0, inplace=False))\n",
      "('blocks', ModuleList(\n",
      "  (0-38): 39 x Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "for x in model.visual_encoder.named_children():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_embed PatchEmbed(\n",
      "  (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
      ")\n",
      "pos_drop Dropout(p=0.0, inplace=False)\n",
      "blocks ModuleList(\n",
      "  (0-38): 39 x Block(\n",
      "    (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (drop_path): Identity()\n",
      "    (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.visual_encoder.named_children():\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cls_token', Parameter containing:\n",
      "tensor([[[ 0.3700,  0.1081, -0.0608,  ...,  0.1736, -0.0758, -0.1867]]],\n",
      "       requires_grad=True))\n",
      "('pos_embed', Parameter containing:\n",
      "tensor([[[ 0.3617,  0.0957, -0.0570,  ...,  0.1747, -0.0557, -0.1614],\n",
      "         [ 0.3302,  0.9622,  0.2345,  ...,  0.2431,  0.0179, -0.9291],\n",
      "         [ 0.2311,  1.4527,  0.1351,  ...,  0.1499,  0.0300, -0.7355],\n",
      "         ...,\n",
      "         [-0.4153,  0.0396,  0.4716,  ..., -0.1404,  0.1401,  1.0388],\n",
      "         [-0.1875, -0.1835,  0.5680,  ...,  0.0724,  0.0063,  0.7481],\n",
      "         [-0.0598, -0.4010,  0.7227,  ...,  0.2676, -0.0519,  0.4881]]],\n",
      "       requires_grad=True))\n",
      "('patch_embed.proj.weight', Parameter containing:\n",
      "tensor([[[[ 1.0929e-02,  5.9179e-03,  3.5793e-03,  ...,  1.4401e-02,\n",
      "            1.5265e-03,  1.8531e-03],\n",
      "          [ 1.3361e-02,  1.0748e-02,  8.9903e-03,  ..., -2.4197e-03,\n",
      "           -2.7329e-03,  4.8976e-04],\n",
      "          [ 1.3349e-02,  9.7972e-03,  7.4245e-03,  ..., -1.3339e-03,\n",
      "            4.0807e-03,  8.1812e-03],\n",
      "          ...,\n",
      "          [ 9.0809e-03, -3.8232e-04,  5.7313e-03,  ...,  4.0712e-03,\n",
      "           -1.0036e-03,  1.4750e-02],\n",
      "          [-5.1130e-03,  1.2889e-03,  4.7878e-03,  ...,  3.2544e-03,\n",
      "           -4.5769e-03,  7.7449e-03],\n",
      "          [-1.3512e-02,  6.8606e-03,  4.0810e-03,  ...,  4.1565e-03,\n",
      "            3.7592e-03,  1.0949e-02]],\n",
      "\n",
      "         [[-1.2988e-02, -8.7647e-03, -7.6875e-03,  ...,  5.4118e-03,\n",
      "           -4.4299e-03, -9.2759e-03],\n",
      "          [-1.6282e-03, -1.4466e-03, -3.9095e-03,  ..., -6.8330e-03,\n",
      "           -3.1231e-03, -3.2460e-03],\n",
      "          [ 9.0504e-04, -2.2498e-03, -4.3372e-03,  ..., -4.2313e-03,\n",
      "            1.2057e-03,  3.4456e-03],\n",
      "          ...,\n",
      "          [ 4.0820e-03, -4.2335e-03, -1.0074e-03,  ...,  3.1395e-03,\n",
      "            3.1087e-03,  6.6756e-03],\n",
      "          [-9.0751e-03, -5.7895e-03, -1.3870e-03,  ...,  3.2539e-05,\n",
      "           -4.4090e-03, -5.7159e-03],\n",
      "          [-3.2654e-03,  1.1766e-02,  6.4575e-03,  ..., -2.5903e-04,\n",
      "           -5.4204e-04, -1.0497e-02]],\n",
      "\n",
      "         [[-5.7531e-03, -6.4982e-03, -2.0012e-03,  ...,  6.1303e-03,\n",
      "           -6.7012e-03, -3.2125e-03],\n",
      "          [ 1.8532e-03, -4.0590e-03, -4.6254e-04,  ..., -1.4497e-03,\n",
      "           -4.0923e-03,  1.8501e-03],\n",
      "          [ 4.0327e-03, -2.9541e-03,  4.3917e-03,  ...,  2.7463e-03,\n",
      "            3.4856e-03,  1.2346e-02],\n",
      "          ...,\n",
      "          [ 9.4960e-03,  2.3550e-03,  5.5272e-03,  ...,  4.7186e-03,\n",
      "            7.3705e-03,  2.3907e-03],\n",
      "          [ 9.5048e-04,  3.7357e-03,  6.4774e-03,  ...,  3.2376e-03,\n",
      "            3.2089e-03, -1.1345e-02],\n",
      "          [-2.0641e-03,  6.7887e-03,  2.7169e-03,  ..., -5.3467e-04,\n",
      "            1.0066e-03, -2.1869e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2113e-02,  3.4973e-03,  5.5510e-04,  ...,  4.1692e-03,\n",
      "            7.8226e-04, -3.1523e-02],\n",
      "          [-3.8408e-03,  8.4360e-03,  7.6700e-03,  ...,  6.4372e-03,\n",
      "            1.2914e-02,  6.1756e-04],\n",
      "          [ 3.1365e-03,  1.0568e-02,  2.5522e-03,  ..., -2.1297e-03,\n",
      "            9.8069e-03, -3.3045e-03],\n",
      "          ...,\n",
      "          [-1.1666e-02, -8.9287e-03, -1.6690e-02,  ..., -6.2530e-03,\n",
      "           -4.8491e-03, -1.0027e-03],\n",
      "          [-1.0619e-02, -2.2105e-03, -1.2603e-02,  ..., -9.8415e-03,\n",
      "           -1.9455e-03,  7.1285e-03],\n",
      "          [-1.2449e-02,  5.3245e-03, -1.5277e-02,  ..., -1.1503e-02,\n",
      "            4.6555e-03,  1.6904e-02]],\n",
      "\n",
      "         [[ 2.7382e-03,  2.9343e-03,  9.6105e-03,  ...,  1.9068e-02,\n",
      "            5.4758e-03, -1.0481e-03],\n",
      "          [ 9.4527e-04, -8.8269e-03, -5.0592e-04,  ...,  2.3379e-03,\n",
      "           -1.5901e-03,  5.5315e-03],\n",
      "          [ 1.1525e-02,  3.7042e-03,  4.5923e-03,  ...,  1.8841e-04,\n",
      "            2.0902e-03,  4.1649e-03],\n",
      "          ...,\n",
      "          [ 3.0487e-03,  3.1626e-04, -1.7932e-03,  ...,  1.1239e-03,\n",
      "           -3.6920e-04,  4.5261e-03],\n",
      "          [ 2.0642e-03,  1.6932e-03, -2.4451e-04,  ..., -3.2448e-04,\n",
      "            1.3252e-03,  9.1790e-03],\n",
      "          [ 2.5606e-02,  2.7015e-02,  1.1244e-02,  ...,  1.4212e-02,\n",
      "            1.9738e-02,  2.3615e-02]],\n",
      "\n",
      "         [[-1.8893e-02, -1.5897e-02, -6.9466e-03,  ..., -2.3858e-03,\n",
      "           -1.4045e-02, -1.4198e-02],\n",
      "          [-1.1052e-02, -1.8470e-02, -1.0044e-02,  ..., -6.6422e-03,\n",
      "           -1.0810e-02,  1.2488e-03],\n",
      "          [-6.0530e-03, -1.0601e-02, -8.6915e-03,  ..., -9.3365e-03,\n",
      "           -1.1304e-02, -3.1126e-03],\n",
      "          ...,\n",
      "          [ 1.9186e-02, -2.9042e-03,  4.0169e-03,  ...,  6.3764e-03,\n",
      "           -1.8147e-04,  1.7609e-02],\n",
      "          [ 9.2968e-03, -4.5805e-03,  7.5741e-03,  ...,  5.5153e-03,\n",
      "            2.9784e-04,  1.1983e-02],\n",
      "          [ 2.8080e-02,  1.7374e-02,  1.4630e-02,  ...,  1.5017e-02,\n",
      "            1.4197e-02,  1.9118e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0286e-03, -1.1224e-03,  4.2238e-03,  ...,  8.3626e-03,\n",
      "           -6.8144e-03, -2.4200e-03],\n",
      "          [-8.0141e-03, -5.6491e-03,  6.1944e-03,  ...,  6.9223e-03,\n",
      "           -1.5388e-03, -5.7318e-03],\n",
      "          [-6.5529e-04, -9.3241e-04,  3.4090e-04,  ..., -2.7509e-03,\n",
      "           -2.4739e-03, -8.0165e-03],\n",
      "          ...,\n",
      "          [-1.2196e-02,  5.6295e-03,  5.0140e-04,  ...,  3.5513e-03,\n",
      "           -2.8903e-03,  1.7615e-03],\n",
      "          [-1.3032e-02,  3.1157e-03, -7.5954e-03,  ..., -5.2203e-03,\n",
      "           -6.8926e-03,  9.9530e-04],\n",
      "          [ 1.1691e-02,  2.4423e-02,  1.1135e-02,  ...,  1.0807e-02,\n",
      "            1.7079e-02,  3.0528e-02]],\n",
      "\n",
      "         [[-5.0547e-03, -8.0524e-03, -2.8135e-03,  ...,  3.1503e-03,\n",
      "           -1.0015e-02,  5.7551e-04],\n",
      "          [ 6.2137e-04, -1.4513e-02, -3.6434e-03,  ..., -2.5196e-03,\n",
      "           -5.4630e-03,  1.2975e-03],\n",
      "          [ 8.4612e-03, -8.4393e-03, -8.6966e-03,  ..., -1.3928e-02,\n",
      "           -9.1755e-03, -2.3085e-03],\n",
      "          ...,\n",
      "          [ 1.6849e-03, -2.9363e-03, -3.6397e-03,  ...,  4.1561e-03,\n",
      "           -6.7058e-03,  1.0723e-02],\n",
      "          [ 1.4716e-03, -2.1839e-03, -7.0013e-03,  ..., -1.7739e-03,\n",
      "           -6.1578e-03,  1.0324e-02],\n",
      "          [ 2.2678e-02,  1.6982e-02,  2.2593e-03,  ..., -2.3751e-03,\n",
      "            2.4677e-03,  1.7103e-02]],\n",
      "\n",
      "         [[-1.7482e-02,  1.9818e-02,  1.6256e-02,  ...,  1.5848e-02,\n",
      "            1.1155e-02, -1.0542e-02],\n",
      "          [-2.3697e-02,  1.1826e-03, -3.1992e-03,  ..., -1.0697e-03,\n",
      "            1.0278e-02, -1.6494e-02],\n",
      "          [-1.4425e-02,  8.6331e-03, -3.1179e-03,  ..., -7.8546e-04,\n",
      "            1.7345e-02, -1.5960e-02],\n",
      "          ...,\n",
      "          [ 1.2422e-02, -5.5600e-05, -2.0959e-03,  ...,  5.8662e-03,\n",
      "           -1.8287e-03,  1.3620e-02],\n",
      "          [ 1.0337e-02, -4.8990e-03, -5.4907e-03,  ..., -7.8519e-04,\n",
      "           -2.1287e-03,  5.8744e-03],\n",
      "          [ 2.8680e-02,  8.1475e-03, -7.8897e-04,  ...,  5.1708e-04,\n",
      "            4.4562e-03,  9.5278e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.5885e-04, -8.5648e-03, -1.4164e-03,  ...,  1.0782e-02,\n",
      "            7.7302e-04, -1.4493e-03],\n",
      "          [ 1.5398e-03, -7.2502e-03,  6.6963e-03,  ...,  1.5323e-03,\n",
      "           -5.0310e-03, -5.2403e-03],\n",
      "          [ 4.7108e-03, -3.4238e-03,  9.2985e-03,  ...,  8.2225e-04,\n",
      "           -5.1284e-03, -2.7946e-03],\n",
      "          ...,\n",
      "          [-1.6640e-04,  8.7352e-04,  5.7320e-03,  ...,  2.3014e-03,\n",
      "           -6.3699e-03,  1.7427e-02],\n",
      "          [-5.0983e-03,  9.4983e-05,  4.5730e-03,  ..., -1.2139e-02,\n",
      "           -1.0345e-02,  1.6435e-02],\n",
      "          [-1.9807e-02,  7.3672e-04, -6.4847e-03,  ..., -1.3639e-02,\n",
      "           -7.0836e-03,  1.8416e-02]],\n",
      "\n",
      "         [[-4.9666e-03, -1.0036e-02, -5.6214e-03,  ...,  1.0654e-03,\n",
      "           -5.2658e-03, -8.7735e-03],\n",
      "          [-9.2122e-04, -8.6447e-03,  7.8092e-04,  ..., -4.4397e-03,\n",
      "           -5.7582e-03, -6.4253e-03],\n",
      "          [ 2.1872e-03, -7.6269e-03,  1.5980e-03,  ..., -2.2145e-03,\n",
      "           -4.2301e-03, -3.7040e-03],\n",
      "          ...,\n",
      "          [-2.7001e-03, -2.9239e-03,  1.0778e-03,  ...,  5.3849e-03,\n",
      "           -4.5622e-03,  6.9377e-03],\n",
      "          [-5.2354e-03, -6.6664e-03, -3.5856e-03,  ..., -1.1336e-02,\n",
      "           -1.0025e-02,  1.3898e-03],\n",
      "          [ 1.4859e-03,  9.0928e-03, -2.7194e-03,  ..., -7.2170e-03,\n",
      "           -1.9744e-03, -7.7609e-04]],\n",
      "\n",
      "         [[-6.7853e-03,  2.0605e-03, -2.0996e-03,  ...,  2.1745e-03,\n",
      "           -3.6706e-04, -3.2760e-03],\n",
      "          [-2.2175e-03,  6.5030e-04, -2.8260e-03,  ..., -3.9575e-03,\n",
      "            1.2554e-03, -3.7601e-03],\n",
      "          [ 2.8568e-03,  8.5886e-04,  2.8261e-03,  ..., -2.9843e-03,\n",
      "            3.9362e-03,  1.9397e-04],\n",
      "          ...,\n",
      "          [-4.0263e-04,  4.3729e-03, -6.7218e-04,  ...,  5.0532e-03,\n",
      "            5.7838e-03, -4.9869e-03],\n",
      "          [-3.2723e-03,  1.3562e-03, -2.3279e-03,  ..., -8.6295e-03,\n",
      "            7.9364e-04, -6.9591e-03],\n",
      "          [ 2.0480e-03,  1.0222e-02, -4.2605e-03,  ..., -5.3880e-03,\n",
      "            7.0571e-03, -1.7308e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0217e-02, -1.0910e-02, -1.2713e-02,  ..., -9.1430e-03,\n",
      "           -9.5118e-03, -2.7056e-02],\n",
      "          [-9.2902e-03, -1.3108e-03,  1.0279e-03,  ...,  1.5231e-03,\n",
      "            7.4147e-03, -1.1528e-02],\n",
      "          [-1.2367e-02,  5.6335e-03,  5.2907e-03,  ..., -2.6647e-03,\n",
      "            2.7705e-03, -1.9462e-02],\n",
      "          ...,\n",
      "          [-2.9477e-02,  1.0997e-02,  6.9015e-03,  ...,  2.8392e-03,\n",
      "            9.6289e-04, -2.3945e-02],\n",
      "          [-2.5383e-02,  1.0750e-02,  2.9042e-03,  ..., -1.5899e-03,\n",
      "           -2.7966e-03, -2.1266e-02],\n",
      "          [-4.8970e-02,  8.3187e-03, -3.0318e-03,  ..., -1.2059e-02,\n",
      "           -5.3759e-03, -3.0765e-02]],\n",
      "\n",
      "         [[-1.3793e-02, -7.7844e-03, -9.2606e-03,  ..., -3.8485e-03,\n",
      "           -6.2046e-03, -1.5867e-02],\n",
      "          [-2.2539e-03, -1.6158e-03,  8.3427e-03,  ...,  6.4579e-03,\n",
      "            5.2812e-03, -4.6596e-03],\n",
      "          [-3.7327e-04,  2.8190e-03,  9.0470e-03,  ...,  3.5618e-03,\n",
      "           -1.4291e-03, -1.0362e-02],\n",
      "          ...,\n",
      "          [-7.2988e-03,  4.7168e-03,  6.3566e-03,  ...,  9.3374e-03,\n",
      "           -1.3491e-03, -7.5879e-03],\n",
      "          [-9.2919e-03,  3.2267e-03,  6.7852e-03,  ...,  5.1089e-03,\n",
      "           -1.8265e-03, -7.2588e-03],\n",
      "          [-1.9300e-02,  1.0681e-02,  4.7326e-03,  ..., -6.3508e-03,\n",
      "           -3.6278e-03, -1.9412e-02]],\n",
      "\n",
      "         [[-1.7319e-02,  3.7844e-03, -3.2167e-03,  ..., -1.1289e-03,\n",
      "            3.1715e-03, -1.5495e-02],\n",
      "          [-4.4673e-03,  5.8149e-03, -2.4404e-03,  ...,  5.4502e-03,\n",
      "            1.8270e-02, -3.5236e-03],\n",
      "          [-5.4494e-03,  1.2718e-02, -1.1869e-03,  ...,  1.9266e-03,\n",
      "            1.7340e-02, -8.6856e-03],\n",
      "          ...,\n",
      "          [-9.2970e-03,  2.4292e-02,  5.8392e-03,  ...,  7.3228e-03,\n",
      "            2.1571e-02, -1.8279e-02],\n",
      "          [-7.7266e-03,  1.5000e-02, -2.1930e-04,  ..., -1.3802e-03,\n",
      "            1.3432e-02, -1.5219e-02],\n",
      "          [-5.0022e-03,  3.1040e-02,  1.1012e-02,  ...,  1.3781e-02,\n",
      "            2.9802e-02, -1.2220e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4363e-02, -9.4449e-03, -1.1825e-02,  ..., -1.0955e-02,\n",
      "           -7.0249e-03, -3.8276e-02],\n",
      "          [-1.0130e-02, -1.4746e-04, -8.9816e-03,  ..., -7.9063e-03,\n",
      "            3.6074e-03, -1.4661e-02],\n",
      "          [-1.4012e-02,  1.5154e-04, -8.1218e-03,  ..., -1.8990e-02,\n",
      "           -4.2174e-03, -2.2177e-02],\n",
      "          ...,\n",
      "          [ 1.1878e-02,  8.1870e-03,  1.0452e-02,  ...,  1.2055e-02,\n",
      "            7.9443e-03,  1.9831e-02],\n",
      "          [ 4.7120e-03,  2.6871e-03,  1.4337e-03,  ..., -1.5371e-03,\n",
      "           -1.2424e-03,  1.5945e-02],\n",
      "          [-5.2029e-03,  4.4750e-03, -6.0261e-03,  ..., -1.0213e-02,\n",
      "           -6.6660e-03,  1.0852e-02]],\n",
      "\n",
      "         [[-3.9241e-03, -1.4146e-02,  6.2969e-04,  ...,  8.8144e-03,\n",
      "           -1.9334e-03, -3.5151e-03],\n",
      "          [-3.7296e-03, -1.9486e-02, -1.3010e-02,  ..., -7.1217e-03,\n",
      "           -6.8662e-03,  3.0785e-03],\n",
      "          [ 1.1168e-02, -3.8429e-03,  4.3124e-04,  ..., -8.5128e-03,\n",
      "           -7.5169e-03,  3.8488e-03],\n",
      "          ...,\n",
      "          [ 2.2654e-02,  5.9179e-03,  1.2476e-02,  ...,  1.7549e-02,\n",
      "            1.0077e-02,  2.1701e-02],\n",
      "          [ 1.3583e-02,  7.0339e-03,  9.3501e-03,  ...,  8.9315e-03,\n",
      "            9.9219e-03,  1.6826e-02],\n",
      "          [ 6.7369e-03,  1.1280e-02,  3.0864e-03,  ..., -1.8649e-03,\n",
      "            3.0570e-03,  1.4927e-03]],\n",
      "\n",
      "         [[-1.5217e-02, -3.1852e-03,  4.2121e-03,  ...,  1.6455e-03,\n",
      "            4.9846e-04, -1.2838e-02],\n",
      "          [-1.1597e-02, -8.9683e-03, -1.3142e-02,  ..., -9.2045e-03,\n",
      "           -1.7728e-03, -9.1031e-03],\n",
      "          [-6.4255e-04,  5.2551e-03, -1.1181e-03,  ..., -7.3061e-03,\n",
      "           -1.9872e-03, -9.5700e-03],\n",
      "          ...,\n",
      "          [ 8.2781e-03,  8.5913e-03,  5.7779e-03,  ...,  5.9181e-03,\n",
      "            1.2383e-02, -4.2702e-03],\n",
      "          [ 6.6417e-03,  1.4181e-02,  1.1114e-02,  ...,  9.8187e-03,\n",
      "            2.1523e-02,  2.0938e-03],\n",
      "          [-6.2415e-03,  1.1687e-02,  3.4133e-04,  ...,  1.3337e-03,\n",
      "            1.1137e-02, -2.1178e-02]]]], requires_grad=True))\n",
      "('patch_embed.proj.bias', Parameter containing:\n",
      "tensor([-0.0510, -0.1765, -0.3844,  ..., -0.0706,  0.0252,  0.4419],\n",
      "       requires_grad=True))\n",
      "('blocks.0.norm1.weight', Parameter containing:\n",
      "tensor([ 9.2920e-05,  1.7360e-03,  3.3957e-03,  ..., -6.9191e-04,\n",
      "        -2.4007e-04,  2.3610e-03], requires_grad=True))\n",
      "('blocks.0.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0006, -0.0007, -0.0019,  ...,  0.0009, -0.0019,  0.0026],\n",
      "       requires_grad=True))\n",
      "('blocks.0.attn.q_bias', Parameter containing:\n",
      "tensor([-0.4422, -0.0698,  0.2440,  ...,  0.1283,  0.4798, -0.2652],\n",
      "       requires_grad=True))\n",
      "('blocks.0.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0030, -0.0107, -0.1787,  ..., -0.0181, -0.0029, -0.0024],\n",
      "       requires_grad=True))\n",
      "('blocks.0.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-3.7433e-05,  4.4084e-06,  1.0484e-04,  ..., -2.0027e-06,\n",
      "          1.3502e-05, -6.1350e-06],\n",
      "        [ 8.7078e-06,  1.1413e-04,  1.2215e-06,  ...,  3.5051e-05,\n",
      "         -2.0387e-05,  5.7940e-05],\n",
      "        [ 2.5630e-05, -3.2265e-05, -1.0366e-04,  ...,  1.4808e-05,\n",
      "         -2.3766e-05, -2.1590e-05],\n",
      "        ...,\n",
      "        [ 5.7928e-05,  4.1712e-04, -3.1326e-04,  ..., -1.7062e-05,\n",
      "          8.7177e-05, -1.5303e-04],\n",
      "        [ 4.2284e-05,  2.6580e-05, -1.0721e-03,  ...,  2.8292e-06,\n",
      "         -5.4697e-05, -1.4002e-04],\n",
      "        [-6.5086e-05, -7.2947e-05,  9.6259e-05,  ..., -1.0860e-05,\n",
      "          6.6359e-05, -5.0974e-05]], requires_grad=True))\n",
      "('blocks.0.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 2.3923e-03,  9.4107e-04,  1.7663e-01,  ...,  1.0351e-02,\n",
      "         -1.6260e-03,  1.0090e-03],\n",
      "        [ 1.0703e-03, -1.2100e-03,  1.4597e-02,  ..., -2.9487e-03,\n",
      "         -2.8233e-03,  7.9404e-04],\n",
      "        [-1.5546e-03,  8.0007e-03,  4.4412e-02,  ...,  3.8289e-03,\n",
      "         -1.4716e-03,  3.5445e-03],\n",
      "        ...,\n",
      "        [ 1.5037e-02, -6.5308e-03, -7.3274e-02,  ..., -3.8709e-03,\n",
      "         -1.7047e-04, -6.7374e-03],\n",
      "        [-4.7929e-03,  2.0415e-03, -3.8939e-03,  ..., -2.7544e-03,\n",
      "          5.8011e-03,  3.1935e-03],\n",
      "        [ 1.0753e-02,  4.0806e-03, -3.2681e-02,  ...,  1.0521e-02,\n",
      "         -8.8043e-04, -2.6419e-03]], requires_grad=True))\n",
      "('blocks.0.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.9502,  0.0106,  0.4036,  ..., -0.3484, -0.1921, -0.3172],\n",
      "       requires_grad=True))\n",
      "('blocks.0.norm2.weight', Parameter containing:\n",
      "tensor([ 1.3761e-05, -2.9154e-04, -2.9453e-04,  ...,  2.0259e-04,\n",
      "         1.8040e-02,  6.1829e-05], requires_grad=True))\n",
      "('blocks.0.norm2.bias', Parameter containing:\n",
      "tensor([ 3.6176e-05, -1.4414e-03, -3.7961e-04,  ..., -3.4226e-04,\n",
      "        -1.9311e-02,  1.5517e-04], requires_grad=True))\n",
      "('blocks.0.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 1.6521e-06, -1.6389e-04,  3.1111e-06,  ..., -4.9172e-05,\n",
      "         -4.6861e-03,  1.8538e-05],\n",
      "        [-2.1236e-05, -1.9233e-05,  3.2991e-04,  ...,  3.3611e-05,\n",
      "         -4.9707e-04,  1.9999e-05],\n",
      "        [ 2.5518e-05,  1.5608e-04, -7.2893e-04,  ..., -4.6946e-05,\n",
      "          1.2192e-03,  6.4165e-05],\n",
      "        ...,\n",
      "        [-4.0412e-06,  2.3371e-04, -6.1151e-04,  ...,  1.5635e-05,\n",
      "          3.5514e-05, -2.7819e-05],\n",
      "        [ 2.1987e-06, -1.8139e-05, -9.0093e-06,  ..., -2.3395e-05,\n",
      "         -4.7528e-05,  3.7585e-06],\n",
      "        [-1.6818e-05,  2.3136e-04, -2.8165e-04,  ..., -1.7897e-05,\n",
      "         -3.9748e-03,  3.3550e-05]], requires_grad=True))\n",
      "('blocks.0.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-1.8476e+00, -9.8197e-01, -2.7438e-01,  ..., -3.3128e-01,\n",
      "        -2.8717e-04, -2.9223e-01], requires_grad=True))\n",
      "('blocks.0.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0167, -0.0034, -0.0071,  ...,  0.0109, -0.0001, -0.0050],\n",
      "        [ 0.0021,  0.0089,  0.0069,  ...,  0.0106, -0.0010, -0.0089],\n",
      "        [-0.0046,  0.0015, -0.0028,  ...,  0.0023, -0.0003,  0.0004],\n",
      "        ...,\n",
      "        [-0.0001,  0.0032,  0.0093,  ..., -0.0094,  0.0004, -0.0064],\n",
      "        [ 0.0097,  0.0007,  0.0129,  ..., -0.0009,  0.0003, -0.0073],\n",
      "        [-0.0002,  0.0164,  0.0250,  ...,  0.0099,  0.0001, -0.0050]],\n",
      "       requires_grad=True))\n",
      "('blocks.0.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-1.2978, -0.2033,  0.0297,  ...,  0.5293,  0.4575, -0.0137],\n",
      "       requires_grad=True))\n",
      "('blocks.1.norm1.weight', Parameter containing:\n",
      "tensor([-2.7548e-05,  2.4993e-01,  3.2133e-01,  ...,  2.5829e-02,\n",
      "         2.1496e-01,  1.3326e-01], requires_grad=True))\n",
      "('blocks.1.norm1.bias', Parameter containing:\n",
      "tensor([ 1.6766e-04,  1.7675e-01, -3.6360e-02,  ..., -1.1489e-02,\n",
      "        -4.2745e-02, -5.6541e-02], requires_grad=True))\n",
      "('blocks.1.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.1412,  0.0212,  0.0409,  ...,  0.3860, -0.1532,  0.0786],\n",
      "       requires_grad=True))\n",
      "('blocks.1.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.1045, -0.0360,  0.0523,  ..., -0.0079,  0.0003,  0.0305],\n",
      "       requires_grad=True))\n",
      "('blocks.1.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-2.6468e-06, -3.5689e-03,  9.2161e-03,  ..., -2.2907e-04,\n",
      "          2.6322e-04, -1.5795e-03],\n",
      "        [ 4.4834e-06, -1.8998e-03,  5.8643e-03,  ..., -4.9383e-04,\n",
      "          2.8072e-04, -1.7173e-03],\n",
      "        [-2.7004e-06, -3.7835e-03,  6.8421e-03,  ...,  1.8498e-04,\n",
      "         -6.7780e-04,  8.0698e-05],\n",
      "        ...,\n",
      "        [-5.6444e-07, -8.7842e-03, -7.7935e-04,  ..., -1.4008e-03,\n",
      "          6.8235e-04, -6.9217e-03],\n",
      "        [-2.9422e-05,  1.7575e-02, -1.5064e-02,  ...,  1.0448e-04,\n",
      "         -8.9290e-03, -3.5412e-03],\n",
      "        [ 1.1423e-05, -4.4689e-03,  1.0784e-02,  ...,  3.0238e-03,\n",
      "         -5.8111e-03, -4.5631e-03]], requires_grad=True))\n",
      "('blocks.1.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0098, -0.0098, -0.0058,  ..., -0.0151, -0.0042, -0.0043],\n",
      "        [ 0.0112, -0.0021, -0.0023,  ...,  0.0036, -0.0134,  0.0015],\n",
      "        [ 0.0102, -0.0152,  0.0099,  ...,  0.0127,  0.0083, -0.0188],\n",
      "        ...,\n",
      "        [-0.0110, -0.0136,  0.0117,  ...,  0.0114, -0.0002, -0.0024],\n",
      "        [-0.0114, -0.0004,  0.0082,  ...,  0.0009,  0.0121,  0.0182],\n",
      "        [-0.0002,  0.0038, -0.0059,  ...,  0.0053,  0.0042, -0.0025]],\n",
      "       requires_grad=True))\n",
      "('blocks.1.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1840,  0.1387, -0.1503,  ..., -0.0245,  0.0134,  0.0964],\n",
      "       requires_grad=True))\n",
      "('blocks.1.norm2.weight', Parameter containing:\n",
      "tensor([0.0368, 0.1511, 0.1774,  ..., 0.0641, 0.1412, 0.1502],\n",
      "       requires_grad=True))\n",
      "('blocks.1.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0501,  0.0399, -0.0328,  ..., -0.0211, -0.0409, -0.1045],\n",
      "       requires_grad=True))\n",
      "('blocks.1.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 2.0417e-03,  1.1918e-02,  3.5756e-04,  ...,  9.2220e-05,\n",
      "          4.0136e-03, -2.4850e-03],\n",
      "        [-7.8024e-03,  1.1033e-02, -9.0852e-03,  ...,  6.7099e-03,\n",
      "         -5.1242e-04,  2.8299e-03],\n",
      "        [ 1.3388e-03, -4.1421e-03, -5.1023e-03,  ..., -2.9827e-03,\n",
      "         -7.9309e-03, -6.6687e-03],\n",
      "        ...,\n",
      "        [-3.6956e-05,  4.5261e-04,  1.0577e-02,  ..., -3.4960e-03,\n",
      "         -1.0093e-02, -5.6058e-03],\n",
      "        [-7.7879e-03, -2.2801e-03, -1.0295e-02,  ...,  5.5889e-03,\n",
      "          1.9609e-02,  2.1940e-03],\n",
      "        [-3.2279e-03,  3.5913e-02, -2.4247e-03,  ..., -4.1544e-04,\n",
      "          4.3930e-03,  1.0344e-02]], requires_grad=True))\n",
      "('blocks.1.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-1.3047, -0.8965, -1.3457,  ..., -1.2549, -1.0547, -1.2725],\n",
      "       requires_grad=True))\n",
      "('blocks.1.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0049,  0.0053,  0.0018,  ...,  0.0007,  0.0216, -0.0095],\n",
      "        [ 0.0061, -0.0031,  0.0121,  ...,  0.0115,  0.0088,  0.0049],\n",
      "        [-0.0010,  0.0191,  0.0087,  ...,  0.0026,  0.0132, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0133,  0.0200,  ...,  0.0051,  0.0059,  0.0039],\n",
      "        [ 0.0018,  0.0107,  0.0175,  ...,  0.0039, -0.0060,  0.0020],\n",
      "        [-0.0189, -0.0172,  0.0124,  ..., -0.0030,  0.0083,  0.0047]],\n",
      "       requires_grad=True))\n",
      "('blocks.1.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.5405,  0.1732,  0.4356,  ...,  0.3982,  0.1030,  0.0102],\n",
      "       requires_grad=True))\n",
      "('blocks.2.norm1.weight', Parameter containing:\n",
      "tensor([0.2023, 0.5014, 0.3770,  ..., 0.1025, 0.3689, 0.2905],\n",
      "       requires_grad=True))\n",
      "('blocks.2.norm1.bias', Parameter containing:\n",
      "tensor([ 0.2306,  0.2372,  0.0613,  ..., -0.0746, -0.1294, -0.2095],\n",
      "       requires_grad=True))\n",
      "('blocks.2.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.7540, -0.5186, -0.3665,  ..., -1.0420, -0.0435,  0.2223],\n",
      "       requires_grad=True))\n",
      "('blocks.2.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0048,  0.3045, -0.0259,  ..., -0.0007, -0.0070, -0.0076],\n",
      "       requires_grad=True))\n",
      "('blocks.2.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 8.3171e-03, -3.8217e-03, -2.0739e-02,  ...,  3.2437e-03,\n",
      "         -2.0715e-03,  8.4872e-04],\n",
      "        [-5.7606e-04,  4.2840e-04,  1.8876e-02,  ..., -1.4190e-03,\n",
      "          7.6833e-04,  1.0330e-02],\n",
      "        [ 1.6355e-03,  9.4142e-03,  1.0345e-02,  ...,  5.8653e-05,\n",
      "         -8.6877e-05,  2.3005e-03],\n",
      "        ...,\n",
      "        [-2.1193e-03, -3.1939e-03,  1.0737e-03,  ..., -3.6047e-03,\n",
      "         -7.0889e-03, -5.4268e-03],\n",
      "        [ 6.9924e-03,  9.4839e-03, -6.2985e-03,  ...,  3.4906e-03,\n",
      "          2.6698e-03, -2.9569e-03],\n",
      "        [-2.0203e-03,  3.6346e-03,  5.6234e-03,  ..., -7.3548e-04,\n",
      "         -1.5799e-03, -2.1069e-03]], requires_grad=True))\n",
      "('blocks.2.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0049, -0.0115,  0.0039,  ..., -0.0066,  0.0013,  0.0006],\n",
      "        [-0.0029, -0.0304, -0.0158,  ...,  0.0069, -0.0095, -0.0033],\n",
      "        [-0.0074, -0.0100, -0.0066,  ..., -0.0008,  0.0057, -0.0049],\n",
      "        ...,\n",
      "        [-0.0039, -0.0088, -0.0121,  ...,  0.0078, -0.0046, -0.0012],\n",
      "        [-0.0198, -0.0099,  0.0034,  ...,  0.0028, -0.0161, -0.0071],\n",
      "        [-0.0269, -0.0089,  0.0026,  ...,  0.0130, -0.0014, -0.0001]],\n",
      "       requires_grad=True))\n",
      "('blocks.2.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.8106,  0.4936,  0.1056,  ..., -0.3889, -0.1581, -0.1961],\n",
      "       requires_grad=True))\n",
      "('blocks.2.norm2.weight', Parameter containing:\n",
      "tensor([0.2830, 0.7329, 0.4973,  ..., 0.2173, 0.5293, 0.4739],\n",
      "       requires_grad=True))\n",
      "('blocks.2.norm2.bias', Parameter containing:\n",
      "tensor([ 0.3581, -0.0946, -0.0150,  ..., -0.0709, -0.1418, -0.2741],\n",
      "       requires_grad=True))\n",
      "('blocks.2.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0094,  0.0049,  0.0071,  ...,  0.0056, -0.0083, -0.0090],\n",
      "        [-0.0099, -0.0111,  0.0321,  ...,  0.0078, -0.0214,  0.0027],\n",
      "        [-0.0135,  0.0029, -0.0016,  ..., -0.0074, -0.0005,  0.0173],\n",
      "        ...,\n",
      "        [-0.0025,  0.0096,  0.0042,  ...,  0.0024,  0.0075,  0.0017],\n",
      "        [-0.0111,  0.0071, -0.0257,  ...,  0.0019, -0.0014,  0.0245],\n",
      "        [ 0.0076, -0.0072, -0.0004,  ...,  0.0038, -0.0071, -0.0283]],\n",
      "       requires_grad=True))\n",
      "('blocks.2.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.8287, -0.9785, -1.3213,  ..., -0.6499, -1.0869, -0.5821],\n",
      "       requires_grad=True))\n",
      "('blocks.2.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0010, -0.0002,  0.0188,  ...,  0.0017, -0.0089, -0.0117],\n",
      "        [ 0.0181, -0.0071, -0.0001,  ..., -0.0023,  0.0030,  0.0044],\n",
      "        [-0.0075, -0.0231,  0.0105,  ...,  0.0102, -0.0032, -0.0171],\n",
      "        ...,\n",
      "        [-0.0051, -0.0009,  0.0036,  ...,  0.0050, -0.0027, -0.0170],\n",
      "        [-0.0026,  0.0067, -0.0018,  ..., -0.0131, -0.0217, -0.0081],\n",
      "        [ 0.0199, -0.0019, -0.0241,  ..., -0.0102, -0.0043, -0.0074]],\n",
      "       requires_grad=True))\n",
      "('blocks.2.mlp.fc2.bias', Parameter containing:\n",
      "tensor([0.0971, 0.1391, 0.5347,  ..., 0.2588, 0.0890, 0.2546],\n",
      "       requires_grad=True))\n",
      "('blocks.3.norm1.weight', Parameter containing:\n",
      "tensor([0.4053, 0.5308, 0.5831,  ..., 0.1855, 0.4677, 0.3310],\n",
      "       requires_grad=True))\n",
      "('blocks.3.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0972, -0.0912, -0.2761,  ..., -0.1003, -0.2363, -0.2628],\n",
      "       requires_grad=True))\n",
      "('blocks.3.attn.q_bias', Parameter containing:\n",
      "tensor([ 1.3008, -0.8276, -0.4878,  ..., -0.1265, -0.3187, -0.9317],\n",
      "       requires_grad=True))\n",
      "('blocks.3.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0179,  0.0123, -0.0092,  ...,  0.0144, -0.0050,  0.0264],\n",
      "       requires_grad=True))\n",
      "('blocks.3.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0114,  0.0049, -0.0061,  ..., -0.0013,  0.0004, -0.0036],\n",
      "        [ 0.0057, -0.0086,  0.0158,  ...,  0.0026, -0.0108, -0.0068],\n",
      "        [-0.0068, -0.0101, -0.0010,  ...,  0.0040,  0.0046,  0.0003],\n",
      "        ...,\n",
      "        [ 0.0029,  0.0082, -0.0035,  ..., -0.0007, -0.0125,  0.0017],\n",
      "        [-0.0085, -0.0126, -0.0029,  ..., -0.0022,  0.0170, -0.0197],\n",
      "        [ 0.0090,  0.0059,  0.0305,  ...,  0.0040,  0.0110, -0.0020]],\n",
      "       requires_grad=True))\n",
      "('blocks.3.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0155,  0.0100, -0.0212,  ..., -0.0113, -0.0038, -0.0055],\n",
      "        [-0.0464,  0.0217, -0.0088,  ..., -0.0074,  0.0154,  0.0160],\n",
      "        [ 0.0168,  0.0048, -0.0349,  ...,  0.0092, -0.0137, -0.0030],\n",
      "        ...,\n",
      "        [ 0.0234,  0.0033,  0.0282,  ...,  0.0031, -0.0023, -0.0020],\n",
      "        [ 0.0109, -0.0011, -0.0187,  ...,  0.0120, -0.0170, -0.0271],\n",
      "        [-0.0355,  0.0195,  0.0062,  ...,  0.0068,  0.0079,  0.0175]],\n",
      "       requires_grad=True))\n",
      "('blocks.3.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1655,  0.1308, -0.2498,  ..., -0.4021, -0.4958, -0.5630],\n",
      "       requires_grad=True))\n",
      "('blocks.3.norm2.weight', Parameter containing:\n",
      "tensor([0.6836, 0.8632, 0.7519,  ..., 0.4539, 0.8458, 0.7242],\n",
      "       requires_grad=True))\n",
      "('blocks.3.norm2.bias', Parameter containing:\n",
      "tensor([ 0.2040, -0.2776, -0.2188,  ..., -0.0460, -0.0017, -0.0583],\n",
      "       requires_grad=True))\n",
      "('blocks.3.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0076, -0.0078, -0.0096,  ...,  0.0105,  0.0006, -0.0157],\n",
      "        [-0.0086, -0.0151, -0.0036,  ..., -0.0029,  0.0136,  0.0015],\n",
      "        [-0.0166, -0.0013, -0.0145,  ..., -0.0125, -0.0035, -0.0084],\n",
      "        ...,\n",
      "        [-0.0173,  0.0156, -0.0002,  ...,  0.0085,  0.0097,  0.0007],\n",
      "        [-0.0196, -0.0143,  0.0207,  ...,  0.0205, -0.0182, -0.0138],\n",
      "        [-0.0228, -0.0454, -0.0051,  ...,  0.0240, -0.0155,  0.0005]],\n",
      "       requires_grad=True))\n",
      "('blocks.3.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-1.1035, -0.8267, -0.6440,  ..., -0.7168, -0.6006, -0.9698],\n",
      "       requires_grad=True))\n",
      "('blocks.3.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0051,  0.0238, -0.0134,  ...,  0.0146,  0.0082,  0.0044],\n",
      "        [ 0.0016,  0.0082, -0.0194,  ...,  0.0168,  0.0068, -0.0104],\n",
      "        [-0.0189,  0.0075,  0.0073,  ..., -0.0121,  0.0137, -0.0075],\n",
      "        ...,\n",
      "        [-0.0138, -0.0023,  0.0071,  ..., -0.0039, -0.0127,  0.0137],\n",
      "        [-0.0038, -0.0038,  0.0065,  ..., -0.0125, -0.0004, -0.0283],\n",
      "        [-0.0195,  0.0030,  0.0185,  ..., -0.0127,  0.0264, -0.0048]],\n",
      "       requires_grad=True))\n",
      "('blocks.3.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.1052, -0.5215,  0.2353,  ...,  0.0621,  0.0499,  0.3188],\n",
      "       requires_grad=True))\n",
      "('blocks.4.norm1.weight', Parameter containing:\n",
      "tensor([0.7363, 0.9302, 0.9043,  ..., 0.6381, 0.9717, 0.7848],\n",
      "       requires_grad=True))\n",
      "('blocks.4.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0590, -0.1354, -0.2542,  ..., -0.0307,  0.1042, -0.2397],\n",
      "       requires_grad=True))\n",
      "('blocks.4.attn.q_bias', Parameter containing:\n",
      "tensor([-0.0205, -0.7842, -0.2427,  ...,  0.5792, -0.0345,  0.2774],\n",
      "       requires_grad=True))\n",
      "('blocks.4.attn.v_bias', Parameter containing:\n",
      "tensor([0.0965, 0.0565, 0.0123,  ..., 0.0559, 0.1323, 0.0172],\n",
      "       requires_grad=True))\n",
      "('blocks.4.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0035, -0.0043, -0.0016,  ...,  0.0022,  0.0119,  0.0063],\n",
      "        [-0.0007, -0.0020,  0.0084,  ...,  0.0021,  0.0073,  0.0069],\n",
      "        [ 0.0057, -0.0091,  0.0003,  ...,  0.0088,  0.0054,  0.0010],\n",
      "        ...,\n",
      "        [-0.0133, -0.0011,  0.0069,  ..., -0.0033, -0.0031, -0.0122],\n",
      "        [-0.0172,  0.0058, -0.0087,  ..., -0.0143, -0.0029,  0.0275],\n",
      "        [-0.0016, -0.0149, -0.0128,  ..., -0.0017,  0.0018, -0.0057]],\n",
      "       requires_grad=True))\n",
      "('blocks.4.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0109,  0.0166,  0.0064,  ...,  0.0052,  0.0536, -0.0013],\n",
      "        [ 0.0219,  0.0022,  0.0132,  ...,  0.0072, -0.0384, -0.0094],\n",
      "        [ 0.0213,  0.0182,  0.0241,  ..., -0.0260,  0.0001,  0.0122],\n",
      "        ...,\n",
      "        [-0.0154, -0.0085,  0.0110,  ...,  0.0229,  0.0235, -0.0097],\n",
      "        [-0.0265, -0.0108, -0.0091,  ...,  0.0132,  0.0054, -0.0182],\n",
      "        [ 0.0131, -0.0093,  0.0062,  ...,  0.0072, -0.0655,  0.0017]],\n",
      "       requires_grad=True))\n",
      "('blocks.4.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1458, -0.1226, -0.4399,  ..., -0.1340,  0.0019, -0.1700],\n",
      "       requires_grad=True))\n",
      "('blocks.4.norm2.weight', Parameter containing:\n",
      "tensor([0.8530, 1.0820, 0.9203,  ..., 0.7344, 1.1123, 0.8569],\n",
      "       requires_grad=True))\n",
      "('blocks.4.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0914, -0.1605,  0.1201,  ...,  0.0955,  0.1349,  0.0294],\n",
      "       requires_grad=True))\n",
      "('blocks.4.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0166,  0.0067,  0.0011,  ...,  0.0059, -0.0099,  0.0166],\n",
      "        [-0.0088, -0.0077,  0.0114,  ..., -0.0028,  0.0032, -0.0349],\n",
      "        [ 0.0075, -0.0285,  0.0068,  ...,  0.0097, -0.0070, -0.0027],\n",
      "        ...,\n",
      "        [-0.0134,  0.0135,  0.0034,  ...,  0.0018,  0.0059, -0.0069],\n",
      "        [ 0.0069,  0.0158, -0.0024,  ..., -0.0134, -0.0052, -0.0307],\n",
      "        [-0.0037,  0.0034, -0.0005,  ..., -0.0008,  0.0011, -0.0052]],\n",
      "       requires_grad=True))\n",
      "('blocks.4.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.8677, -0.6650, -0.8355,  ..., -0.6220, -0.7261, -1.0186],\n",
      "       requires_grad=True))\n",
      "('blocks.4.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 6.6990e-04, -3.4181e-03,  1.8762e-02,  ..., -1.9060e-02,\n",
      "          4.2094e-03,  1.0103e-03],\n",
      "        [ 1.1792e-02,  2.9783e-02, -3.7315e-03,  ..., -7.2022e-03,\n",
      "         -1.2514e-02,  2.8550e-03],\n",
      "        [-1.0187e-02,  1.3913e-02,  4.7267e-03,  ...,  7.7426e-03,\n",
      "         -1.4603e-02,  2.5115e-06],\n",
      "        ...,\n",
      "        [-3.3358e-03,  1.4008e-02,  8.5069e-03,  ..., -2.3889e-02,\n",
      "          2.5185e-02, -8.1158e-04],\n",
      "        [-4.3853e-03,  2.7340e-02, -6.2133e-03,  ..., -1.0108e-02,\n",
      "         -2.3189e-02,  3.8472e-04],\n",
      "        [ 7.3509e-03,  3.5588e-02,  1.0388e-02,  ...,  2.0831e-02,\n",
      "          4.6059e-03, -2.8873e-04]], requires_grad=True))\n",
      "('blocks.4.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0088, -0.3467, -0.0248,  ..., -0.1599, -0.0669,  0.0146],\n",
      "       requires_grad=True))\n",
      "('blocks.5.norm1.weight', Parameter containing:\n",
      "tensor([0.7909, 0.9176, 0.8740,  ..., 0.7480, 1.0030, 0.8218],\n",
      "       requires_grad=True))\n",
      "('blocks.5.norm1.bias', Parameter containing:\n",
      "tensor([-0.0136,  0.0294,  0.0995,  ...,  0.1076,  0.0952, -0.1071],\n",
      "       requires_grad=True))\n",
      "('blocks.5.attn.q_bias', Parameter containing:\n",
      "tensor([-0.3455, -0.2540,  0.2472,  ...,  0.2106,  0.0545, -2.2851],\n",
      "       requires_grad=True))\n",
      "('blocks.5.attn.v_bias', Parameter containing:\n",
      "tensor([-0.1622, -0.0169, -0.1089,  ...,  0.0097, -0.1629, -0.0119],\n",
      "       requires_grad=True))\n",
      "('blocks.5.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0179, -0.0018, -0.0100,  ..., -0.0011,  0.0071, -0.0056],\n",
      "        [ 0.0005,  0.0009, -0.0060,  ...,  0.0134,  0.0074,  0.0072],\n",
      "        [ 0.0150,  0.0082, -0.0108,  ..., -0.0040,  0.0096, -0.0002],\n",
      "        ...,\n",
      "        [-0.0066, -0.0050, -0.0120,  ..., -0.0008, -0.0091,  0.0221],\n",
      "        [-0.0092,  0.0085, -0.0135,  ...,  0.0034, -0.0213, -0.0074],\n",
      "        [ 0.0111,  0.0012,  0.0192,  ..., -0.0062,  0.0024,  0.0075]],\n",
      "       requires_grad=True))\n",
      "('blocks.5.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0001, -0.0022,  0.0102,  ...,  0.0010,  0.0125, -0.0209],\n",
      "        [ 0.0053,  0.0173, -0.0069,  ..., -0.0051,  0.0011, -0.0015],\n",
      "        [-0.0003,  0.0047,  0.0237,  ..., -0.0009,  0.0163, -0.0165],\n",
      "        ...,\n",
      "        [ 0.0041, -0.0009,  0.0109,  ...,  0.0021, -0.0168,  0.0009],\n",
      "        [ 0.0066, -0.0043,  0.0077,  ...,  0.0098,  0.0149, -0.0049],\n",
      "        [ 0.0022,  0.0048, -0.0118,  ..., -0.0170, -0.0170, -0.0093]],\n",
      "       requires_grad=True))\n",
      "('blocks.5.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0476, -0.0169, -0.0583,  ..., -0.3544, -0.0322, -0.1225],\n",
      "       requires_grad=True))\n",
      "('blocks.5.norm2.weight', Parameter containing:\n",
      "tensor([1.0029, 1.1269, 0.9790,  ..., 1.0136, 1.2745, 1.0518],\n",
      "       requires_grad=True))\n",
      "('blocks.5.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0208, -0.0739,  0.0551,  ...,  0.3534,  0.0900,  0.0553],\n",
      "       requires_grad=True))\n",
      "('blocks.5.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0007,  0.0014,  0.0021,  ..., -0.0031,  0.0015, -0.0044],\n",
      "        [-0.0061,  0.0034,  0.0017,  ..., -0.0094,  0.0199, -0.0080],\n",
      "        [-0.0010,  0.0019,  0.0021,  ...,  0.0032, -0.0214,  0.0070],\n",
      "        ...,\n",
      "        [-0.0047, -0.0096,  0.0183,  ...,  0.0001, -0.0137,  0.0107],\n",
      "        [-0.0024, -0.0156,  0.0170,  ...,  0.0101, -0.0062, -0.0206],\n",
      "        [ 0.0164,  0.0304, -0.0061,  ...,  0.0004, -0.0064, -0.0240]],\n",
      "       requires_grad=True))\n",
      "('blocks.5.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.5352, -0.6563, -0.7193,  ..., -0.7095, -1.5723, -0.5948],\n",
      "       requires_grad=True))\n",
      "('blocks.5.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0039, -0.0056, -0.0099,  ...,  0.0106,  0.0383, -0.0129],\n",
      "        [ 0.0041,  0.0010, -0.0207,  ...,  0.0015,  0.0088, -0.0374],\n",
      "        [-0.0049, -0.0117, -0.0103,  ...,  0.0014,  0.0142,  0.0093],\n",
      "        ...,\n",
      "        [-0.0036,  0.0049, -0.0111,  ...,  0.0207, -0.0140, -0.0180],\n",
      "        [-0.0012,  0.0173, -0.0020,  ...,  0.0295, -0.0083,  0.0114],\n",
      "        [-0.0048,  0.0093, -0.0100,  ..., -0.0258, -0.0020,  0.0286]],\n",
      "       requires_grad=True))\n",
      "('blocks.5.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0130, -0.1940, -0.0424,  ...,  0.0183,  0.0523,  0.0899],\n",
      "       requires_grad=True))\n",
      "('blocks.6.norm1.weight', Parameter containing:\n",
      "tensor([0.8438, 0.8106, 0.9648,  ..., 0.8735, 0.9800, 0.9301],\n",
      "       requires_grad=True))\n",
      "('blocks.6.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0175,  0.0736,  0.1311,  ...,  0.3081, -0.0233, -0.0490],\n",
      "       requires_grad=True))\n",
      "('blocks.6.attn.q_bias', Parameter containing:\n",
      "tensor([-0.5171,  0.2197,  0.6528,  ...,  0.3669, -0.0420,  0.3262],\n",
      "       requires_grad=True))\n",
      "('blocks.6.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0446,  0.0050,  0.0653,  ..., -0.0341, -0.0234, -0.0060],\n",
      "       requires_grad=True))\n",
      "('blocks.6.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-1.6779e-02,  2.3301e-02, -3.0385e-03,  ..., -1.0557e-03,\n",
      "         -2.7437e-03, -2.3242e-03],\n",
      "        [-2.4502e-04,  2.0448e-02, -5.4511e-03,  ...,  1.1040e-02,\n",
      "          1.7580e-02,  9.2104e-03],\n",
      "        [ 5.6359e-03, -3.2306e-02, -2.8881e-03,  ...,  2.1800e-03,\n",
      "         -6.6196e-03, -1.7409e-03],\n",
      "        ...,\n",
      "        [ 9.6142e-03, -3.9728e-03,  4.3052e-03,  ...,  1.1882e-02,\n",
      "         -1.1768e-02, -3.8474e-05],\n",
      "        [ 9.7810e-03, -2.1482e-02, -1.5920e-02,  ..., -8.4577e-03,\n",
      "         -2.7720e-02,  2.8290e-02],\n",
      "        [-1.2912e-02, -1.3057e-02, -1.0197e-02,  ...,  2.9188e-02,\n",
      "          9.6336e-03,  1.7753e-02]], requires_grad=True))\n",
      "('blocks.6.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0208,  0.0235, -0.0196,  ..., -0.0099, -0.0052,  0.0019],\n",
      "        [-0.0052, -0.0091, -0.0142,  ...,  0.0014,  0.0124,  0.0194],\n",
      "        [ 0.0057, -0.0048,  0.0102,  ..., -0.0140,  0.0103,  0.0158],\n",
      "        ...,\n",
      "        [-0.0015, -0.0012,  0.0066,  ..., -0.0097,  0.0030, -0.0299],\n",
      "        [-0.0111, -0.0055, -0.0163,  ..., -0.0079,  0.0103,  0.0117],\n",
      "        [ 0.0062,  0.0102, -0.0218,  ...,  0.0127, -0.0223, -0.0116]],\n",
      "       requires_grad=True))\n",
      "('blocks.6.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.4273,  0.0425, -0.1787,  ..., -0.1361, -0.0787, -0.5254],\n",
      "       requires_grad=True))\n",
      "('blocks.6.norm2.weight', Parameter containing:\n",
      "tensor([1.1553, 1.1094, 1.0966,  ..., 1.1132, 1.2479, 1.1337],\n",
      "       requires_grad=True))\n",
      "('blocks.6.norm2.bias', Parameter containing:\n",
      "tensor([-0.2773, -0.0504,  0.2272,  ...,  0.5415, -0.0124,  0.3944],\n",
      "       requires_grad=True))\n",
      "('blocks.6.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-2.1030e-03,  1.6095e-02, -2.4633e-03,  ...,  1.7518e-02,\n",
      "          2.3579e-03,  2.6470e-02],\n",
      "        [-1.6451e-02,  8.5894e-03, -4.3297e-03,  ...,  1.0846e-02,\n",
      "          2.9816e-03, -2.7138e-02],\n",
      "        [ 2.8142e-02, -1.5029e-02,  1.6963e-03,  ..., -8.1264e-03,\n",
      "          2.2328e-03,  1.4561e-02],\n",
      "        ...,\n",
      "        [ 8.7709e-03, -2.3390e-03, -1.6700e-03,  ..., -3.1354e-02,\n",
      "         -1.1560e-02, -7.6787e-03],\n",
      "        [ 4.5492e-03, -2.0219e-02,  6.9649e-06,  ..., -1.5809e-02,\n",
      "         -3.4745e-02,  8.6848e-03],\n",
      "        [ 6.8328e-03,  1.5324e-02,  5.1405e-03,  ...,  1.2737e-02,\n",
      "         -2.0799e-03, -1.2394e-02]], requires_grad=True))\n",
      "('blocks.6.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.6817, -0.4246, -0.8300,  ..., -0.6130, -0.7568, -0.5649],\n",
      "       requires_grad=True))\n",
      "('blocks.6.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0123,  0.0004, -0.0164,  ..., -0.0032, -0.0102, -0.0184],\n",
      "        [ 0.0101,  0.0067, -0.0035,  ..., -0.0075, -0.0304,  0.0185],\n",
      "        [ 0.0123,  0.0006,  0.0078,  ..., -0.0066, -0.0063, -0.0106],\n",
      "        ...,\n",
      "        [-0.0153, -0.0173,  0.0043,  ...,  0.0331,  0.0063,  0.0033],\n",
      "        [ 0.0224,  0.0089, -0.0017,  ...,  0.0048,  0.0077, -0.0098],\n",
      "        [ 0.0130,  0.0102, -0.0386,  ...,  0.0045,  0.0028,  0.0040]],\n",
      "       requires_grad=True))\n",
      "('blocks.6.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.1783, -0.1051, -0.0489,  ..., -0.0830,  0.2237,  0.2042],\n",
      "       requires_grad=True))\n",
      "('blocks.7.norm1.weight', Parameter containing:\n",
      "tensor([0.9351, 0.8219, 0.9477,  ..., 0.9159, 0.8569, 0.8695],\n",
      "       requires_grad=True))\n",
      "('blocks.7.norm1.bias', Parameter containing:\n",
      "tensor([-0.1777,  0.0502,  0.1961,  ...,  0.3787, -0.1143,  0.2500],\n",
      "       requires_grad=True))\n",
      "('blocks.7.attn.q_bias', Parameter containing:\n",
      "tensor([-0.0637,  0.0126, -0.1125,  ...,  0.5342,  0.1387, -0.2078],\n",
      "       requires_grad=True))\n",
      "('blocks.7.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0957,  0.3057, -0.0875,  ...,  0.1256, -0.0387, -0.0339],\n",
      "       requires_grad=True))\n",
      "('blocks.7.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0007,  0.0049,  0.0091,  ..., -0.0122,  0.0146,  0.0027],\n",
      "        [ 0.0047,  0.0030,  0.0067,  ...,  0.0084,  0.0117,  0.0006],\n",
      "        [-0.0121,  0.0040,  0.0047,  ...,  0.0059,  0.0170, -0.0179],\n",
      "        ...,\n",
      "        [-0.0287, -0.0125,  0.0016,  ...,  0.0121,  0.0042, -0.0053],\n",
      "        [-0.0105, -0.0117, -0.0162,  ..., -0.0220, -0.0126, -0.0170],\n",
      "        [-0.0156, -0.0389,  0.0346,  ...,  0.0009,  0.0095, -0.0084]],\n",
      "       requires_grad=True))\n",
      "('blocks.7.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0256,  0.0258, -0.0298,  ..., -0.0026,  0.0212,  0.0071],\n",
      "        [ 0.0045, -0.0019, -0.0214,  ...,  0.0008,  0.0072, -0.0072],\n",
      "        [ 0.0133,  0.0106,  0.0046,  ..., -0.0022, -0.0242,  0.0192],\n",
      "        ...,\n",
      "        [ 0.0240, -0.0268, -0.0119,  ..., -0.0083,  0.0375, -0.0053],\n",
      "        [-0.0063, -0.0361, -0.0004,  ..., -0.0016,  0.0341, -0.0069],\n",
      "        [ 0.0074,  0.0018, -0.0209,  ..., -0.0143,  0.0077,  0.0024]],\n",
      "       requires_grad=True))\n",
      "('blocks.7.attn.proj.bias', Parameter containing:\n",
      "tensor([-0.1333, -0.2170,  0.0640,  ...,  0.5356,  0.1115, -0.0567],\n",
      "       requires_grad=True))\n",
      "('blocks.7.norm2.weight', Parameter containing:\n",
      "tensor([1.2627, 1.1846, 1.1583,  ..., 1.4414, 1.4189, 1.2627],\n",
      "       requires_grad=True))\n",
      "('blocks.7.norm2.bias', Parameter containing:\n",
      "tensor([-0.1200,  0.1446,  0.2909,  ...,  0.0819, -0.3246,  0.2159],\n",
      "       requires_grad=True))\n",
      "('blocks.7.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0007,  0.0018, -0.0006,  ..., -0.0011,  0.0009,  0.0021],\n",
      "        [ 0.0014,  0.0024, -0.0003,  ..., -0.0004,  0.0013,  0.0032],\n",
      "        [-0.0063, -0.0020,  0.0010,  ...,  0.0005, -0.0143,  0.0155],\n",
      "        ...,\n",
      "        [-0.0181,  0.0096,  0.0024,  ..., -0.0164, -0.0003, -0.0017],\n",
      "        [ 0.0138, -0.0281, -0.0081,  ..., -0.0076, -0.0057, -0.0108],\n",
      "        [ 0.0021,  0.0329, -0.0061,  ...,  0.0210,  0.0072, -0.0151]],\n",
      "       requires_grad=True))\n",
      "('blocks.7.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.5023, -0.3783, -0.7026,  ..., -0.4197, -0.5898, -0.7772],\n",
      "       requires_grad=True))\n",
      "('blocks.7.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0012,  0.0020, -0.0049,  ...,  0.0007, -0.0018, -0.0083],\n",
      "        [ 0.0018, -0.0006,  0.0055,  ...,  0.0004,  0.0161,  0.0119],\n",
      "        [-0.0003, -0.0004, -0.0109,  ..., -0.0084,  0.0030,  0.0045],\n",
      "        ...,\n",
      "        [-0.0006,  0.0005,  0.0118,  ...,  0.0043,  0.0140,  0.0141],\n",
      "        [ 0.0004,  0.0016,  0.0065,  ..., -0.0086, -0.0053,  0.0211],\n",
      "        [ 0.0008,  0.0025, -0.0040,  ..., -0.0062,  0.0210,  0.0043]],\n",
      "       requires_grad=True))\n",
      "('blocks.7.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.2905, -0.1093, -0.0437,  ..., -0.2225,  0.0823,  0.1545],\n",
      "       requires_grad=True))\n",
      "('blocks.8.norm1.weight', Parameter containing:\n",
      "tensor([1.0029, 0.8926, 1.0293,  ..., 1.3457, 0.9727, 1.2694],\n",
      "       requires_grad=True))\n",
      "('blocks.8.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0046,  0.1574,  0.2041,  ...,  0.1328, -0.2191,  0.2627],\n",
      "       requires_grad=True))\n",
      "('blocks.8.attn.q_bias', Parameter containing:\n",
      "tensor([-0.1084, -0.4211,  0.4740,  ..., -0.0582, -0.0100, -0.4851],\n",
      "       requires_grad=True))\n",
      "('blocks.8.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0169,  0.0014, -0.0415,  ...,  0.0295,  0.0118, -0.0008],\n",
      "       requires_grad=True))\n",
      "('blocks.8.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-2.8174e-03, -1.0030e-02, -8.7917e-04,  ..., -4.5553e-03,\n",
      "         -1.0820e-02,  3.8397e-03],\n",
      "        [-6.9439e-03, -3.2089e-03,  1.9222e-05,  ..., -6.7329e-03,\n",
      "          1.0661e-02, -8.1285e-03],\n",
      "        [ 5.3048e-03,  3.3688e-03,  6.8593e-03,  ..., -3.2209e-03,\n",
      "         -2.0333e-03,  1.9943e-02],\n",
      "        ...,\n",
      "        [-1.1176e-02, -6.3530e-03, -4.9460e-03,  ..., -3.1594e-03,\n",
      "         -3.0984e-03,  6.2251e-03],\n",
      "        [-2.8617e-02,  5.5021e-03, -1.0349e-02,  ..., -4.3262e-03,\n",
      "         -3.7285e-03,  8.9975e-04],\n",
      "        [-7.0012e-05, -2.7998e-03, -3.0137e-03,  ...,  1.5897e-02,\n",
      "         -2.8220e-02,  1.1695e-02]], requires_grad=True))\n",
      "('blocks.8.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 3.7399e-03, -1.5461e-02, -2.3308e-02,  ..., -1.2159e-02,\n",
      "          4.1758e-03,  7.1235e-03],\n",
      "        [ 1.2839e-02,  2.9927e-03, -2.4587e-02,  ...,  9.2216e-03,\n",
      "          5.3966e-04,  9.2970e-05],\n",
      "        [ 1.9576e-03, -1.6358e-02,  2.4865e-03,  ..., -1.0611e-03,\n",
      "          1.7096e-02,  6.8641e-04],\n",
      "        ...,\n",
      "        [ 1.9918e-02, -1.6833e-02, -1.3502e-02,  ..., -7.8963e-03,\n",
      "          1.3899e-02, -1.4820e-02],\n",
      "        [ 3.4956e-02,  3.6171e-02,  1.5232e-02,  ..., -2.4754e-03,\n",
      "         -6.5971e-03,  1.0859e-02],\n",
      "        [-1.1277e-02,  1.0306e-02, -2.9947e-02,  ...,  2.0282e-02,\n",
      "         -2.5344e-02, -1.1402e-02]], requires_grad=True))\n",
      "('blocks.8.attn.proj.bias', Parameter containing:\n",
      "tensor([-0.1416, -0.1174,  0.3753,  ...,  0.4248, -0.0591, -0.0140],\n",
      "       requires_grad=True))\n",
      "('blocks.8.norm2.weight', Parameter containing:\n",
      "tensor([1.2793, 1.0058, 1.1271,  ..., 1.6709, 1.2090, 1.3252],\n",
      "       requires_grad=True))\n",
      "('blocks.8.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0612,  0.2033,  0.1624,  ..., -0.1833, -0.2275,  0.2163],\n",
      "       requires_grad=True))\n",
      "('blocks.8.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 1.2754e-03,  1.9218e-03, -1.7657e-03,  ..., -1.7884e-03,\n",
      "          6.5439e-05,  1.5786e-03],\n",
      "        [ 1.3564e-03,  2.0407e-03, -1.8263e-03,  ..., -1.8894e-03,\n",
      "          5.3574e-05,  1.6874e-03],\n",
      "        [ 2.6650e-03,  1.8179e-03, -1.7323e-02,  ..., -8.5320e-03,\n",
      "          2.1652e-02, -1.5157e-02],\n",
      "        ...,\n",
      "        [ 2.6395e-03,  3.1390e-02, -1.0493e-03,  ...,  9.7420e-04,\n",
      "          2.0111e-02, -9.2933e-03],\n",
      "        [-3.6403e-03, -2.7747e-03,  8.0074e-03,  ..., -2.1710e-02,\n",
      "          2.3719e-02,  9.4232e-03],\n",
      "        [-1.5144e-03, -2.0508e-02,  2.0722e-03,  ..., -3.3477e-02,\n",
      "          4.2571e-03,  1.3682e-02]], requires_grad=True))\n",
      "('blocks.8.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.6479, -0.5336, -0.2662,  ..., -0.5893, -0.6652, -0.5962],\n",
      "       requires_grad=True))\n",
      "('blocks.8.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-1.2986e-05, -5.4704e-05, -8.3133e-03,  ..., -1.6901e-02,\n",
      "         -6.5552e-03, -4.6463e-03],\n",
      "        [ 1.2203e-03,  1.3058e-03, -3.4963e-03,  ...,  4.5587e-03,\n",
      "         -2.6685e-02, -7.8671e-03],\n",
      "        [-5.9360e-04, -6.0373e-04,  1.2022e-02,  ..., -6.8219e-03,\n",
      "         -1.5861e-02, -1.2322e-02],\n",
      "        ...,\n",
      "        [-1.1852e-03, -1.2491e-03,  1.4192e-02,  ...,  1.0765e-02,\n",
      "         -9.5228e-03,  1.3404e-02],\n",
      "        [ 2.6578e-04,  2.5892e-04, -1.3292e-02,  ...,  1.2270e-02,\n",
      "          7.8515e-03, -6.3276e-03],\n",
      "        [ 1.8214e-04,  1.4840e-04,  8.4268e-03,  ..., -1.0069e-02,\n",
      "          1.0237e-02,  1.2549e-02]], requires_grad=True))\n",
      "('blocks.8.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.2360,  0.1172, -0.1374,  ..., -0.0688, -0.0008,  0.1804],\n",
      "       requires_grad=True))\n",
      "('blocks.9.norm1.weight', Parameter containing:\n",
      "tensor([1.1143, 0.7617, 0.9385,  ..., 1.4208, 0.8951, 1.2910],\n",
      "       requires_grad=True))\n",
      "('blocks.9.norm1.bias', Parameter containing:\n",
      "tensor([ 0.2620,  0.0975, -0.0056,  ..., -0.0894, -0.1780,  0.1137],\n",
      "       requires_grad=True))\n",
      "('blocks.9.attn.q_bias', Parameter containing:\n",
      "tensor([-0.2151, -0.1228, -0.4415,  ...,  0.2137,  0.2834, -0.5727],\n",
      "       requires_grad=True))\n",
      "('blocks.9.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0464, -0.0760, -0.1642,  ..., -0.0971,  0.1056,  0.0643],\n",
      "       requires_grad=True))\n",
      "('blocks.9.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0007,  0.0033,  0.0011,  ..., -0.0051, -0.0002, -0.0011],\n",
      "        [-0.0057,  0.0052, -0.0176,  ..., -0.0016, -0.0122, -0.0030],\n",
      "        [ 0.0130,  0.0022, -0.0072,  ...,  0.0032,  0.0044, -0.0001],\n",
      "        ...,\n",
      "        [-0.0213, -0.0026, -0.0050,  ...,  0.0118,  0.0049, -0.0061],\n",
      "        [ 0.0126,  0.0024, -0.0004,  ..., -0.0102,  0.0266, -0.0010],\n",
      "        [ 0.0042, -0.0155,  0.0200,  ...,  0.0003,  0.0038,  0.0031]],\n",
      "       requires_grad=True))\n",
      "('blocks.9.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 1.0813e-02,  1.9214e-02, -7.1164e-03,  ...,  2.2609e-02,\n",
      "         -5.9537e-03, -1.1975e-02],\n",
      "        [ 1.0184e-03,  1.4683e-02,  1.2367e-02,  ...,  9.9196e-04,\n",
      "          5.5459e-03,  7.0774e-03],\n",
      "        [ 5.9189e-04, -3.2104e-03, -2.9095e-02,  ..., -3.5094e-03,\n",
      "         -6.5593e-03, -2.0895e-02],\n",
      "        ...,\n",
      "        [ 2.8226e-02, -2.8506e-02,  7.4222e-03,  ..., -1.2299e-02,\n",
      "          1.8379e-02, -1.8430e-02],\n",
      "        [ 3.4714e-03, -1.8548e-02,  8.8588e-03,  ..., -1.9270e-02,\n",
      "         -3.8827e-02,  3.2855e-03],\n",
      "        [ 1.6339e-02,  9.9900e-03,  1.8974e-05,  ...,  1.2957e-02,\n",
      "          1.7223e-02, -1.8766e-02]], requires_grad=True))\n",
      "('blocks.9.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1988, -0.0844,  0.2478,  ...,  0.0011, -0.2693, -0.0833],\n",
      "       requires_grad=True))\n",
      "('blocks.9.norm2.weight', Parameter containing:\n",
      "tensor([1.4482, 1.0195, 1.1388,  ..., 1.8388, 1.3009, 1.5986],\n",
      "       requires_grad=True))\n",
      "('blocks.9.norm2.bias', Parameter containing:\n",
      "tensor([ 0.1336,  0.1816, -0.0377,  ...,  0.1619, -0.0422,  0.1990],\n",
      "       requires_grad=True))\n",
      "('blocks.9.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 1.0679e-02,  7.2717e-03, -7.1650e-03,  ..., -1.4525e-02,\n",
      "         -4.1033e-02, -4.6627e-03],\n",
      "        [ 3.2196e-05, -2.9906e-02,  9.8265e-04,  ..., -1.0966e-02,\n",
      "          5.4687e-03, -5.1039e-03],\n",
      "        [ 6.7825e-03,  1.0877e-02, -4.8790e-03,  ..., -4.2888e-03,\n",
      "         -6.5587e-03,  3.3961e-02],\n",
      "        ...,\n",
      "        [ 4.3509e-04,  6.0769e-04, -1.8768e-03,  ..., -5.5917e-03,\n",
      "          1.5674e-04, -3.1415e-04],\n",
      "        [ 4.2381e-04,  6.1171e-04, -1.8755e-03,  ..., -5.5624e-03,\n",
      "          1.6843e-04, -3.1972e-04],\n",
      "        [ 1.6754e-03,  1.7909e-02,  1.0688e-02,  ..., -1.0342e-02,\n",
      "         -2.8287e-03,  5.8769e-03]], requires_grad=True))\n",
      "('blocks.9.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.6493, -0.3415, -0.9028,  ..., -0.5975, -0.6101, -0.4632],\n",
      "       requires_grad=True))\n",
      "('blocks.9.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0071, -0.0034, -0.0034,  ..., -0.0004, -0.0004,  0.0006],\n",
      "        [ 0.0010, -0.0029, -0.0002,  ...,  0.0012,  0.0012, -0.0334],\n",
      "        [-0.0109,  0.0099,  0.0067,  ..., -0.0003, -0.0003,  0.0118],\n",
      "        ...,\n",
      "        [ 0.0081, -0.0088,  0.0156,  ..., -0.0023, -0.0023,  0.0235],\n",
      "        [-0.0052,  0.0184, -0.0142,  ...,  0.0002,  0.0002,  0.0038],\n",
      "        [-0.0153,  0.0033,  0.0074,  ..., -0.0006, -0.0006,  0.0031]],\n",
      "       requires_grad=True))\n",
      "('blocks.9.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.1740,  0.1383, -0.1624,  ..., -0.1269,  0.0969,  0.2326],\n",
      "       requires_grad=True))\n",
      "('blocks.10.norm1.weight', Parameter containing:\n",
      "tensor([1.2764, 0.7599, 1.0363,  ..., 1.8555, 0.9598, 1.5460],\n",
      "       requires_grad=True))\n",
      "('blocks.10.norm1.bias', Parameter containing:\n",
      "tensor([ 0.3157,  0.1213, -0.0660,  ...,  0.0307, -0.1170,  0.0746],\n",
      "       requires_grad=True))\n",
      "('blocks.10.attn.q_bias', Parameter containing:\n",
      "tensor([-0.0696, -0.0998,  0.2967,  ..., -0.3521,  0.0125,  0.9668],\n",
      "       requires_grad=True))\n",
      "('blocks.10.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0046, -0.0604, -0.0985,  ...,  0.0501, -0.0011, -0.0397],\n",
      "       requires_grad=True))\n",
      "('blocks.10.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0135,  0.0039, -0.0010,  ..., -0.0163,  0.0027,  0.0056],\n",
      "        [ 0.0031, -0.0013, -0.0127,  ...,  0.0012,  0.0007,  0.0024],\n",
      "        [ 0.0155, -0.0092, -0.0111,  ...,  0.0031, -0.0137,  0.0015],\n",
      "        ...,\n",
      "        [-0.0097,  0.0004, -0.0047,  ...,  0.0018, -0.0070, -0.0041],\n",
      "        [ 0.0036,  0.0046,  0.0142,  ..., -0.0196,  0.0096, -0.0154],\n",
      "        [-0.0069,  0.0162,  0.0024,  ..., -0.0260, -0.0009,  0.0545]],\n",
      "       requires_grad=True))\n",
      "('blocks.10.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0329,  0.0015,  0.0062,  ..., -0.0126, -0.0290,  0.0368],\n",
      "        [ 0.0175,  0.0034, -0.0050,  ...,  0.0112, -0.0131, -0.0104],\n",
      "        [-0.0110,  0.0023, -0.0009,  ...,  0.0049, -0.0203, -0.0082],\n",
      "        ...,\n",
      "        [-0.0046,  0.0308,  0.0089,  ...,  0.0010,  0.0044,  0.0299],\n",
      "        [ 0.0019,  0.0060,  0.0209,  ...,  0.0045,  0.0042,  0.0175],\n",
      "        [ 0.0070,  0.0068,  0.0014,  ...,  0.0022, -0.0082, -0.0050]],\n",
      "       requires_grad=True))\n",
      "('blocks.10.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1265, -0.0017,  0.5693,  ..., -0.1869, -0.2728,  0.1443],\n",
      "       requires_grad=True))\n",
      "('blocks.10.norm2.weight', Parameter containing:\n",
      "tensor([1.3925, 0.9316, 1.1172,  ..., 1.9707, 1.3155, 1.4785],\n",
      "       requires_grad=True))\n",
      "('blocks.10.norm2.bias', Parameter containing:\n",
      "tensor([ 0.2432,  0.1578, -0.3582,  ...,  0.4055,  0.0145,  0.0290],\n",
      "       requires_grad=True))\n",
      "('blocks.10.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0007,  0.0006, -0.0019,  ..., -0.0033,  0.0007, -0.0022],\n",
      "        [-0.0007,  0.0007, -0.0021,  ..., -0.0034,  0.0007, -0.0023],\n",
      "        [-0.0019,  0.0024,  0.0230,  ...,  0.0027, -0.0078, -0.0082],\n",
      "        ...,\n",
      "        [-0.0141,  0.0070,  0.0161,  ...,  0.0279, -0.0232, -0.0091],\n",
      "        [ 0.0177,  0.0100,  0.0007,  ...,  0.0106,  0.0450,  0.0010],\n",
      "        [ 0.0003,  0.0010, -0.0019,  ..., -0.0057, -0.0020, -0.0026]],\n",
      "       requires_grad=True))\n",
      "('blocks.10.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.5473, -0.4287, -0.6055,  ..., -0.6919, -0.4879, -0.3278],\n",
      "       requires_grad=True))\n",
      "('blocks.10.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0003, -0.0003, -0.0007,  ...,  0.0256,  0.0042,  0.0005],\n",
      "        [ 0.0012,  0.0013, -0.0076,  ..., -0.0088, -0.0024,  0.0009],\n",
      "        [-0.0002, -0.0002, -0.0211,  ..., -0.0031,  0.0036,  0.0004],\n",
      "        ...,\n",
      "        [-0.0009, -0.0009, -0.0089,  ..., -0.0165, -0.0176, -0.0030],\n",
      "        [ 0.0005,  0.0005,  0.0026,  ...,  0.0180, -0.0376, -0.0011],\n",
      "        [-0.0005, -0.0007,  0.0186,  ...,  0.0124,  0.0027,  0.0003]],\n",
      "       requires_grad=True))\n",
      "('blocks.10.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0124,  0.0143, -0.2962,  ...,  0.0176,  0.0994,  0.0044],\n",
      "       requires_grad=True))\n",
      "('blocks.11.norm1.weight', Parameter containing:\n",
      "tensor([1.3535, 0.8798, 1.0165,  ..., 2.0977, 1.1143, 1.4522],\n",
      "       requires_grad=True))\n",
      "('blocks.11.norm1.bias', Parameter containing:\n",
      "tensor([ 0.2803,  0.1708, -0.4000,  ...,  0.2976,  0.0384, -0.1470],\n",
      "       requires_grad=True))\n",
      "('blocks.11.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.2036,  0.4199, -0.2633,  ...,  0.5449, -0.4099,  0.7529],\n",
      "       requires_grad=True))\n",
      "('blocks.11.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0083, -0.0657, -0.0235,  ..., -0.0964, -0.0143, -0.1061],\n",
      "       requires_grad=True))\n",
      "('blocks.11.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0056, -0.0020, -0.0017,  ...,  0.0025,  0.0133,  0.0203],\n",
      "        [-0.0010,  0.0030,  0.0090,  ..., -0.0029, -0.0065, -0.0013],\n",
      "        [-0.0060, -0.0047, -0.0059,  ...,  0.0026, -0.0005,  0.0058],\n",
      "        ...,\n",
      "        [-0.0021,  0.0063,  0.0163,  ...,  0.0065,  0.0078,  0.0095],\n",
      "        [-0.0084, -0.0088,  0.0141,  ..., -0.0214, -0.0181,  0.0083],\n",
      "        [-0.0001, -0.0128, -0.0258,  ...,  0.0329, -0.0214,  0.0088]],\n",
      "       requires_grad=True))\n",
      "('blocks.11.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0090,  0.0020, -0.0100,  ..., -0.0008,  0.0031, -0.0073],\n",
      "        [-0.0077,  0.0039,  0.0214,  ..., -0.0030,  0.0146,  0.0149],\n",
      "        [-0.0242, -0.0071, -0.0061,  ..., -0.0075, -0.0036,  0.0233],\n",
      "        ...,\n",
      "        [ 0.0040, -0.0035, -0.0096,  ..., -0.0077,  0.0093, -0.0227],\n",
      "        [ 0.0057,  0.0041,  0.0003,  ..., -0.0130,  0.0197,  0.0060],\n",
      "        [ 0.0356, -0.0157,  0.0004,  ..., -0.0153,  0.0074, -0.0147]],\n",
      "       requires_grad=True))\n",
      "('blocks.11.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.3279,  0.2392, -0.0377,  ...,  0.0965, -0.0168, -0.1127],\n",
      "       requires_grad=True))\n",
      "('blocks.11.norm2.weight', Parameter containing:\n",
      "tensor([1.6700, 1.1591, 1.2959,  ..., 2.2637, 1.5517, 1.7129],\n",
      "       requires_grad=True))\n",
      "('blocks.11.norm2.bias', Parameter containing:\n",
      "tensor([ 0.2050, -0.0894, -0.2744,  ...,  0.4633,  0.0819,  0.1956],\n",
      "       requires_grad=True))\n",
      "('blocks.11.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0061, -0.0167, -0.0060,  ...,  0.0193,  0.0105, -0.0210],\n",
      "        [-0.0068,  0.0211, -0.0062,  ..., -0.0061, -0.0182,  0.0026],\n",
      "        [-0.0143,  0.0136,  0.0252,  ..., -0.0103, -0.0089,  0.0183],\n",
      "        ...,\n",
      "        [ 0.0037, -0.0016,  0.0047,  ..., -0.0013,  0.0058, -0.0188],\n",
      "        [-0.0064,  0.0142,  0.0088,  ...,  0.0251,  0.0034, -0.0150],\n",
      "        [ 0.0403,  0.0044, -0.0098,  ...,  0.0177,  0.0001,  0.0218]],\n",
      "       requires_grad=True))\n",
      "('blocks.11.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.6865, -0.7904, -0.6543,  ..., -0.3677, -0.4894, -0.9364],\n",
      "       requires_grad=True))\n",
      "('blocks.11.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0141, -0.0240,  0.0326,  ..., -0.0048,  0.0026, -0.0168],\n",
      "        [ 0.0202, -0.0045, -0.0006,  ...,  0.0186,  0.0134, -0.0202],\n",
      "        [ 0.0083,  0.0024, -0.0050,  ..., -0.0041,  0.0030, -0.0117],\n",
      "        ...,\n",
      "        [-0.0062,  0.0259, -0.0008,  ..., -0.0080,  0.0404, -0.0029],\n",
      "        [-0.0201, -0.0227,  0.0228,  ...,  0.0010, -0.0101,  0.0197],\n",
      "        [-0.0088,  0.0319,  0.0192,  ..., -0.0078,  0.0064, -0.0224]],\n",
      "       requires_grad=True))\n",
      "('blocks.11.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0982, -0.0393, -0.2523,  ...,  0.0581,  0.1158, -0.0506],\n",
      "       requires_grad=True))\n",
      "('blocks.12.norm1.weight', Parameter containing:\n",
      "tensor([1.2668, 0.8726, 1.0021,  ..., 1.9834, 1.0781, 1.4445],\n",
      "       requires_grad=True))\n",
      "('blocks.12.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0986,  0.0543, -0.2749,  ...,  0.3243, -0.0501, -0.0636],\n",
      "       requires_grad=True))\n",
      "('blocks.12.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.0521,  0.1707,  1.8887,  ..., -0.0841,  0.6035, -0.0894],\n",
      "       requires_grad=True))\n",
      "('blocks.12.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0676, -0.0535,  0.0299,  ...,  0.0787, -0.0325,  0.0396],\n",
      "       requires_grad=True))\n",
      "('blocks.12.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0053,  0.0064,  0.0154,  ..., -0.0008,  0.0106,  0.0069],\n",
      "        [-0.0098,  0.0186,  0.0093,  ..., -0.0120,  0.0179,  0.0051],\n",
      "        [-0.0062, -0.0082, -0.0030,  ..., -0.0060,  0.0074, -0.0063],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0006, -0.0087,  ...,  0.0008, -0.0160, -0.0053],\n",
      "        [ 0.0100, -0.0132,  0.0010,  ..., -0.0110,  0.0006,  0.0069],\n",
      "        [ 0.0011,  0.0049, -0.0159,  ...,  0.0098, -0.0268, -0.0234]],\n",
      "       requires_grad=True))\n",
      "('blocks.12.attn.proj.weight', Parameter containing:\n",
      "tensor([[-9.6646e-03,  8.8635e-03,  2.3486e-02,  ...,  9.5588e-03,\n",
      "          9.6290e-03, -1.9798e-03],\n",
      "        [-1.3910e-02, -9.0910e-03, -6.0279e-02,  ...,  3.1144e-03,\n",
      "          1.2210e-02, -1.5769e-02],\n",
      "        [ 1.9507e-02,  8.9872e-03, -4.3847e-03,  ...,  1.0604e-02,\n",
      "          2.1006e-02, -1.2209e-03],\n",
      "        ...,\n",
      "        [ 2.4310e-03,  2.9288e-02, -6.5339e-03,  ..., -1.3753e-02,\n",
      "          1.4438e-02,  3.9001e-03],\n",
      "        [-2.5335e-03, -4.0029e-03,  1.7994e-02,  ..., -1.3449e-03,\n",
      "         -8.3333e-03, -2.2002e-05],\n",
      "        [-5.4392e-03, -1.0160e-03, -1.8161e-02,  ..., -1.2760e-02,\n",
      "          2.3271e-03,  1.7005e-02]], requires_grad=True))\n",
      "('blocks.12.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1740,  0.2263,  0.1818,  ...,  0.5825, -0.4493, -0.2215],\n",
      "       requires_grad=True))\n",
      "('blocks.12.norm2.weight', Parameter containing:\n",
      "tensor([1.7783, 1.0928, 1.2713,  ..., 2.3827, 1.5421, 1.7100],\n",
      "       requires_grad=True))\n",
      "('blocks.12.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0841, -0.2164, -0.4564,  ..., -0.1780,  0.2367,  0.1364],\n",
      "       requires_grad=True))\n",
      "('blocks.12.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 1.7556e-02, -4.1551e-03, -9.3109e-04,  ..., -2.1997e-02,\n",
      "         -1.6265e-04,  7.4379e-03],\n",
      "        [ 1.2914e-03, -2.2677e-03, -5.7472e-03,  ..., -9.8765e-03,\n",
      "          2.2096e-03, -6.6412e-05],\n",
      "        [ 2.4891e-03,  1.3703e-02,  8.9330e-03,  ...,  7.2890e-03,\n",
      "          1.5826e-03, -1.4093e-03],\n",
      "        ...,\n",
      "        [-8.9283e-03, -1.2058e-02, -1.9127e-02,  ..., -2.6914e-03,\n",
      "         -1.2299e-02,  4.7445e-03],\n",
      "        [-1.5623e-02,  2.2935e-02,  8.1999e-03,  ...,  4.2200e-03,\n",
      "          2.1970e-02, -5.3600e-03],\n",
      "        [-1.3804e-03,  1.7980e-03, -7.1651e-05,  ..., -6.0560e-03,\n",
      "          2.2863e-03, -2.5591e-04]], requires_grad=True))\n",
      "('blocks.12.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.5538, -0.3176, -0.6187,  ..., -0.7124, -0.8169, -0.3307],\n",
      "       requires_grad=True))\n",
      "('blocks.12.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0013,  0.0028, -0.0048,  ..., -0.0230, -0.0173,  0.0004],\n",
      "        [-0.0055, -0.0003, -0.0130,  ...,  0.0137, -0.0018,  0.0010],\n",
      "        [ 0.0004, -0.0003, -0.0096,  ...,  0.0040,  0.0015,  0.0012],\n",
      "        ...,\n",
      "        [-0.0002, -0.0003, -0.0046,  ..., -0.0033,  0.0023, -0.0020],\n",
      "        [-0.0019, -0.0004, -0.0034,  ..., -0.0071, -0.0151,  0.0018],\n",
      "        [ 0.0206,  0.0052, -0.0078,  ...,  0.0051, -0.0167, -0.0002]],\n",
      "       requires_grad=True))\n",
      "('blocks.12.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0737, -0.0456, -0.2501,  ..., -0.1110,  0.1354, -0.1219],\n",
      "       requires_grad=True))\n",
      "('blocks.13.norm1.weight', Parameter containing:\n",
      "tensor([1.3975, 0.7372, 0.9218,  ..., 2.0236, 1.0351, 1.6378],\n",
      "       requires_grad=True))\n",
      "('blocks.13.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0646, -0.0314, -0.3167,  ..., -0.1311,  0.1275,  0.1121],\n",
      "       requires_grad=True))\n",
      "('blocks.13.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.1522, -0.0837, -0.0847,  ..., -0.0479,  0.2898, -0.5000],\n",
      "       requires_grad=True))\n",
      "('blocks.13.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0016, -0.0643, -0.0156,  ...,  0.0943,  0.0388,  0.0024],\n",
      "       requires_grad=True))\n",
      "('blocks.13.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0057, -0.0020, -0.0009,  ..., -0.0121, -0.0021,  0.0098],\n",
      "        [ 0.0012,  0.0077, -0.0195,  ...,  0.0011,  0.0081,  0.0036],\n",
      "        [ 0.0077,  0.0020,  0.0135,  ...,  0.0058,  0.0010,  0.0130],\n",
      "        ...,\n",
      "        [-0.0176, -0.0098,  0.0170,  ..., -0.0073,  0.0190, -0.0024],\n",
      "        [-0.0266, -0.0023,  0.0149,  ...,  0.0087, -0.0269,  0.0101],\n",
      "        [ 0.0142, -0.0102, -0.0206,  ..., -0.0017,  0.0093,  0.0359]],\n",
      "       requires_grad=True))\n",
      "('blocks.13.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0201, -0.0010, -0.0032,  ...,  0.0174,  0.0268, -0.0050],\n",
      "        [-0.0047,  0.0043,  0.0229,  ...,  0.0056,  0.0129,  0.0172],\n",
      "        [-0.0028,  0.0078,  0.0007,  ..., -0.0093, -0.0241,  0.0117],\n",
      "        ...,\n",
      "        [ 0.0049, -0.0156,  0.0068,  ...,  0.0229, -0.0091,  0.0153],\n",
      "        [ 0.0178, -0.0038,  0.0188,  ..., -0.0162,  0.0304,  0.0034],\n",
      "        [-0.0287,  0.0280, -0.0129,  ...,  0.0057, -0.0029, -0.0342]],\n",
      "       requires_grad=True))\n",
      "('blocks.13.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0655,  0.0283, -0.2267,  ...,  0.1470, -0.2355, -0.1373],\n",
      "       requires_grad=True))\n",
      "('blocks.13.norm2.weight', Parameter containing:\n",
      "tensor([1.7217, 0.9868, 1.2089,  ..., 2.0763, 1.3995, 1.6660],\n",
      "       requires_grad=True))\n",
      "('blocks.13.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0738, -0.0782, -0.2412,  ..., -0.1475,  0.3172,  0.3763],\n",
      "       requires_grad=True))\n",
      "('blocks.13.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-1.3147e-02, -2.1505e-03,  4.3160e-03,  ...,  3.5506e-03,\n",
      "          1.8883e-02,  9.4025e-03],\n",
      "        [-5.0852e-03,  2.2406e-02,  5.6466e-03,  ..., -5.9848e-04,\n",
      "          5.7217e-04,  9.3269e-03],\n",
      "        [ 9.4574e-03,  9.7980e-03,  6.3469e-03,  ..., -1.3626e-02,\n",
      "         -1.2906e-02, -5.8880e-04],\n",
      "        ...,\n",
      "        [-1.6782e-02,  2.2494e-02, -8.1029e-03,  ...,  7.9593e-04,\n",
      "          1.6330e-02,  7.6365e-03],\n",
      "        [ 6.5568e-05,  2.2234e-04,  1.3124e-03,  ..., -3.9079e-03,\n",
      "          1.0896e-03, -1.2692e-03],\n",
      "        [-2.3943e-02,  2.2518e-02,  5.1151e-03,  ..., -9.0916e-03,\n",
      "         -2.2797e-03,  1.2176e-02]], requires_grad=True))\n",
      "('blocks.13.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.4337, -1.1377, -0.2930,  ..., -0.3857, -0.5936, -0.2651],\n",
      "       requires_grad=True))\n",
      "('blocks.13.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 5.3052e-03, -2.0756e-02, -8.5168e-03,  ...,  6.6943e-03,\n",
      "          6.9346e-04,  1.1271e-02],\n",
      "        [ 1.1058e-02, -1.9114e-02,  4.5898e-03,  ..., -1.9871e-02,\n",
      "          5.3605e-04, -2.4505e-02],\n",
      "        [ 5.0946e-03, -9.1458e-03,  9.4471e-03,  ...,  1.5870e-02,\n",
      "          5.9851e-04, -8.3402e-03],\n",
      "        ...,\n",
      "        [ 9.8165e-03,  5.5849e-03,  1.9539e-02,  ..., -1.5232e-02,\n",
      "         -9.8381e-04, -1.6506e-02],\n",
      "        [-1.1593e-03, -8.0594e-03,  6.5339e-03,  ..., -5.2012e-03,\n",
      "          9.0318e-04,  2.0764e-02],\n",
      "        [ 2.4035e-02, -1.8648e-02, -2.9686e-05,  ...,  6.8333e-03,\n",
      "          3.1457e-04,  9.0261e-03]], requires_grad=True))\n",
      "('blocks.13.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0031, -0.1195, -0.3203,  ..., -0.1141,  0.2166, -0.1277],\n",
      "       requires_grad=True))\n",
      "('blocks.14.norm1.weight', Parameter containing:\n",
      "tensor([1.4749, 0.6973, 0.8506,  ..., 1.9229, 0.9874, 1.4787],\n",
      "       requires_grad=True))\n",
      "('blocks.14.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0075, -0.0415, -0.1026,  ..., -0.0571,  0.1333,  0.1218],\n",
      "       requires_grad=True))\n",
      "('blocks.14.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.3454,  0.0991,  0.2908,  ...,  0.0662, -0.0834, -0.0732],\n",
      "       requires_grad=True))\n",
      "('blocks.14.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0258,  0.0109,  0.0289,  ...,  0.0280, -0.0335,  0.0305],\n",
      "       requires_grad=True))\n",
      "('blocks.14.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0026, -0.0031, -0.0142,  ...,  0.0055,  0.0162,  0.0032],\n",
      "        [ 0.0192,  0.0001, -0.0099,  ...,  0.0055, -0.0026,  0.0168],\n",
      "        [-0.0007,  0.0240, -0.0075,  ...,  0.0029,  0.0045,  0.0019],\n",
      "        ...,\n",
      "        [-0.0030, -0.0117, -0.0028,  ..., -0.0009, -0.0205, -0.0304],\n",
      "        [-0.0290,  0.0090,  0.0085,  ..., -0.0002, -0.0002, -0.0072],\n",
      "        [ 0.0075, -0.0091, -0.0100,  ...,  0.0149, -0.0061, -0.0386]],\n",
      "       requires_grad=True))\n",
      "('blocks.14.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0095,  0.0004, -0.0060,  ...,  0.0091, -0.0046, -0.0138],\n",
      "        [-0.0240, -0.0034,  0.0077,  ...,  0.0093, -0.0174,  0.0066],\n",
      "        [ 0.0016,  0.0046, -0.0031,  ...,  0.0019, -0.0020, -0.0080],\n",
      "        ...,\n",
      "        [ 0.0249,  0.0137, -0.0203,  ..., -0.0211,  0.0177,  0.0046],\n",
      "        [ 0.0103,  0.0048,  0.0009,  ..., -0.0008,  0.0202,  0.0199],\n",
      "        [-0.0109, -0.0220,  0.0212,  ...,  0.0089, -0.0141,  0.0161]],\n",
      "       requires_grad=True))\n",
      "('blocks.14.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0079, -0.0413, -0.1318,  ...,  0.1542, -0.1022, -0.1774],\n",
      "       requires_grad=True))\n",
      "('blocks.14.norm2.weight', Parameter containing:\n",
      "tensor([1.7781, 1.0713, 1.2462,  ..., 1.9501, 1.4648, 1.7236],\n",
      "       requires_grad=True))\n",
      "('blocks.14.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0881, -0.1394, -0.0599,  ..., -0.1244,  0.1284,  0.3601],\n",
      "       requires_grad=True))\n",
      "('blocks.14.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0130, -0.0017,  0.0300,  ..., -0.0011, -0.0246,  0.0012],\n",
      "        [-0.0112, -0.0028,  0.0046,  ..., -0.0343,  0.0129, -0.0363],\n",
      "        [ 0.0007, -0.0099, -0.0003,  ..., -0.0021, -0.0113, -0.0158],\n",
      "        ...,\n",
      "        [-0.0003,  0.0013,  0.0015,  ..., -0.0036,  0.0031, -0.0009],\n",
      "        [-0.0003,  0.0013,  0.0014,  ..., -0.0034,  0.0029, -0.0008],\n",
      "        [ 0.0063,  0.0076, -0.0215,  ...,  0.0140,  0.0043, -0.0076]],\n",
      "       requires_grad=True))\n",
      "('blocks.14.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.8256, -0.7666, -0.4054,  ..., -0.4619, -0.5922, -0.2437],\n",
      "       requires_grad=True))\n",
      "('blocks.14.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 9.7671e-03, -2.6820e-02, -7.0873e-04,  ...,  1.6159e-05,\n",
      "         -7.6231e-05,  3.3665e-03],\n",
      "        [ 9.3356e-03, -2.3020e-03, -4.8695e-03,  ...,  1.1689e-03,\n",
      "          1.1014e-03,  1.8568e-03],\n",
      "        [ 9.6850e-03,  8.1942e-03, -4.2145e-03,  ...,  8.1479e-04,\n",
      "          7.0613e-04,  1.6453e-02],\n",
      "        ...,\n",
      "        [ 1.0694e-02,  1.1974e-02,  1.0019e-02,  ..., -4.1117e-04,\n",
      "         -4.6202e-04, -8.4247e-03],\n",
      "        [ 2.0196e-03, -2.6257e-02,  9.8258e-03,  ...,  1.9110e-03,\n",
      "          1.8129e-03, -1.6777e-03],\n",
      "        [-8.1025e-03,  2.1943e-03,  1.6035e-02,  ...,  4.3669e-04,\n",
      "          4.4028e-04, -2.0957e-04]], requires_grad=True))\n",
      "('blocks.14.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0923, -0.0889, -0.3272,  ..., -0.2622,  0.2325, -0.0190],\n",
      "       requires_grad=True))\n",
      "('blocks.15.norm1.weight', Parameter containing:\n",
      "tensor([1.5009, 0.8818, 0.9701,  ..., 1.8691, 1.0664, 1.5363],\n",
      "       requires_grad=True))\n",
      "('blocks.15.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0209, -0.0333,  0.0275,  ...,  0.1049,  0.0941,  0.1473],\n",
      "       requires_grad=True))\n",
      "('blocks.15.attn.q_bias', Parameter containing:\n",
      "tensor([-0.0144,  0.6085, -0.2015,  ..., -0.0270,  0.1057,  0.1521],\n",
      "       requires_grad=True))\n",
      "('blocks.15.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.1344,  0.0160, -0.1297,  ...,  0.0318, -0.1037, -0.0468],\n",
      "       requires_grad=True))\n",
      "('blocks.15.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0090,  0.0212, -0.0252,  ...,  0.0091, -0.0104, -0.0078],\n",
      "        [ 0.0144, -0.0204,  0.0106,  ..., -0.0254, -0.0114,  0.0045],\n",
      "        [ 0.0088,  0.0267,  0.0115,  ..., -0.0308, -0.0091, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0281, -0.0201,  0.0012,  ..., -0.0110,  0.0028, -0.0270],\n",
      "        [ 0.0028,  0.0054, -0.0147,  ...,  0.0100,  0.0078,  0.0171],\n",
      "        [-0.0032,  0.0281, -0.0222,  ..., -0.0012, -0.0064, -0.0014]],\n",
      "       requires_grad=True))\n",
      "('blocks.15.attn.proj.weight', Parameter containing:\n",
      "tensor([[-6.3805e-03, -1.7974e-02,  2.0370e-02,  ..., -1.1187e-02,\n",
      "          3.0905e-03, -4.6930e-03],\n",
      "        [ 1.5504e-02, -9.8611e-03, -1.2617e-02,  ..., -5.1059e-03,\n",
      "         -4.1929e-02, -1.8004e-02],\n",
      "        [ 7.9128e-06, -1.4049e-02, -3.1606e-04,  ..., -1.5086e-02,\n",
      "         -2.5627e-03,  1.3846e-03],\n",
      "        ...,\n",
      "        [-9.5193e-05, -1.6654e-02,  3.6239e-02,  ..., -1.9099e-02,\n",
      "          1.4534e-02,  1.5304e-02],\n",
      "        [ 1.4343e-03,  2.8443e-03,  1.9050e-02,  ..., -2.3349e-04,\n",
      "          6.4821e-03,  1.5952e-03],\n",
      "        [-6.8869e-03, -5.5657e-03,  8.3424e-03,  ...,  9.6651e-03,\n",
      "         -2.5204e-02, -1.4331e-02]], requires_grad=True))\n",
      "('blocks.15.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1810,  0.0344, -0.1007,  ...,  0.1609, -0.3614, -0.0475],\n",
      "       requires_grad=True))\n",
      "('blocks.15.norm2.weight', Parameter containing:\n",
      "tensor([1.6494, 1.1417, 1.2823,  ..., 1.7481, 1.3437, 1.6161],\n",
      "       requires_grad=True))\n",
      "('blocks.15.norm2.bias', Parameter containing:\n",
      "tensor([-0.0442, -0.1038,  0.0799,  ...,  0.0132,  0.2891,  0.2919],\n",
      "       requires_grad=True))\n",
      "('blocks.15.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0131, -0.0020,  0.0020,  ...,  0.0035, -0.0044, -0.0246],\n",
      "        [-0.0006,  0.0004,  0.0032,  ..., -0.0035,  0.0043, -0.0009],\n",
      "        [ 0.0041,  0.0010,  0.0052,  ...,  0.0482,  0.0037, -0.0205],\n",
      "        ...,\n",
      "        [-0.0024,  0.0130,  0.0009,  ...,  0.0123,  0.0164,  0.0179],\n",
      "        [ 0.0077, -0.0181, -0.0224,  ..., -0.0042,  0.0135, -0.0212],\n",
      "        [-0.0266,  0.0125, -0.0036,  ..., -0.0099, -0.0148,  0.0128]],\n",
      "       requires_grad=True))\n",
      "('blocks.15.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.4263, -0.3709, -0.3910,  ..., -0.4079, -0.7389, -0.8062],\n",
      "       requires_grad=True))\n",
      "('blocks.15.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0345,  0.0003, -0.0132,  ..., -0.0013, -0.0017, -0.0076],\n",
      "        [-0.0021,  0.0009,  0.0083,  ...,  0.0198, -0.0048, -0.0172],\n",
      "        [-0.0114,  0.0029, -0.0007,  ...,  0.0013,  0.0207,  0.0052],\n",
      "        ...,\n",
      "        [-0.0312, -0.0011, -0.0287,  ..., -0.0157,  0.0044, -0.0098],\n",
      "        [ 0.0040,  0.0032, -0.0010,  ..., -0.0102,  0.0019, -0.0223],\n",
      "        [ 0.0110,  0.0020,  0.0228,  ..., -0.0077,  0.0009,  0.0218]],\n",
      "       requires_grad=True))\n",
      "('blocks.15.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.1535, -0.0796, -0.0208,  ..., -0.1762,  0.1931, -0.0155],\n",
      "       requires_grad=True))\n",
      "('blocks.16.norm1.weight', Parameter containing:\n",
      "tensor([1.6651, 0.9238, 1.0781,  ..., 1.9102, 1.2061, 1.7200],\n",
      "       requires_grad=True))\n",
      "('blocks.16.norm1.bias', Parameter containing:\n",
      "tensor([-0.1926,  0.0383,  0.0995,  ...,  0.1796,  0.2328,  0.0132],\n",
      "       requires_grad=True))\n",
      "('blocks.16.attn.q_bias', Parameter containing:\n",
      "tensor([-0.2453,  0.0750, -0.1495,  ..., -0.1422, -0.1946,  0.6008],\n",
      "       requires_grad=True))\n",
      "('blocks.16.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0030,  0.0370, -0.0587,  ..., -0.0231,  0.0527, -0.0064],\n",
      "       requires_grad=True))\n",
      "('blocks.16.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0211,  0.0106,  0.0121,  ..., -0.0140,  0.0020, -0.0126],\n",
      "        [ 0.0121, -0.0114, -0.0232,  ...,  0.0115, -0.0001, -0.0045],\n",
      "        [ 0.0096, -0.0028,  0.0083,  ..., -0.0005, -0.0045,  0.0117],\n",
      "        ...,\n",
      "        [ 0.0154,  0.0027,  0.0428,  ..., -0.0134, -0.0295, -0.0030],\n",
      "        [ 0.0027,  0.0041, -0.0222,  ...,  0.0237, -0.0311,  0.0132],\n",
      "        [-0.0007,  0.0180, -0.0002,  ..., -0.0005, -0.0090,  0.0048]],\n",
      "       requires_grad=True))\n",
      "('blocks.16.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0014,  0.0299,  0.0146,  ...,  0.0057,  0.0008,  0.0078],\n",
      "        [ 0.0079,  0.0002,  0.0021,  ...,  0.0095, -0.0173,  0.0178],\n",
      "        [ 0.0084, -0.0185,  0.0065,  ..., -0.0257,  0.0140,  0.0137],\n",
      "        ...,\n",
      "        [ 0.0314,  0.0197,  0.0098,  ...,  0.0162,  0.0120, -0.0074],\n",
      "        [ 0.0323,  0.0006,  0.0330,  ...,  0.0116,  0.0326, -0.0051],\n",
      "        [-0.0267,  0.0034, -0.0207,  ..., -0.0046, -0.0031, -0.0021]],\n",
      "       requires_grad=True))\n",
      "('blocks.16.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.2164, -0.1363, -0.0104,  ...,  0.1669,  0.1122,  0.1241],\n",
      "       requires_grad=True))\n",
      "('blocks.16.norm2.weight', Parameter containing:\n",
      "tensor([1.7754, 1.2188, 1.3819,  ..., 1.7725, 1.4102, 1.6631],\n",
      "       requires_grad=True))\n",
      "('blocks.16.norm2.bias', Parameter containing:\n",
      "tensor([-0.3611,  0.0221,  0.1620,  ...,  0.0693, -0.0020, -0.0722],\n",
      "       requires_grad=True))\n",
      "('blocks.16.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0036, -0.0194, -0.0032,  ..., -0.0083,  0.0013, -0.0058],\n",
      "        [ 0.0121, -0.0117,  0.0015,  ...,  0.0083, -0.0288, -0.0130],\n",
      "        [ 0.0125,  0.0023, -0.0100,  ...,  0.0167,  0.0215,  0.0143],\n",
      "        ...,\n",
      "        [ 0.0060,  0.0170,  0.0043,  ..., -0.0186, -0.0112,  0.0250],\n",
      "        [ 0.0231, -0.0028,  0.0017,  ..., -0.0041,  0.0056, -0.0040],\n",
      "        [ 0.0008,  0.0232, -0.0009,  ..., -0.0095,  0.0055, -0.0030]],\n",
      "       requires_grad=True))\n",
      "('blocks.16.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.8186, -0.4947, -0.6846,  ..., -0.8320, -0.7988, -0.2613],\n",
      "       requires_grad=True))\n",
      "('blocks.16.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-2.5628e-02, -1.3913e-02, -2.4918e-02,  ...,  1.7837e-02,\n",
      "         -1.6140e-02, -1.1477e-02],\n",
      "        [-1.9589e-03,  4.9960e-03,  4.9838e-04,  ..., -1.7331e-02,\n",
      "         -2.4360e-03, -9.9473e-03],\n",
      "        [-1.0762e-02, -8.7377e-05,  2.3584e-02,  ...,  3.8301e-03,\n",
      "         -2.0608e-02,  1.9756e-02],\n",
      "        ...,\n",
      "        [ 1.8410e-02, -1.2132e-02, -5.4011e-03,  ...,  9.0164e-03,\n",
      "          4.0286e-03,  4.7618e-03],\n",
      "        [-1.0385e-02,  1.0848e-02, -1.2402e-02,  ...,  1.1918e-02,\n",
      "          1.0396e-02,  6.5637e-03],\n",
      "        [-1.3197e-02,  2.4881e-02, -2.4101e-03,  ...,  5.7183e-03,\n",
      "          1.2878e-02, -4.6767e-03]], requires_grad=True))\n",
      "('blocks.16.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0560, -0.0692,  0.0620,  ..., -0.1468,  0.2287, -0.0282],\n",
      "       requires_grad=True))\n",
      "('blocks.17.norm1.weight', Parameter containing:\n",
      "tensor([1.6799, 0.9197, 1.0498,  ..., 1.8535, 1.1914, 1.6767],\n",
      "       requires_grad=True))\n",
      "('blocks.17.norm1.bias', Parameter containing:\n",
      "tensor([-0.3846,  0.1095, -0.0315,  ...,  0.2135,  0.0441, -0.2338],\n",
      "       requires_grad=True))\n",
      "('blocks.17.attn.q_bias', Parameter containing:\n",
      "tensor([-0.0885, -0.4856, -0.5240,  ..., -0.0291, -0.2779, -0.0117],\n",
      "       requires_grad=True))\n",
      "('blocks.17.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0314,  0.0688,  0.1056,  ..., -0.0659,  0.0176, -0.0256],\n",
      "       requires_grad=True))\n",
      "('blocks.17.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0177, -0.0014, -0.0165,  ...,  0.0118,  0.0141, -0.0116],\n",
      "        [-0.0093,  0.0062, -0.0073,  ..., -0.0052, -0.0053, -0.0018],\n",
      "        [-0.0046,  0.0153,  0.0040,  ..., -0.0090, -0.0203, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0386, -0.0056, -0.0194,  ..., -0.0150, -0.0224, -0.0126],\n",
      "        [-0.0087,  0.0022, -0.0052,  ...,  0.0026, -0.0140,  0.0092],\n",
      "        [-0.0087,  0.0188,  0.0087,  ..., -0.0024, -0.0018, -0.0286]],\n",
      "       requires_grad=True))\n",
      "('blocks.17.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0023,  0.0203,  0.0208,  ..., -0.0306,  0.0557, -0.0030],\n",
      "        [ 0.0035, -0.0176,  0.0010,  ...,  0.0015, -0.0048,  0.0064],\n",
      "        [-0.0127, -0.0113,  0.0021,  ...,  0.0129,  0.0053, -0.0081],\n",
      "        ...,\n",
      "        [ 0.0081, -0.0199,  0.0254,  ...,  0.0479, -0.0031, -0.0003],\n",
      "        [ 0.0111,  0.0076, -0.0203,  ..., -0.0011,  0.0075, -0.0009],\n",
      "        [-0.0006,  0.0082, -0.0026,  ...,  0.0193, -0.0301, -0.0095]],\n",
      "       requires_grad=True))\n",
      "('blocks.17.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1068,  0.2346, -0.0532,  ..., -0.0791,  0.4489,  0.0634],\n",
      "       requires_grad=True))\n",
      "('blocks.17.norm2.weight', Parameter containing:\n",
      "tensor([1.7706, 1.2217, 1.4472,  ..., 1.8067, 1.4484, 1.7382],\n",
      "       requires_grad=True))\n",
      "('blocks.17.norm2.bias', Parameter containing:\n",
      "tensor([-0.4308, -0.1444,  0.0518,  ...,  0.3655, -0.5760, -0.2570],\n",
      "       requires_grad=True))\n",
      "('blocks.17.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0229,  0.0054,  0.0033,  ...,  0.0215, -0.0136,  0.0067],\n",
      "        [-0.0141, -0.0001, -0.0023,  ...,  0.0051,  0.0042,  0.0193],\n",
      "        [-0.0020, -0.0187, -0.0024,  ...,  0.0215,  0.0156,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0147,  0.0302,  0.0141,  ...,  0.0074,  0.0007, -0.0050],\n",
      "        [ 0.0038,  0.0186,  0.0016,  ...,  0.0189,  0.0033,  0.0054],\n",
      "        [ 0.0273, -0.0038, -0.0263,  ..., -0.0345,  0.0016,  0.0086]],\n",
      "       requires_grad=True))\n",
      "('blocks.17.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.2974, -0.6684, -0.3340,  ..., -0.1839, -0.8438, -0.8647],\n",
      "       requires_grad=True))\n",
      "('blocks.17.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0081, -0.0060, -0.0032,  ..., -0.0134,  0.0003,  0.0126],\n",
      "        [ 0.0116,  0.0164,  0.0217,  ..., -0.0243,  0.0101, -0.0083],\n",
      "        [ 0.0119,  0.0083, -0.0047,  ..., -0.0087, -0.0009, -0.0142],\n",
      "        ...,\n",
      "        [-0.0079, -0.0046, -0.0273,  ..., -0.0035,  0.0078,  0.0056],\n",
      "        [ 0.0071, -0.0115, -0.0153,  ..., -0.0139, -0.0013, -0.0025],\n",
      "        [-0.0227, -0.0002, -0.0162,  ...,  0.0094,  0.0198, -0.0192]],\n",
      "       requires_grad=True))\n",
      "('blocks.17.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0018, -0.1286,  0.1795,  ..., -0.1810,  0.1133, -0.0908],\n",
      "       requires_grad=True))\n",
      "('blocks.18.norm1.weight', Parameter containing:\n",
      "tensor([1.7080, 0.9468, 1.1604,  ..., 1.8417, 1.2566, 1.6916],\n",
      "       requires_grad=True))\n",
      "('blocks.18.norm1.bias', Parameter containing:\n",
      "tensor([-0.4059,  0.0558, -0.1454,  ...,  0.4579, -0.4104, -0.4294],\n",
      "       requires_grad=True))\n",
      "('blocks.18.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.1385,  0.0691, -0.5653,  ..., -0.0397,  0.1247,  0.2852],\n",
      "       requires_grad=True))\n",
      "('blocks.18.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0298,  0.0125, -0.0498,  ...,  0.0610, -0.0605, -0.1371],\n",
      "       requires_grad=True))\n",
      "('blocks.18.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0118, -0.0046, -0.0075,  ...,  0.0106,  0.0037,  0.0258],\n",
      "        [ 0.0073,  0.0248,  0.0030,  ...,  0.0145,  0.0085,  0.0078],\n",
      "        [ 0.0051, -0.0054, -0.0233,  ...,  0.0065, -0.0095, -0.0088],\n",
      "        ...,\n",
      "        [ 0.0056, -0.0401,  0.0024,  ..., -0.0185,  0.0105, -0.0136],\n",
      "        [-0.0076,  0.0052,  0.0104,  ...,  0.0007, -0.0274, -0.0071],\n",
      "        [-0.0094,  0.0008,  0.0333,  ...,  0.0270,  0.0043,  0.0200]],\n",
      "       requires_grad=True))\n",
      "('blocks.18.attn.proj.weight', Parameter containing:\n",
      "tensor([[-2.9560e-02,  2.4609e-02,  4.1064e-03,  ...,  1.0250e-02,\n",
      "         -2.4872e-02,  1.8055e-02],\n",
      "        [ 7.5692e-03, -3.3478e-02,  2.8634e-03,  ...,  1.2388e-02,\n",
      "         -6.0337e-03, -1.1461e-02],\n",
      "        [ 1.1675e-04,  1.1773e-02, -8.7568e-03,  ...,  1.9385e-03,\n",
      "         -1.0033e-02, -1.4637e-02],\n",
      "        ...,\n",
      "        [ 6.2076e-03, -3.6561e-03, -9.9046e-03,  ..., -9.1226e-05,\n",
      "         -2.5021e-02, -2.1071e-02],\n",
      "        [-2.6420e-02, -2.5410e-02,  4.0628e-03,  ..., -1.6513e-02,\n",
      "          2.2382e-02,  7.1638e-03],\n",
      "        [ 1.4735e-02, -1.8121e-02, -5.4683e-03,  ...,  8.4800e-03,\n",
      "         -1.4745e-02,  5.7023e-03]], requires_grad=True))\n",
      "('blocks.18.attn.proj.bias', Parameter containing:\n",
      "tensor([0.0858, 0.1337, 0.0930,  ..., 0.0926, 0.0534, 0.0054],\n",
      "       requires_grad=True))\n",
      "('blocks.18.norm2.weight', Parameter containing:\n",
      "tensor([1.8721, 1.2608, 1.4854,  ..., 1.8770, 1.5362, 1.7949],\n",
      "       requires_grad=True))\n",
      "('blocks.18.norm2.bias', Parameter containing:\n",
      "tensor([-0.4766, -0.1107, -0.3666,  ...,  0.3637, -0.7489, -0.4235],\n",
      "       requires_grad=True))\n",
      "('blocks.18.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0110,  0.0085,  0.0101,  ...,  0.0130,  0.0286, -0.0062],\n",
      "        [-0.0088,  0.0154,  0.0154,  ...,  0.0049,  0.0090, -0.0065],\n",
      "        [-0.0189,  0.0110,  0.0144,  ...,  0.0081, -0.0119, -0.0074],\n",
      "        ...,\n",
      "        [ 0.0227, -0.0070,  0.0255,  ...,  0.0245,  0.0088,  0.0220],\n",
      "        [-0.0024, -0.0010,  0.0034,  ..., -0.0003,  0.0029, -0.0009],\n",
      "        [-0.0018, -0.0072, -0.0181,  ..., -0.0043, -0.0045,  0.0016]],\n",
      "       requires_grad=True))\n",
      "('blocks.18.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.2045, -0.6782, -0.2974,  ..., -0.9510, -0.4846, -0.1434],\n",
      "       requires_grad=True))\n",
      "('blocks.18.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0053, -0.0102, -0.0002,  ...,  0.0102, -0.0011,  0.0184],\n",
      "        [-0.0206,  0.0069, -0.0063,  ..., -0.0149,  0.0003,  0.0039],\n",
      "        [-0.0161,  0.0097,  0.0060,  ..., -0.0141,  0.0040,  0.0104],\n",
      "        ...,\n",
      "        [-0.0118, -0.0039,  0.0058,  ...,  0.0394,  0.0006,  0.0029],\n",
      "        [-0.0105, -0.0069,  0.0103,  ..., -0.0202,  0.0006,  0.0114],\n",
      "        [ 0.0086, -0.0140,  0.0309,  ..., -0.0016,  0.0020,  0.0030]],\n",
      "       requires_grad=True))\n",
      "('blocks.18.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.1315, -0.1690,  0.1959,  ..., -0.0999, -0.0982, -0.2220],\n",
      "       requires_grad=True))\n",
      "('blocks.19.norm1.weight', Parameter containing:\n",
      "tensor([1.7861, 0.9355, 1.1171,  ..., 1.8234, 1.2773, 1.7151],\n",
      "       requires_grad=True))\n",
      "('blocks.19.norm1.bias', Parameter containing:\n",
      "tensor([-0.4160,  0.1017, -0.3913,  ...,  0.3933, -0.5162, -0.4855],\n",
      "       requires_grad=True))\n",
      "('blocks.19.attn.q_bias', Parameter containing:\n",
      "tensor([-0.3019, -0.2748, -0.6349,  ..., -1.1807,  0.2328, -0.3970],\n",
      "       requires_grad=True))\n",
      "('blocks.19.attn.v_bias', Parameter containing:\n",
      "tensor([-0.1279, -0.0544, -0.0526,  ..., -0.0225,  0.0649,  0.0796],\n",
      "       requires_grad=True))\n",
      "('blocks.19.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0161, -0.0003,  0.0066,  ...,  0.0021,  0.0003, -0.0014],\n",
      "        [-0.0232,  0.0015, -0.0127,  ..., -0.0160,  0.0023,  0.0164],\n",
      "        [ 0.0051, -0.0195, -0.0071,  ..., -0.0108, -0.0282,  0.0027],\n",
      "        ...,\n",
      "        [-0.0099, -0.0005,  0.0169,  ...,  0.0009, -0.0165,  0.0120],\n",
      "        [-0.0295,  0.0218,  0.0096,  ...,  0.0176, -0.0045, -0.0003],\n",
      "        [-0.0164,  0.0084, -0.0220,  ...,  0.0011,  0.0140,  0.0259]],\n",
      "       requires_grad=True))\n",
      "('blocks.19.attn.proj.weight', Parameter containing:\n",
      "tensor([[-1.1215e-03,  1.8685e-04,  2.4499e-02,  ...,  9.3552e-03,\n",
      "          1.8368e-02,  4.3473e-03],\n",
      "        [-9.8813e-03,  1.0053e-02, -1.1223e-04,  ..., -8.4406e-04,\n",
      "         -3.1464e-02, -1.7529e-02],\n",
      "        [ 2.6345e-04,  7.7447e-03, -6.3332e-03,  ..., -1.7578e-02,\n",
      "          6.8444e-05, -2.0938e-03],\n",
      "        ...,\n",
      "        [-1.0628e-02, -4.9260e-03,  1.3797e-02,  ..., -2.7642e-03,\n",
      "         -5.1374e-03,  9.8020e-03],\n",
      "        [ 1.4928e-02, -1.6504e-03,  4.2388e-03,  ...,  9.8481e-03,\n",
      "         -2.8320e-03, -6.2773e-03],\n",
      "        [-9.4434e-03, -2.9448e-03,  6.2495e-03,  ..., -1.5851e-02,\n",
      "          7.3644e-03, -5.1792e-03]], requires_grad=True))\n",
      "('blocks.19.attn.proj.bias', Parameter containing:\n",
      "tensor([-0.0819,  0.0532, -0.0888,  ...,  0.3123, -0.2326, -0.0945],\n",
      "       requires_grad=True))\n",
      "('blocks.19.norm2.weight', Parameter containing:\n",
      "tensor([1.9766, 1.2500, 1.5245,  ..., 1.9385, 1.5331, 1.8927],\n",
      "       requires_grad=True))\n",
      "('blocks.19.norm2.bias', Parameter containing:\n",
      "tensor([-0.2907,  0.0876, -0.5470,  ...,  0.0533, -0.5565, -0.4033],\n",
      "       requires_grad=True))\n",
      "('blocks.19.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0140, -0.0162, -0.0187,  ..., -0.0197, -0.0062, -0.0092],\n",
      "        [ 0.0022,  0.0016,  0.0070,  ...,  0.0228,  0.0118,  0.0093],\n",
      "        [ 0.0211,  0.0054,  0.0242,  ...,  0.0086, -0.0035,  0.0094],\n",
      "        ...,\n",
      "        [-0.0044, -0.0302, -0.0002,  ..., -0.0118,  0.0029,  0.0042],\n",
      "        [-0.0150,  0.0057, -0.0191,  ...,  0.0056,  0.0053, -0.0170],\n",
      "        [-0.0020,  0.0097, -0.0046,  ..., -0.0122, -0.0041,  0.0034]],\n",
      "       requires_grad=True))\n",
      "('blocks.19.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.2873, -0.8241, -0.3661,  ..., -0.4625, -0.2969, -0.3957],\n",
      "       requires_grad=True))\n",
      "('blocks.19.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0144, -0.0079, -0.0111,  ..., -0.0062,  0.0072,  0.0191],\n",
      "        [ 0.0246,  0.0165,  0.0028,  ...,  0.0064, -0.0065, -0.0017],\n",
      "        [ 0.0090,  0.0033, -0.0091,  ..., -0.0062,  0.0003, -0.0221],\n",
      "        ...,\n",
      "        [ 0.0194,  0.0377, -0.0014,  ...,  0.0341, -0.0053, -0.0021],\n",
      "        [ 0.0034,  0.0027,  0.0115,  ...,  0.0135,  0.0107, -0.0237],\n",
      "        [ 0.0063,  0.0023,  0.0022,  ...,  0.0044,  0.0095, -0.0188]],\n",
      "       requires_grad=True))\n",
      "('blocks.19.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.2663, -0.1111,  0.0858,  ..., -0.0334, -0.2100, -0.2735],\n",
      "       requires_grad=True))\n",
      "('blocks.20.norm1.weight', Parameter containing:\n",
      "tensor([1.7822, 0.9242, 1.1494,  ..., 1.7390, 1.2022, 1.7422],\n",
      "       requires_grad=True))\n",
      "('blocks.20.norm1.bias', Parameter containing:\n",
      "tensor([-0.1477,  0.1479, -0.5640,  ...,  0.0610, -0.2509, -0.3355],\n",
      "       requires_grad=True))\n",
      "('blocks.20.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.1447, -0.1433,  0.0317,  ..., -0.1728,  0.2338, -2.0101],\n",
      "       requires_grad=True))\n",
      "('blocks.20.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0174, -0.0563, -0.0148,  ..., -0.0365,  0.0478, -0.0526],\n",
      "       requires_grad=True))\n",
      "('blocks.20.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0078, -0.0126, -0.0149,  ...,  0.0053,  0.0118, -0.0113],\n",
      "        [-0.0077,  0.0115, -0.0135,  ...,  0.0273,  0.0163,  0.0071],\n",
      "        [ 0.0285,  0.0006,  0.0083,  ..., -0.0064, -0.0062,  0.0103],\n",
      "        ...,\n",
      "        [-0.0020,  0.0159, -0.0150,  ...,  0.0027, -0.0158, -0.0038],\n",
      "        [-0.0043, -0.0184,  0.0081,  ...,  0.0242,  0.0233,  0.0071],\n",
      "        [ 0.0049, -0.0014,  0.0093,  ...,  0.0025,  0.0056,  0.0081]],\n",
      "       requires_grad=True))\n",
      "('blocks.20.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 5.2020e-03,  3.7092e-02,  7.4658e-03,  ..., -9.1731e-03,\n",
      "         -1.2720e-02,  1.0902e-02],\n",
      "        [ 8.9272e-03,  1.3806e-02, -1.0288e-03,  ..., -1.6911e-02,\n",
      "          4.3800e-03, -3.8197e-03],\n",
      "        [-2.4234e-02,  4.7790e-03,  1.2067e-02,  ...,  8.3146e-04,\n",
      "         -8.2658e-03, -1.5191e-02],\n",
      "        ...,\n",
      "        [ 4.0587e-03,  6.4718e-03,  5.5141e-03,  ...,  6.4804e-03,\n",
      "          4.8613e-03,  4.3188e-03],\n",
      "        [-9.4272e-03, -1.5689e-02, -2.4057e-02,  ..., -1.5340e-02,\n",
      "         -1.1157e-02,  8.2156e-05],\n",
      "        [-2.1047e-02, -1.6418e-02, -5.6680e-03,  ..., -7.3080e-03,\n",
      "         -1.7598e-02, -3.1247e-03]], requires_grad=True))\n",
      "('blocks.20.attn.proj.bias', Parameter containing:\n",
      "tensor([-0.0662,  0.0302, -0.0820,  ...,  0.3044, -0.4779, -0.0184],\n",
      "       requires_grad=True))\n",
      "('blocks.20.norm2.weight', Parameter containing:\n",
      "tensor([1.9374, 1.2637, 1.5421,  ..., 1.8654, 1.5527, 1.8975],\n",
      "       requires_grad=True))\n",
      "('blocks.20.norm2.bias', Parameter containing:\n",
      "tensor([-0.0082,  0.2592, -0.7032,  ..., -0.3892,  0.1176, -0.2908],\n",
      "       requires_grad=True))\n",
      "('blocks.20.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0308, -0.0030,  0.0013,  ..., -0.0294, -0.0088, -0.0110],\n",
      "        [-0.0022, -0.0004, -0.0003,  ...,  0.0006,  0.0007,  0.0010],\n",
      "        [ 0.0096, -0.0101, -0.0033,  ...,  0.0013, -0.0110, -0.0096],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0164, -0.0112,  ...,  0.0208, -0.0007, -0.0075],\n",
      "        [-0.0129, -0.0008,  0.0277,  ..., -0.0026, -0.0021, -0.0016],\n",
      "        [ 0.0237,  0.0028,  0.0078,  ...,  0.0068, -0.0080,  0.0104]],\n",
      "       requires_grad=True))\n",
      "('blocks.20.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1755, -0.4041, -0.2779,  ..., -0.2145, -0.7144, -0.6596],\n",
      "       requires_grad=True))\n",
      "('blocks.20.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0164, -0.0023, -0.0023,  ..., -0.0203, -0.0126, -0.0140],\n",
      "        [-0.0089,  0.0017,  0.0062,  ..., -0.0009, -0.0016, -0.0081],\n",
      "        [ 0.0007,  0.0014,  0.0102,  ...,  0.0116, -0.0083,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0180,  0.0050, -0.0012,  ..., -0.0202, -0.0029, -0.0007],\n",
      "        [ 0.0020, -0.0013,  0.0213,  ...,  0.0018,  0.0047, -0.0136],\n",
      "        [ 0.0020, -0.0014,  0.0147,  ...,  0.0020, -0.0101, -0.0073]],\n",
      "       requires_grad=True))\n",
      "('blocks.20.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.1833, -0.0806,  0.0705,  ..., -0.1007, -0.1249, -0.2370],\n",
      "       requires_grad=True))\n",
      "('blocks.21.norm1.weight', Parameter containing:\n",
      "tensor([1.8663, 0.8925, 1.1368,  ..., 1.6476, 1.2443, 1.7843],\n",
      "       requires_grad=True))\n",
      "('blocks.21.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0789,  0.1830, -0.6067,  ..., -0.3303,  0.2471, -0.2238],\n",
      "       requires_grad=True))\n",
      "('blocks.21.attn.q_bias', Parameter containing:\n",
      "tensor([-0.2778,  0.3059, -0.1180,  ..., -0.2798,  0.0182,  0.1286],\n",
      "       requires_grad=True))\n",
      "('blocks.21.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0644,  0.1091,  0.0261,  ..., -0.0567,  0.0393, -0.0067],\n",
      "       requires_grad=True))\n",
      "('blocks.21.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0163, -0.0170, -0.0062,  ..., -0.0163,  0.0183,  0.0080],\n",
      "        [ 0.0110, -0.0157,  0.0126,  ...,  0.0108, -0.0149, -0.0045],\n",
      "        [-0.0031,  0.0014, -0.0092,  ...,  0.0039, -0.0045, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0310, -0.0125,  0.0153,  ..., -0.0116, -0.0073, -0.0066],\n",
      "        [ 0.0358, -0.0073, -0.0069,  ...,  0.0035,  0.0015,  0.0111],\n",
      "        [ 0.0324,  0.0050,  0.0119,  ...,  0.0335, -0.0011, -0.0364]],\n",
      "       requires_grad=True))\n",
      "('blocks.21.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0031, -0.0163, -0.0064,  ..., -0.0411, -0.0254,  0.0137],\n",
      "        [ 0.0043,  0.0075, -0.0144,  ..., -0.0041, -0.0102, -0.0297],\n",
      "        [-0.0250, -0.0085,  0.0237,  ..., -0.0051, -0.0072,  0.0034],\n",
      "        ...,\n",
      "        [ 0.0307, -0.0038, -0.0070,  ..., -0.0214,  0.0119, -0.0096],\n",
      "        [ 0.0117,  0.0093,  0.0098,  ..., -0.0120, -0.0071,  0.0206],\n",
      "        [-0.0136, -0.0068, -0.0028,  ..., -0.0188,  0.0011,  0.0158]],\n",
      "       requires_grad=True))\n",
      "('blocks.21.attn.proj.bias', Parameter containing:\n",
      "tensor([-0.1362,  0.0620, -0.1792,  ...,  0.4097, -0.3266, -0.1019],\n",
      "       requires_grad=True))\n",
      "('blocks.21.norm2.weight', Parameter containing:\n",
      "tensor([1.8498, 1.2324, 1.5002,  ..., 1.7187, 1.4843, 1.8534],\n",
      "       requires_grad=True))\n",
      "('blocks.21.norm2.bias', Parameter containing:\n",
      "tensor([ 0.3888,  0.3577, -0.6815,  ..., -0.8853,  0.6432,  0.0089],\n",
      "       requires_grad=True))\n",
      "('blocks.21.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0055,  0.0166,  0.0035,  ..., -0.0058,  0.0181, -0.0114],\n",
      "        [ 0.0007,  0.0090, -0.0124,  ..., -0.0217,  0.0222, -0.0153],\n",
      "        [ 0.0053, -0.0208, -0.0187,  ..., -0.0192,  0.0273,  0.0143],\n",
      "        ...,\n",
      "        [-0.0065, -0.0398, -0.0038,  ...,  0.0149, -0.0235, -0.0148],\n",
      "        [ 0.0219,  0.0274,  0.0105,  ..., -0.0085,  0.0061,  0.0145],\n",
      "        [ 0.0061,  0.0204,  0.0348,  ..., -0.0395, -0.0102, -0.0216]],\n",
      "       requires_grad=True))\n",
      "('blocks.21.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.8359, -0.2070, -0.2384,  ..., -0.2080, -0.3859, -1.2206],\n",
      "       requires_grad=True))\n",
      "('blocks.21.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0027, -0.0026, -0.0030,  ...,  0.0071, -0.0152, -0.0166],\n",
      "        [-0.0105, -0.0132,  0.0142,  ...,  0.0226, -0.0183,  0.0090],\n",
      "        [ 0.0182,  0.0143,  0.0096,  ..., -0.0019, -0.0043,  0.0295],\n",
      "        ...,\n",
      "        [-0.0043,  0.0184,  0.0370,  ..., -0.0045,  0.0143, -0.0182],\n",
      "        [ 0.0003, -0.0193, -0.0110,  ..., -0.0035, -0.0151, -0.0227],\n",
      "        [ 0.0117,  0.0092, -0.0014,  ...,  0.0065, -0.0038, -0.0071]],\n",
      "       requires_grad=True))\n",
      "('blocks.21.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.1188, -0.0652, -0.0383,  ..., -0.2678,  0.1600, -0.2947],\n",
      "       requires_grad=True))\n",
      "('blocks.22.norm1.weight', Parameter containing:\n",
      "tensor([1.7757, 0.9445, 1.1922,  ..., 1.5673, 1.2344, 1.7375],\n",
      "       requires_grad=True))\n",
      "('blocks.22.norm1.bias', Parameter containing:\n",
      "tensor([ 0.4256,  0.2134, -0.5668,  ..., -0.7457,  0.5401,  0.0506],\n",
      "       requires_grad=True))\n",
      "('blocks.22.attn.q_bias', Parameter containing:\n",
      "tensor([-4.2185e-04,  2.4219e-01,  2.9134e-01,  ..., -2.0695e-01,\n",
      "        -1.2642e-01, -7.6381e-01], requires_grad=True))\n",
      "('blocks.22.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0017, -0.0424,  0.0485,  ..., -0.0111,  0.0016,  0.0221],\n",
      "       requires_grad=True))\n",
      "('blocks.22.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 4.3619e-03, -9.9784e-03, -1.2990e-02,  ...,  3.4356e-03,\n",
      "          5.6196e-04,  2.0705e-02],\n",
      "        [-2.6170e-03, -8.8215e-03,  1.7149e-02,  ...,  2.1448e-02,\n",
      "         -3.7733e-03, -1.3120e-02],\n",
      "        [ 7.8036e-03,  1.1874e-02, -2.0300e-03,  ...,  9.7804e-03,\n",
      "          6.5453e-05, -2.7804e-02],\n",
      "        ...,\n",
      "        [-1.4322e-02,  1.1424e-02,  7.9952e-03,  ..., -6.2310e-03,\n",
      "          2.4415e-03, -1.2538e-02],\n",
      "        [ 6.1443e-03,  1.2243e-02, -1.7998e-02,  ...,  1.8522e-02,\n",
      "          7.6071e-03,  1.8743e-02],\n",
      "        [ 1.1465e-03,  1.6987e-02,  7.2023e-03,  ...,  5.2194e-03,\n",
      "          2.5203e-02,  5.0361e-03]], requires_grad=True))\n",
      "('blocks.22.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 6.2008e-03,  5.9298e-03, -3.7006e-02,  ...,  1.1084e-03,\n",
      "         -1.4041e-02,  2.7219e-02],\n",
      "        [-4.9419e-03,  1.5798e-02,  2.0000e-02,  ..., -3.4897e-03,\n",
      "         -1.2454e-02, -6.8667e-03],\n",
      "        [ 1.4950e-03,  2.0176e-03, -1.4795e-02,  ..., -5.0614e-03,\n",
      "          1.1285e-02,  6.0196e-03],\n",
      "        ...,\n",
      "        [ 5.1501e-03,  3.8543e-03,  4.8497e-03,  ..., -3.5623e-03,\n",
      "          6.2616e-05,  7.5545e-04],\n",
      "        [-7.7399e-03, -8.3101e-03, -1.6860e-02,  ...,  1.4820e-02,\n",
      "         -1.2193e-02,  1.2885e-03],\n",
      "        [ 1.4172e-02, -3.3342e-02,  1.0233e-02,  ...,  2.9300e-03,\n",
      "         -1.2746e-02, -1.0919e-02]], requires_grad=True))\n",
      "('blocks.22.attn.proj.bias', Parameter containing:\n",
      "tensor([-0.2012, -0.1735, -0.2785,  ...,  0.1968, -0.2026, -0.0685],\n",
      "       requires_grad=True))\n",
      "('blocks.22.norm2.weight', Parameter containing:\n",
      "tensor([1.7430, 1.2451, 1.4705,  ..., 1.6380, 1.4803, 1.7519],\n",
      "       requires_grad=True))\n",
      "('blocks.22.norm2.bias', Parameter containing:\n",
      "tensor([ 0.8945,  0.6065, -0.4212,  ..., -1.0153,  0.9882,  0.2580],\n",
      "       requires_grad=True))\n",
      "('blocks.22.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0294, -0.0049,  0.0239,  ..., -0.0118, -0.0002,  0.0065],\n",
      "        [-0.0141,  0.0002, -0.0022,  ..., -0.0027, -0.0125, -0.0207],\n",
      "        [-0.0180, -0.0050, -0.0056,  ..., -0.0061,  0.0180, -0.0468],\n",
      "        ...,\n",
      "        [-0.0144, -0.0053,  0.0226,  ...,  0.0084, -0.0121,  0.0161],\n",
      "        [ 0.0273, -0.0300,  0.0031,  ..., -0.0129,  0.0310, -0.0084],\n",
      "        [-0.0035, -0.0050,  0.0049,  ..., -0.0022, -0.0088, -0.0052]],\n",
      "       requires_grad=True))\n",
      "('blocks.22.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.5427, -0.6763, -0.9861,  ..., -0.7875, -0.3540, -0.1672],\n",
      "       requires_grad=True))\n",
      "('blocks.22.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-3.4814e-02, -1.3379e-03, -1.6146e-02,  ..., -3.6060e-03,\n",
      "         -1.0302e-02,  1.2236e-05],\n",
      "        [ 5.2149e-03,  3.0120e-02, -1.5094e-02,  ...,  3.8141e-03,\n",
      "          3.7822e-03,  9.1021e-03],\n",
      "        [-2.4516e-03,  5.1201e-03,  1.5582e-03,  ...,  9.4934e-03,\n",
      "         -1.0411e-02, -9.6414e-03],\n",
      "        ...,\n",
      "        [-7.7118e-04,  1.5288e-02, -6.2561e-03,  ..., -9.5795e-03,\n",
      "         -1.0342e-02,  7.6522e-03],\n",
      "        [-5.5317e-03, -4.2308e-03,  1.1442e-02,  ..., -3.9180e-03,\n",
      "          1.2825e-02,  8.5024e-03],\n",
      "        [-1.6156e-02,  2.5475e-03, -1.0803e-02,  ...,  4.7372e-03,\n",
      "          1.2698e-02,  7.6573e-03]], requires_grad=True))\n",
      "('blocks.22.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.1270, -0.0220, -0.0495,  ..., -0.3673,  0.3279, -0.0759],\n",
      "       requires_grad=True))\n",
      "('blocks.23.norm1.weight', Parameter containing:\n",
      "tensor([1.7844, 1.0499, 1.3055,  ..., 1.5341, 1.3168, 1.7265],\n",
      "       requires_grad=True))\n",
      "('blocks.23.norm1.bias', Parameter containing:\n",
      "tensor([ 0.7559,  0.3835, -0.3534,  ..., -0.7814,  0.6420,  0.2086],\n",
      "       requires_grad=True))\n",
      "('blocks.23.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.2445,  0.1790,  0.1885,  ..., -0.2395, -0.0562, -0.2862],\n",
      "       requires_grad=True))\n",
      "('blocks.23.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.1106,  0.0003,  0.0229,  ..., -0.0157, -0.0888, -0.0411],\n",
      "       requires_grad=True))\n",
      "('blocks.23.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-9.3831e-04, -8.8159e-03, -1.3850e-02,  ...,  8.0285e-03,\n",
      "          9.7610e-03, -1.9409e-02],\n",
      "        [-1.2771e-02,  1.5554e-02,  3.2078e-03,  ...,  3.3750e-02,\n",
      "          2.2131e-03,  5.1182e-03],\n",
      "        [ 1.3975e-02,  6.3772e-03, -1.1813e-02,  ..., -5.2227e-03,\n",
      "          3.3773e-03,  6.9091e-03],\n",
      "        ...,\n",
      "        [ 7.4552e-03,  3.7137e-03, -4.8602e-03,  ..., -1.1964e-02,\n",
      "         -1.0512e-02,  2.0540e-04],\n",
      "        [-5.9511e-03, -1.8025e-02,  7.7546e-03,  ...,  8.4932e-05,\n",
      "          9.9193e-03,  6.9713e-03],\n",
      "        [ 4.1013e-03,  3.5561e-03, -1.2009e-02,  ...,  2.8351e-03,\n",
      "          1.3293e-03,  2.1519e-02]], requires_grad=True))\n",
      "('blocks.23.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0194,  0.0028, -0.0004,  ..., -0.0103,  0.0090,  0.0130],\n",
      "        [-0.0175,  0.0231,  0.0112,  ...,  0.0159, -0.0173,  0.0071],\n",
      "        [-0.0048, -0.0100,  0.0043,  ...,  0.0065,  0.0031, -0.0031],\n",
      "        ...,\n",
      "        [-0.0194,  0.0076, -0.0065,  ...,  0.0241,  0.0083,  0.0098],\n",
      "        [-0.0142,  0.0157,  0.0084,  ...,  0.0038, -0.0020, -0.0066],\n",
      "        [-0.0125, -0.0345, -0.0344,  ...,  0.0080,  0.0274,  0.0028]],\n",
      "       requires_grad=True))\n",
      "('blocks.23.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1322, -0.0544, -0.1900,  ..., -0.0353,  0.1180,  0.0540],\n",
      "       requires_grad=True))\n",
      "('blocks.23.norm2.weight', Parameter containing:\n",
      "tensor([1.6826, 1.2723, 1.4617,  ..., 1.5607, 1.4629, 1.6758],\n",
      "       requires_grad=True))\n",
      "('blocks.23.norm2.bias', Parameter containing:\n",
      "tensor([ 0.7066,  0.7106, -0.1888,  ..., -0.7977,  0.6231,  0.2740],\n",
      "       requires_grad=True))\n",
      "('blocks.23.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0034, -0.0039,  0.0045,  ..., -0.0107,  0.0344,  0.0071],\n",
      "        [-0.0003,  0.0176,  0.0208,  ...,  0.0021,  0.0016,  0.0174],\n",
      "        [ 0.0074,  0.0013, -0.0044,  ..., -0.0082, -0.0166, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0067,  0.0025,  0.0100,  ..., -0.0140, -0.0065, -0.0150],\n",
      "        [-0.0007,  0.0135, -0.0010,  ...,  0.0077,  0.0147,  0.0094],\n",
      "        [-0.0089, -0.0121, -0.0103,  ...,  0.0156,  0.0090, -0.0416]],\n",
      "       requires_grad=True))\n",
      "('blocks.23.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1720, -0.8112, -0.1392,  ..., -0.7289, -0.1709, -0.5557],\n",
      "       requires_grad=True))\n",
      "('blocks.23.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0015,  0.0048,  0.0025,  ...,  0.0104, -0.0149,  0.0101],\n",
      "        [ 0.0155,  0.0045,  0.0042,  ..., -0.0013, -0.0102, -0.0038],\n",
      "        [ 0.0081, -0.0021, -0.0008,  ...,  0.0060,  0.0144,  0.0151],\n",
      "        ...,\n",
      "        [ 0.0105,  0.0144, -0.0019,  ..., -0.0002, -0.0169, -0.0110],\n",
      "        [-0.0289,  0.0075, -0.0012,  ..., -0.0072, -0.0259, -0.0147],\n",
      "        [ 0.0026, -0.0064,  0.0060,  ...,  0.0101, -0.0088,  0.0166]],\n",
      "       requires_grad=True))\n",
      "('blocks.23.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.1451,  0.0771,  0.0182,  ..., -0.2572,  0.2910, -0.0370],\n",
      "       requires_grad=True))\n",
      "('blocks.24.norm1.weight', Parameter containing:\n",
      "tensor([1.8438, 1.1845, 1.3663,  ..., 1.5275, 1.4240, 1.7595],\n",
      "       requires_grad=True))\n",
      "('blocks.24.norm1.bias', Parameter containing:\n",
      "tensor([ 0.6167,  0.5168, -0.1383,  ..., -0.5102,  0.3481,  0.2557],\n",
      "       requires_grad=True))\n",
      "('blocks.24.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.2484, -0.0510, -0.0637,  ..., -0.4366,  0.3744,  0.3185],\n",
      "       requires_grad=True))\n",
      "('blocks.24.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.1427, -0.0362,  0.0309,  ...,  0.0383, -0.0627,  0.0277],\n",
      "       requires_grad=True))\n",
      "('blocks.24.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0167,  0.0097,  0.0123,  ..., -0.0117,  0.0001, -0.0126],\n",
      "        [-0.0192,  0.0063, -0.0239,  ..., -0.0194, -0.0020,  0.0116],\n",
      "        [-0.0121,  0.0047, -0.0110,  ...,  0.0172,  0.0127, -0.0063],\n",
      "        ...,\n",
      "        [-0.0055,  0.0022,  0.0109,  ...,  0.0076,  0.0044, -0.0081],\n",
      "        [ 0.0100, -0.0230, -0.0046,  ...,  0.0165, -0.0308, -0.0102],\n",
      "        [ 0.0229,  0.0051, -0.0003,  ..., -0.0233,  0.0039,  0.0047]],\n",
      "       requires_grad=True))\n",
      "('blocks.24.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 1.6389e-02, -6.4955e-05, -1.5830e-02,  ..., -9.4933e-03,\n",
      "          6.2482e-03, -1.9212e-02],\n",
      "        [-1.3924e-03,  8.1223e-03,  9.8311e-03,  ...,  2.3349e-03,\n",
      "         -1.3905e-02, -1.8324e-02],\n",
      "        [ 1.1670e-02, -5.3163e-03,  1.7871e-03,  ...,  1.5665e-02,\n",
      "          2.7041e-03, -5.5801e-04],\n",
      "        ...,\n",
      "        [ 3.0016e-03,  2.5380e-02,  1.4104e-02,  ..., -2.2740e-03,\n",
      "          2.7811e-02,  1.0073e-02],\n",
      "        [ 5.1132e-03,  9.4547e-03,  8.2969e-04,  ...,  4.7590e-03,\n",
      "         -1.8989e-03,  2.0343e-02],\n",
      "        [ 2.2737e-02,  4.0232e-03, -6.1944e-03,  ...,  2.9673e-02,\n",
      "         -2.3110e-03,  5.2444e-03]], requires_grad=True))\n",
      "('blocks.24.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1104,  0.0239, -0.1013,  ..., -0.0937,  0.1278,  0.1301],\n",
      "       requires_grad=True))\n",
      "('blocks.24.norm2.weight', Parameter containing:\n",
      "tensor([1.6611, 1.3352, 1.4795,  ..., 1.5174, 1.4864, 1.6248],\n",
      "       requires_grad=True))\n",
      "('blocks.24.norm2.bias', Parameter containing:\n",
      "tensor([ 0.5596,  0.7355,  0.1161,  ..., -0.2766,  0.2574,  0.1011],\n",
      "       requires_grad=True))\n",
      "('blocks.24.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0092, -0.0148,  0.0025,  ...,  0.0078, -0.0012,  0.0076],\n",
      "        [ 0.0088,  0.0050,  0.0091,  ...,  0.0014, -0.0064,  0.0018],\n",
      "        [ 0.0015,  0.0075,  0.0026,  ..., -0.0077,  0.0011, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0153,  0.0123,  0.0060,  ...,  0.0291, -0.0017, -0.0133],\n",
      "        [-0.0220, -0.0082, -0.0061,  ..., -0.0089, -0.0095,  0.0250],\n",
      "        [-0.0045, -0.0028,  0.0060,  ..., -0.0025, -0.0046,  0.0029]],\n",
      "       requires_grad=True))\n",
      "('blocks.24.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.9856, -0.1756,  0.0037,  ..., -0.0705, -0.9459, -0.6865],\n",
      "       requires_grad=True))\n",
      "('blocks.24.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0189, -0.0031,  0.0038,  ..., -0.0114,  0.0129,  0.0071],\n",
      "        [ 0.0082,  0.0141,  0.0005,  ..., -0.0146, -0.0056, -0.0050],\n",
      "        [ 0.0041, -0.0100, -0.0012,  ..., -0.0147,  0.0067,  0.0043],\n",
      "        ...,\n",
      "        [ 0.0063, -0.0050,  0.0048,  ..., -0.0361, -0.0094, -0.0043],\n",
      "        [ 0.0044,  0.0079,  0.0052,  ...,  0.0104,  0.0059,  0.0117],\n",
      "        [-0.0042, -0.0115,  0.0100,  ...,  0.0117, -0.0082, -0.0015]],\n",
      "       requires_grad=True))\n",
      "('blocks.24.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.1432,  0.1475, -0.0292,  ..., -0.1309,  0.2275,  0.0349],\n",
      "       requires_grad=True))\n",
      "('blocks.25.norm1.weight', Parameter containing:\n",
      "tensor([1.8056, 1.2825, 1.4286,  ..., 1.4779, 1.5101, 1.7335],\n",
      "       requires_grad=True))\n",
      "('blocks.25.norm1.bias', Parameter containing:\n",
      "tensor([ 0.3674,  0.5159, -0.0239,  ..., -0.1464,  0.0519, -0.0064],\n",
      "       requires_grad=True))\n",
      "('blocks.25.attn.q_bias', Parameter containing:\n",
      "tensor([-0.1637,  0.4572,  0.2929,  ...,  0.3248, -0.1880, -0.2499],\n",
      "       requires_grad=True))\n",
      "('blocks.25.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0074,  0.0105, -0.0157,  ...,  0.0369, -0.0978, -0.0217],\n",
      "       requires_grad=True))\n",
      "('blocks.25.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0022,  0.0049,  0.0070,  ..., -0.0029, -0.0321,  0.0183],\n",
      "        [ 0.0012,  0.0039, -0.0260,  ..., -0.0061, -0.0072, -0.0026],\n",
      "        [ 0.0158,  0.0022, -0.0139,  ...,  0.0051,  0.0095, -0.0107],\n",
      "        ...,\n",
      "        [-0.0248,  0.0193,  0.0070,  ..., -0.0099, -0.0079, -0.0089],\n",
      "        [-0.0196, -0.0113,  0.0060,  ...,  0.0103, -0.0111,  0.0099],\n",
      "        [-0.0086,  0.0197, -0.0034,  ..., -0.0086,  0.0100,  0.0087]],\n",
      "       requires_grad=True))\n",
      "('blocks.25.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0264, -0.0088, -0.0106,  ..., -0.0016,  0.0236,  0.0088],\n",
      "        [ 0.0223,  0.0061,  0.0171,  ..., -0.0177,  0.0087,  0.0102],\n",
      "        [ 0.0108, -0.0023, -0.0163,  ...,  0.0134,  0.0181,  0.0072],\n",
      "        ...,\n",
      "        [ 0.0182, -0.0079,  0.0066,  ...,  0.0041,  0.0234, -0.0064],\n",
      "        [ 0.0007,  0.0102,  0.0044,  ..., -0.0064, -0.0028, -0.0043],\n",
      "        [-0.0266, -0.0278,  0.0071,  ...,  0.0109,  0.0075, -0.0152]],\n",
      "       requires_grad=True))\n",
      "('blocks.25.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1285,  0.1935, -0.1435,  ..., -0.1038, -0.0263,  0.0248],\n",
      "       requires_grad=True))\n",
      "('blocks.25.norm2.weight', Parameter containing:\n",
      "tensor([1.6209, 1.3916, 1.4902,  ..., 1.4602, 1.4959, 1.6110],\n",
      "       requires_grad=True))\n",
      "('blocks.25.norm2.bias', Parameter containing:\n",
      "tensor([0.2077, 0.3307, 0.3759,  ..., 0.1366, 0.0827, 0.1148],\n",
      "       requires_grad=True))\n",
      "('blocks.25.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0207, -0.0212, -0.0137,  ...,  0.0004,  0.0254, -0.0110],\n",
      "        [ 0.0278,  0.0257,  0.0062,  ..., -0.0117,  0.0195, -0.0300],\n",
      "        [ 0.0040, -0.0065,  0.0166,  ..., -0.0005, -0.0051,  0.0061],\n",
      "        ...,\n",
      "        [-0.0166,  0.0192,  0.0020,  ..., -0.0185,  0.0148,  0.0010],\n",
      "        [ 0.0049,  0.0079, -0.0080,  ..., -0.0061, -0.0013, -0.0006],\n",
      "        [ 0.0035,  0.0240, -0.0154,  ...,  0.0041, -0.0081,  0.0158]],\n",
      "       requires_grad=True))\n",
      "('blocks.25.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.9744, -0.9012, -0.0723,  ..., -0.1129, -0.0396, -0.6299],\n",
      "       requires_grad=True))\n",
      "('blocks.25.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0026,  0.0158, -0.0031,  ...,  0.0184,  0.0065, -0.0060],\n",
      "        [ 0.0072,  0.0199,  0.0231,  ..., -0.0248, -0.0012, -0.0175],\n",
      "        [ 0.0031,  0.0039, -0.0132,  ...,  0.0081,  0.0082,  0.0162],\n",
      "        ...,\n",
      "        [ 0.0135, -0.0005, -0.0013,  ...,  0.0056, -0.0013,  0.0060],\n",
      "        [ 0.0281, -0.0054,  0.0072,  ..., -0.0073, -0.0149, -0.0348],\n",
      "        [-0.0207, -0.0136, -0.0068,  ..., -0.0066,  0.0034,  0.0022]],\n",
      "       requires_grad=True))\n",
      "('blocks.25.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.1312,  0.0148,  0.0909,  ..., -0.0248,  0.0122,  0.0283],\n",
      "       requires_grad=True))\n",
      "('blocks.26.norm1.weight', Parameter containing:\n",
      "tensor([1.7826, 1.3672, 1.5051,  ..., 1.4681, 1.5254, 1.6942],\n",
      "       requires_grad=True))\n",
      "('blocks.26.norm1.bias', Parameter containing:\n",
      "tensor([ 0.1935,  0.2499,  0.1588,  ...,  0.0655,  0.0498, -0.0020],\n",
      "       requires_grad=True))\n",
      "('blocks.26.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.1677,  0.3683,  0.3075,  ...,  0.1339,  0.2801, -0.5758],\n",
      "       requires_grad=True))\n",
      "('blocks.26.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0615,  0.0736,  0.0192,  ..., -0.0225,  0.0111,  0.1074],\n",
      "       requires_grad=True))\n",
      "('blocks.26.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0082, -0.0177, -0.0102,  ..., -0.0058, -0.0063,  0.0105],\n",
      "        [-0.0034,  0.0112,  0.0026,  ..., -0.0215,  0.0214, -0.0214],\n",
      "        [ 0.0053,  0.0048,  0.0201,  ..., -0.0170,  0.0027, -0.0204],\n",
      "        ...,\n",
      "        [ 0.0129,  0.0020, -0.0105,  ..., -0.0116,  0.0133,  0.0156],\n",
      "        [ 0.0003, -0.0007, -0.0065,  ...,  0.0118,  0.0004,  0.0066],\n",
      "        [ 0.0206,  0.0057, -0.0028,  ..., -0.0041,  0.0168, -0.0285]],\n",
      "       requires_grad=True))\n",
      "('blocks.26.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0016, -0.0141, -0.0006,  ...,  0.0155,  0.0258,  0.0183],\n",
      "        [-0.0015,  0.0056,  0.0171,  ...,  0.0051, -0.0034,  0.0041],\n",
      "        [-0.0091,  0.0013, -0.0060,  ..., -0.0056, -0.0001,  0.0240],\n",
      "        ...,\n",
      "        [ 0.0130,  0.0055,  0.0226,  ...,  0.0059, -0.0140, -0.0013],\n",
      "        [-0.0068, -0.0008, -0.0001,  ...,  0.0195,  0.0042,  0.0019],\n",
      "        [ 0.0028, -0.0218,  0.0338,  ...,  0.0353,  0.0059,  0.0011]],\n",
      "       requires_grad=True))\n",
      "('blocks.26.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0792,  0.2557, -0.0867,  ..., -0.0310, -0.1755,  0.0733],\n",
      "       requires_grad=True))\n",
      "('blocks.26.norm2.weight', Parameter containing:\n",
      "tensor([1.6268, 1.3976, 1.4920,  ..., 1.4443, 1.4921, 1.5812],\n",
      "       requires_grad=True))\n",
      "('blocks.26.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0880, -0.1294,  0.4913,  ...,  0.3006,  0.3708, -0.0661],\n",
      "       requires_grad=True))\n",
      "('blocks.26.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 7.5033e-03,  6.8695e-03, -8.9068e-03,  ...,  2.9156e-03,\n",
      "          1.8675e-02,  7.9754e-03],\n",
      "        [ 2.7897e-03,  4.1305e-03,  1.8406e-02,  ..., -8.1182e-03,\n",
      "          3.9601e-03, -2.8903e-03],\n",
      "        [-2.2936e-02, -1.2443e-02,  4.5618e-03,  ..., -4.9064e-04,\n",
      "          3.1413e-03, -4.8159e-03],\n",
      "        ...,\n",
      "        [-1.0966e-02, -3.7392e-03,  3.4030e-03,  ..., -1.4535e-02,\n",
      "         -6.7382e-03, -2.6089e-03],\n",
      "        [-6.5846e-03,  1.8950e-02,  1.5157e-03,  ..., -6.0289e-03,\n",
      "         -2.3559e-03, -1.0977e-02],\n",
      "        [ 3.0039e-03,  1.0842e-02,  8.3694e-05,  ...,  9.8180e-04,\n",
      "         -1.3545e-02, -7.8635e-03]], requires_grad=True))\n",
      "('blocks.26.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.2364, -0.1527, -0.6944,  ..., -0.2350, -0.8872, -0.1633],\n",
      "       requires_grad=True))\n",
      "('blocks.26.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-9.6383e-03, -5.7863e-03, -1.2159e-03,  ...,  2.5597e-02,\n",
      "         -1.0350e-02, -5.4649e-04],\n",
      "        [-2.3610e-03,  1.0008e-04,  2.1508e-02,  ...,  1.4245e-02,\n",
      "          5.3653e-03,  7.9693e-03],\n",
      "        [-7.2533e-03, -5.4694e-03, -1.5117e-02,  ..., -1.7592e-03,\n",
      "         -8.4018e-03,  1.0928e-03],\n",
      "        ...,\n",
      "        [ 1.5684e-02,  1.5506e-02,  1.7823e-02,  ...,  1.1882e-02,\n",
      "         -5.1399e-03,  1.0784e-02],\n",
      "        [-1.4084e-02, -1.4198e-02,  1.6859e-03,  ..., -1.1554e-02,\n",
      "          4.5617e-03,  7.4612e-03],\n",
      "        [-8.6282e-03,  5.6839e-03,  2.6064e-03,  ...,  3.8312e-03,\n",
      "          9.0132e-05,  4.9582e-03]], requires_grad=True))\n",
      "('blocks.26.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.1171, -0.0966,  0.1209,  ..., -0.0584,  0.1448, -0.0176],\n",
      "       requires_grad=True))\n",
      "('blocks.27.norm1.weight', Parameter containing:\n",
      "tensor([1.7630, 1.4640, 1.5479,  ..., 1.4835, 1.5965, 1.7235],\n",
      "       requires_grad=True))\n",
      "('blocks.27.norm1.bias', Parameter containing:\n",
      "tensor([ 0.1310,  0.0094,  0.2080,  ...,  0.1143,  0.2583, -0.0390],\n",
      "       requires_grad=True))\n",
      "('blocks.27.attn.q_bias', Parameter containing:\n",
      "tensor([-0.7432, -0.0089, -0.1318,  ..., -0.0122,  0.7327, -0.3816],\n",
      "       requires_grad=True))\n",
      "('blocks.27.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0061, -0.0489, -0.0507,  ...,  0.0388,  0.1054, -0.0667],\n",
      "       requires_grad=True))\n",
      "('blocks.27.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-2.4580e-02, -2.7925e-03, -1.0016e-02,  ..., -1.8416e-02,\n",
      "          6.2287e-03,  1.6986e-03],\n",
      "        [ 4.2263e-03, -5.7805e-03,  1.5606e-02,  ...,  2.7611e-04,\n",
      "          8.9572e-03,  2.0701e-02],\n",
      "        [ 2.2024e-03, -1.2155e-02, -1.2981e-02,  ..., -1.2018e-02,\n",
      "         -9.2042e-03,  2.1281e-02],\n",
      "        ...,\n",
      "        [ 1.6137e-02,  3.9433e-03, -7.4913e-03,  ..., -3.2157e-04,\n",
      "         -7.4182e-04, -1.4149e-05],\n",
      "        [ 1.5206e-02,  1.3437e-02, -3.4636e-03,  ..., -2.3823e-02,\n",
      "         -1.1046e-02, -1.7674e-02],\n",
      "        [-2.1588e-03, -1.1279e-02,  1.3028e-02,  ..., -1.1842e-02,\n",
      "         -2.5225e-02, -1.2455e-02]], requires_grad=True))\n",
      "('blocks.27.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0044, -0.0042,  0.0107,  ...,  0.0009,  0.0025,  0.0010],\n",
      "        [-0.0097, -0.0017, -0.0287,  ...,  0.0140,  0.0092,  0.0157],\n",
      "        [ 0.0030, -0.0210,  0.0031,  ..., -0.0091, -0.0171,  0.0020],\n",
      "        ...,\n",
      "        [-0.0094,  0.0016, -0.0005,  ..., -0.0053,  0.0025,  0.0010],\n",
      "        [-0.0177, -0.0032, -0.0118,  ...,  0.0396, -0.0100, -0.0055],\n",
      "        [-0.0179, -0.0067, -0.0090,  ...,  0.0283,  0.0219,  0.0073]],\n",
      "       requires_grad=True))\n",
      "('blocks.27.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0709,  0.1987, -0.0241,  ...,  0.0214, -0.1110,  0.0047],\n",
      "       requires_grad=True))\n",
      "('blocks.27.norm2.weight', Parameter containing:\n",
      "tensor([1.6533, 1.4443, 1.5343,  ..., 1.4532, 1.5276, 1.6378],\n",
      "       requires_grad=True))\n",
      "('blocks.27.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0197, -0.3121,  0.4316,  ...,  0.2245,  0.5518,  0.1045],\n",
      "       requires_grad=True))\n",
      "('blocks.27.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0046,  0.0095,  0.0027,  ...,  0.0088,  0.0093,  0.0263],\n",
      "        [-0.0280, -0.0090, -0.0105,  ...,  0.0132, -0.0263,  0.0243],\n",
      "        [ 0.0088, -0.0221,  0.0079,  ..., -0.0009,  0.0183,  0.0064],\n",
      "        ...,\n",
      "        [-0.0045, -0.0183,  0.0092,  ...,  0.0086, -0.0004, -0.0034],\n",
      "        [ 0.0012, -0.0054,  0.0145,  ...,  0.0018, -0.0029,  0.0048],\n",
      "        [ 0.0081,  0.0178, -0.0019,  ...,  0.0101, -0.0067, -0.0123]],\n",
      "       requires_grad=True))\n",
      "('blocks.27.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.4579, -0.7350,  0.0189,  ..., -0.2361, -0.1133, -0.0553],\n",
      "       requires_grad=True))\n",
      "('blocks.27.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0083, -0.0289, -0.0057,  ...,  0.0070, -0.0082, -0.0073],\n",
      "        [ 0.0106,  0.0046,  0.0050,  ...,  0.0057, -0.0051, -0.0091],\n",
      "        [-0.0135, -0.0104, -0.0100,  ..., -0.0108, -0.0169,  0.0039],\n",
      "        ...,\n",
      "        [-0.0021,  0.0007,  0.0001,  ..., -0.0101, -0.0080, -0.0230],\n",
      "        [ 0.0044, -0.0148, -0.0088,  ...,  0.0040,  0.0127,  0.0018],\n",
      "        [-0.0120, -0.0102,  0.0197,  ...,  0.0103,  0.0143,  0.0306]],\n",
      "       requires_grad=True))\n",
      "('blocks.27.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0207, -0.2238, -0.0284,  ..., -0.0068,  0.0339,  0.0169],\n",
      "       requires_grad=True))\n",
      "('blocks.28.norm1.weight', Parameter containing:\n",
      "tensor([1.8322, 1.5432, 1.6517,  ..., 1.5968, 1.7001, 1.7845],\n",
      "       requires_grad=True))\n",
      "('blocks.28.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0887, -0.0054,  0.0734,  ...,  0.0201,  0.4208,  0.1486],\n",
      "       requires_grad=True))\n",
      "('blocks.28.attn.q_bias', Parameter containing:\n",
      "tensor([-0.4246, -0.1859,  0.1911,  ..., -0.0623,  0.3389,  0.2139],\n",
      "       requires_grad=True))\n",
      "('blocks.28.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0233, -0.0231,  0.0037,  ...,  0.0244,  0.0506,  0.0083],\n",
      "       requires_grad=True))\n",
      "('blocks.28.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0180,  0.0021,  0.0056,  ...,  0.0166,  0.0146, -0.0020],\n",
      "        [ 0.0002,  0.0074,  0.0084,  ...,  0.0230,  0.0062, -0.0013],\n",
      "        [ 0.0108, -0.0140,  0.0268,  ..., -0.0122, -0.0013, -0.0021],\n",
      "        ...,\n",
      "        [ 0.0019,  0.0100, -0.0065,  ..., -0.0003, -0.0192,  0.0224],\n",
      "        [-0.0119, -0.0018, -0.0098,  ..., -0.0009, -0.0030,  0.0069],\n",
      "        [ 0.0009,  0.0022,  0.0140,  ..., -0.0177,  0.0063,  0.0108]],\n",
      "       requires_grad=True))\n",
      "('blocks.28.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0024,  0.0085, -0.0012,  ..., -0.0058,  0.0103, -0.0132],\n",
      "        [ 0.0060,  0.0107,  0.0099,  ..., -0.0214,  0.0151, -0.0149],\n",
      "        [-0.0148,  0.0064,  0.0012,  ...,  0.0078,  0.0080, -0.0119],\n",
      "        ...,\n",
      "        [ 0.0088, -0.0052,  0.0254,  ...,  0.0037,  0.0068,  0.0129],\n",
      "        [-0.0183,  0.0002, -0.0019,  ...,  0.0034,  0.0084,  0.0105],\n",
      "        [-0.0037, -0.0166,  0.0018,  ..., -0.0210, -0.0101, -0.0018]],\n",
      "       requires_grad=True))\n",
      "('blocks.28.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0428,  0.0928,  0.0488,  ...,  0.0461, -0.0551,  0.0404],\n",
      "       requires_grad=True))\n",
      "('blocks.28.norm2.weight', Parameter containing:\n",
      "tensor([1.7281, 1.5380, 1.6202,  ..., 1.5108, 1.5912, 1.7265],\n",
      "       requires_grad=True))\n",
      "('blocks.28.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0547, -0.1749,  0.1540,  ...,  0.0631,  0.6548,  0.2485],\n",
      "       requires_grad=True))\n",
      "('blocks.28.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-8.1228e-03, -4.6735e-03, -8.5254e-05,  ..., -1.1024e-02,\n",
      "         -1.0527e-02, -3.8502e-03],\n",
      "        [ 1.8341e-02, -1.1173e-02,  5.2344e-04,  ..., -1.9991e-02,\n",
      "         -2.2411e-02, -3.3856e-02],\n",
      "        [ 3.7536e-03, -9.3209e-03, -2.8311e-03,  ..., -2.9424e-03,\n",
      "          1.1164e-02, -6.8485e-03],\n",
      "        ...,\n",
      "        [-1.4125e-02, -1.2276e-02, -1.0340e-02,  ..., -6.0606e-03,\n",
      "         -6.8810e-03, -3.1479e-03],\n",
      "        [ 1.6846e-02, -1.6222e-02,  3.4544e-02,  ...,  1.0053e-02,\n",
      "          2.7618e-02,  1.0607e-02],\n",
      "        [ 1.6063e-03,  1.1638e-02, -8.6593e-03,  ...,  2.2796e-03,\n",
      "         -6.1538e-03, -1.5334e-02]], requires_grad=True))\n",
      "('blocks.28.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.7169, -0.8631, -0.0738,  ..., -0.0467, -0.4103, -0.0730],\n",
      "       requires_grad=True))\n",
      "('blocks.28.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0153,  0.0073, -0.0130,  ...,  0.0015, -0.0023, -0.0050],\n",
      "        [ 0.0107,  0.0002, -0.0020,  ...,  0.0016,  0.0078,  0.0180],\n",
      "        [-0.0044,  0.0051, -0.0062,  ...,  0.0110, -0.0183,  0.0125],\n",
      "        ...,\n",
      "        [-0.0129, -0.0202,  0.0043,  ...,  0.0100, -0.0001, -0.0040],\n",
      "        [ 0.0003,  0.0088, -0.0067,  ..., -0.0002, -0.0031,  0.0067],\n",
      "        [-0.0173,  0.0326,  0.0107,  ...,  0.0102, -0.0013,  0.0096]],\n",
      "       requires_grad=True))\n",
      "('blocks.28.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0328, -0.1769,  0.0839,  ...,  0.0508,  0.0542, -0.0528],\n",
      "       requires_grad=True))\n",
      "('blocks.29.norm1.weight', Parameter containing:\n",
      "tensor([1.9468, 1.6738, 1.7570,  ..., 1.6796, 1.8023, 1.8985],\n",
      "       requires_grad=True))\n",
      "('blocks.29.norm1.bias', Parameter containing:\n",
      "tensor([ 0.1812,  0.1983, -0.2349,  ..., -0.1380,  0.4812,  0.1958],\n",
      "       requires_grad=True))\n",
      "('blocks.29.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.0104, -0.3441,  0.1351,  ...,  0.5449,  0.2390,  0.4775],\n",
      "       requires_grad=True))\n",
      "('blocks.29.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0077, -0.0011,  0.0295,  ...,  0.0222,  0.0220,  0.0664],\n",
      "       requires_grad=True))\n",
      "('blocks.29.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0202, -0.0034, -0.0089,  ..., -0.0064, -0.0169, -0.0142],\n",
      "        [ 0.0201,  0.0086,  0.0162,  ..., -0.0037, -0.0139, -0.0118],\n",
      "        [ 0.0032,  0.0056,  0.0230,  ..., -0.0042,  0.0008, -0.0167],\n",
      "        ...,\n",
      "        [ 0.0088, -0.0153,  0.0164,  ...,  0.0055, -0.0090,  0.0181],\n",
      "        [-0.0030,  0.0091,  0.0087,  ..., -0.0005, -0.0100,  0.0024],\n",
      "        [ 0.0065,  0.0030,  0.0348,  ..., -0.0100,  0.0037,  0.0029]],\n",
      "       requires_grad=True))\n",
      "('blocks.29.attn.proj.weight', Parameter containing:\n",
      "tensor([[-7.7610e-05,  1.1544e-02,  2.1422e-03,  ..., -2.4631e-02,\n",
      "          6.9638e-03,  1.8499e-04],\n",
      "        [-2.1738e-03, -1.4263e-02, -7.3554e-04,  ..., -1.4588e-03,\n",
      "          1.3034e-02, -3.6653e-03],\n",
      "        [ 3.5371e-03, -1.4532e-04,  1.5107e-03,  ..., -5.4354e-03,\n",
      "          3.1511e-03, -2.5017e-02],\n",
      "        ...,\n",
      "        [ 9.1803e-04,  5.1582e-03,  1.1507e-02,  ..., -5.8415e-03,\n",
      "          8.4665e-03, -2.4984e-02],\n",
      "        [-5.0177e-03, -1.6938e-02, -1.6399e-02,  ..., -1.5479e-03,\n",
      "          1.0453e-02, -3.2697e-03],\n",
      "        [ 2.4226e-02, -1.6685e-02, -1.8265e-02,  ..., -5.6132e-03,\n",
      "          1.0532e-02, -8.5818e-03]], requires_grad=True))\n",
      "('blocks.29.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0151,  0.0397,  0.0192,  ...,  0.0166, -0.0459,  0.0592],\n",
      "       requires_grad=True))\n",
      "('blocks.29.norm2.weight', Parameter containing:\n",
      "tensor([1.7850, 1.5893, 1.6934,  ..., 1.5915, 1.6718, 1.7933],\n",
      "       requires_grad=True))\n",
      "('blocks.29.norm2.bias', Parameter containing:\n",
      "tensor([ 0.2061,  0.1024, -0.1545,  ..., -0.1084,  0.7672,  0.1743],\n",
      "       requires_grad=True))\n",
      "('blocks.29.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0007, -0.0154, -0.0169,  ...,  0.0211, -0.0239, -0.0039],\n",
      "        [-0.0107,  0.0338, -0.0141,  ...,  0.0068, -0.0068, -0.0036],\n",
      "        [ 0.0097, -0.0061,  0.0071,  ...,  0.0097,  0.0085, -0.0126],\n",
      "        ...,\n",
      "        [-0.0086, -0.0084, -0.0032,  ...,  0.0245, -0.0158,  0.0008],\n",
      "        [-0.0036,  0.0031,  0.0061,  ..., -0.0069,  0.0022, -0.0040],\n",
      "        [ 0.0010,  0.0026, -0.0054,  ...,  0.0157, -0.0043,  0.0162]],\n",
      "       requires_grad=True))\n",
      "('blocks.29.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-7.9458e-01, -7.8924e-01,  7.3078e-02,  ..., -3.8461e-01,\n",
      "        -1.3190e-02,  6.7667e-04], requires_grad=True))\n",
      "('blocks.29.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0009, -0.0024, -0.0104,  ...,  0.0082,  0.0028, -0.0026],\n",
      "        [-0.0293,  0.0154,  0.0020,  ...,  0.0022, -0.0054,  0.0098],\n",
      "        [-0.0198, -0.0060, -0.0026,  ...,  0.0056, -0.0167, -0.0069],\n",
      "        ...,\n",
      "        [ 0.0104,  0.0251,  0.0003,  ..., -0.0167,  0.0079, -0.0094],\n",
      "        [-0.0183,  0.0143, -0.0092,  ...,  0.0035, -0.0016, -0.0082],\n",
      "        [-0.0016,  0.0074,  0.0011,  ..., -0.0018,  0.0149,  0.0032]],\n",
      "       requires_grad=True))\n",
      "('blocks.29.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0120, -0.1148,  0.0027,  ...,  0.0050,  0.1211, -0.0272],\n",
      "       requires_grad=True))\n",
      "('blocks.30.norm1.weight', Parameter containing:\n",
      "tensor([1.9639, 1.7171, 1.7648,  ..., 1.6882, 1.8114, 1.9689],\n",
      "       requires_grad=True))\n",
      "('blocks.30.norm1.bias', Parameter containing:\n",
      "tensor([ 0.2904,  0.4221, -0.4542,  ..., -0.1201,  0.5064,  0.1800],\n",
      "       requires_grad=True))\n",
      "('blocks.30.attn.q_bias', Parameter containing:\n",
      "tensor([-0.2612, -0.5440, -0.8345,  ..., -0.4752, -0.4302, -0.8812],\n",
      "       requires_grad=True))\n",
      "('blocks.30.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0275, -0.0151,  0.0514,  ..., -0.0102, -0.0140,  0.0069],\n",
      "       requires_grad=True))\n",
      "('blocks.30.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-1.9320e-04, -3.1524e-03,  1.1178e-02,  ..., -1.1147e-03,\n",
      "         -4.2783e-03,  1.6814e-02],\n",
      "        [-2.4829e-02,  2.8028e-02, -9.8566e-03,  ...,  2.0525e-03,\n",
      "         -1.2855e-02,  2.9903e-03],\n",
      "        [-7.6511e-04, -2.3382e-03,  4.8505e-03,  ...,  1.0732e-02,\n",
      "          2.4735e-03,  1.3223e-02],\n",
      "        ...,\n",
      "        [-1.6208e-02, -6.8727e-03,  2.7876e-02,  ...,  2.3337e-03,\n",
      "         -1.8788e-03,  4.8474e-03],\n",
      "        [ 4.1581e-03, -5.6392e-03, -1.1022e-02,  ..., -1.6043e-03,\n",
      "          3.4360e-05, -7.4555e-03],\n",
      "        [ 3.2451e-02, -1.0767e-02, -8.3039e-03,  ..., -7.4295e-03,\n",
      "          2.5634e-02,  2.4183e-02]], requires_grad=True))\n",
      "('blocks.30.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0100, -0.0262, -0.0014,  ..., -0.0047, -0.0106,  0.0122],\n",
      "        [-0.0024,  0.0070, -0.0329,  ...,  0.0171,  0.0176, -0.0097],\n",
      "        [-0.0033, -0.0013,  0.0119,  ..., -0.0092,  0.0075,  0.0119],\n",
      "        ...,\n",
      "        [-0.0151, -0.0002,  0.0019,  ...,  0.0148, -0.0038, -0.0082],\n",
      "        [-0.0047, -0.0105, -0.0057,  ...,  0.0023, -0.0156,  0.0138],\n",
      "        [-0.0217,  0.0065, -0.0054,  ..., -0.0009, -0.0004, -0.0086]],\n",
      "       requires_grad=True))\n",
      "('blocks.30.attn.proj.bias', Parameter containing:\n",
      "tensor([0.0231, 0.0329, 0.0418,  ..., 0.0029, 0.0174, 0.0549],\n",
      "       requires_grad=True))\n",
      "('blocks.30.norm2.weight', Parameter containing:\n",
      "tensor([1.8891, 1.6926, 1.7773,  ..., 1.6755, 1.7924, 1.9208],\n",
      "       requires_grad=True))\n",
      "('blocks.30.norm2.bias', Parameter containing:\n",
      "tensor([ 0.3549,  0.3337, -0.5774,  ..., -0.3035,  0.7317,  0.1831],\n",
      "       requires_grad=True))\n",
      "('blocks.30.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0077, -0.0055, -0.0132,  ...,  0.0006,  0.0206, -0.0076],\n",
      "        [-0.0063, -0.0051, -0.0069,  ...,  0.0194, -0.0023,  0.0060],\n",
      "        [-0.0021,  0.0034, -0.0145,  ..., -0.0071,  0.0071, -0.0091],\n",
      "        ...,\n",
      "        [-0.0200, -0.0032,  0.0078,  ..., -0.0082,  0.0104,  0.0182],\n",
      "        [ 0.0021,  0.0068,  0.0162,  ..., -0.0052, -0.0162,  0.0031],\n",
      "        [ 0.0001, -0.0109,  0.0169,  ...,  0.0037,  0.0167, -0.0136]],\n",
      "       requires_grad=True))\n",
      "('blocks.30.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.9664,  0.0130, -0.0037,  ..., -0.0108, -0.6397, -0.4601],\n",
      "       requires_grad=True))\n",
      "('blocks.30.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0154, -0.0058, -0.0184,  ...,  0.0203, -0.0106,  0.0019],\n",
      "        [-0.0182,  0.0151,  0.0151,  ..., -0.0009,  0.0282,  0.0056],\n",
      "        [-0.0243,  0.0136,  0.0048,  ...,  0.0001, -0.0007,  0.0060],\n",
      "        ...,\n",
      "        [-0.0049, -0.0061, -0.0035,  ...,  0.0098,  0.0014,  0.0126],\n",
      "        [ 0.0096,  0.0059, -0.0132,  ...,  0.0054,  0.0118, -0.0192],\n",
      "        [-0.0139, -0.0030,  0.0107,  ..., -0.0045, -0.0067, -0.0146]],\n",
      "       requires_grad=True))\n",
      "('blocks.30.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0113, -0.1037,  0.0300,  ..., -0.0147,  0.1018, -0.0847],\n",
      "       requires_grad=True))\n",
      "('blocks.31.norm1.weight', Parameter containing:\n",
      "tensor([1.9651, 1.7515, 1.8273,  ..., 1.7286, 1.8709, 1.9766],\n",
      "       requires_grad=True))\n",
      "('blocks.31.norm1.bias', Parameter containing:\n",
      "tensor([ 0.3538,  0.5966, -0.7064,  ..., -0.0976,  0.4258,  0.2070],\n",
      "       requires_grad=True))\n",
      "('blocks.31.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.5931, -0.7075,  0.0389,  ..., -0.0873, -0.1987,  0.2903],\n",
      "       requires_grad=True))\n",
      "('blocks.31.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0290, -0.0010, -0.0149,  ..., -0.0310,  0.0304,  0.0163],\n",
      "       requires_grad=True))\n",
      "('blocks.31.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0205,  0.0040, -0.0107,  ..., -0.0132,  0.0172, -0.0272],\n",
      "        [-0.0036, -0.0140,  0.0083,  ...,  0.0087,  0.0071, -0.0114],\n",
      "        [ 0.0120,  0.0285, -0.0372,  ..., -0.0337, -0.0083, -0.0148],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0017,  0.0028,  ...,  0.0072,  0.0055,  0.0083],\n",
      "        [ 0.0133, -0.0120, -0.0155,  ...,  0.0139,  0.0037, -0.0199],\n",
      "        [ 0.0278, -0.0157,  0.0115,  ..., -0.0017,  0.0262, -0.0020]],\n",
      "       requires_grad=True))\n",
      "('blocks.31.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 8.0238e-03,  1.1602e-04,  7.8129e-03,  ...,  1.1216e-03,\n",
      "         -1.1344e-02, -1.6271e-02],\n",
      "        [ 4.6261e-03,  1.5440e-02,  1.7679e-03,  ...,  8.6805e-03,\n",
      "          3.1513e-03, -4.0913e-03],\n",
      "        [-3.0713e-05, -4.5746e-03,  1.5795e-02,  ...,  8.4579e-03,\n",
      "         -3.4968e-03,  1.7664e-02],\n",
      "        ...,\n",
      "        [ 2.8166e-03,  1.2293e-02, -7.7146e-04,  ..., -1.1491e-02,\n",
      "         -1.3380e-02,  5.5206e-03],\n",
      "        [-6.9413e-03,  1.6855e-02, -6.1431e-03,  ..., -8.0441e-03,\n",
      "         -1.4661e-03, -3.8946e-03],\n",
      "        [-1.4011e-03,  7.2819e-03,  5.9810e-03,  ...,  5.3537e-03,\n",
      "         -1.0221e-02,  9.5707e-03]], requires_grad=True))\n",
      "('blocks.31.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0168,  0.0261,  0.0639,  ..., -0.0114,  0.0383,  0.0242],\n",
      "       requires_grad=True))\n",
      "('blocks.31.norm2.weight', Parameter containing:\n",
      "tensor([2.0179, 1.7815, 1.8962,  ..., 1.7729, 1.9204, 2.0354],\n",
      "       requires_grad=True))\n",
      "('blocks.31.norm2.bias', Parameter containing:\n",
      "tensor([ 0.5249,  0.5372, -0.8955,  ..., -0.4056,  0.4869,  0.3953],\n",
      "       requires_grad=True))\n",
      "('blocks.31.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-1.0334e-03,  4.0493e-03,  9.4922e-03,  ...,  7.5266e-03,\n",
      "         -5.5183e-04,  5.6855e-03],\n",
      "        [ 5.8268e-06,  4.8195e-03, -1.8975e-02,  ...,  2.1549e-02,\n",
      "          1.1069e-02,  6.6887e-03],\n",
      "        [-1.2917e-02,  7.9619e-03, -5.7700e-03,  ...,  1.6786e-02,\n",
      "          8.1642e-03, -1.7850e-04],\n",
      "        ...,\n",
      "        [-5.3321e-03,  1.3459e-03,  7.8335e-03,  ..., -1.4683e-04,\n",
      "          4.8023e-03,  1.2506e-02],\n",
      "        [ 1.2063e-02, -1.0775e-02, -1.0625e-03,  ...,  2.4489e-02,\n",
      "         -1.4746e-03,  1.2942e-02],\n",
      "        [ 5.6716e-03, -7.3497e-03,  1.2611e-02,  ...,  1.1443e-02,\n",
      "         -2.1103e-03,  5.2491e-03]], requires_grad=True))\n",
      "('blocks.31.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1325, -0.4032, -0.0727,  ..., -0.4428,  0.0947, -0.2426],\n",
      "       requires_grad=True))\n",
      "('blocks.31.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0169, -0.0117,  0.0041,  ..., -0.0129,  0.0050,  0.0119],\n",
      "        [-0.0037, -0.0003,  0.0060,  ...,  0.0053,  0.0124,  0.0041],\n",
      "        [-0.0061, -0.0012, -0.0076,  ...,  0.0069, -0.0036,  0.0078],\n",
      "        ...,\n",
      "        [ 0.0061,  0.0036, -0.0069,  ..., -0.0070, -0.0011, -0.0148],\n",
      "        [ 0.0086,  0.0180,  0.0277,  ...,  0.0042,  0.0017, -0.0020],\n",
      "        [-0.0158,  0.0102,  0.0121,  ...,  0.0074, -0.0063, -0.0124]],\n",
      "       requires_grad=True))\n",
      "('blocks.31.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0136, -0.0624, -0.0080,  ..., -0.1302,  0.1422, -0.0306],\n",
      "       requires_grad=True))\n",
      "('blocks.32.norm1.weight', Parameter containing:\n",
      "tensor([2.0663, 1.8713, 1.9102,  ..., 1.8262, 1.9962, 2.1778],\n",
      "       requires_grad=True))\n",
      "('blocks.32.norm1.bias', Parameter containing:\n",
      "tensor([ 0.4753,  0.7207, -0.8585,  ..., -0.0523,  0.2245,  0.2799],\n",
      "       requires_grad=True))\n",
      "('blocks.32.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.0102, -0.2258, -0.2275,  ...,  0.0155,  0.3296, -0.0158],\n",
      "       requires_grad=True))\n",
      "('blocks.32.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0187,  0.0444, -0.0130,  ..., -0.0126, -0.0195,  0.0258],\n",
      "       requires_grad=True))\n",
      "('blocks.32.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0223,  0.0051, -0.0057,  ...,  0.0120,  0.0144,  0.0090],\n",
      "        [ 0.0063, -0.0257,  0.0189,  ...,  0.0078, -0.0053,  0.0037],\n",
      "        [-0.0194, -0.0226,  0.0096,  ...,  0.0064,  0.0029, -0.0218],\n",
      "        ...,\n",
      "        [ 0.0044,  0.0019,  0.0234,  ..., -0.0032,  0.0049,  0.0101],\n",
      "        [ 0.0012, -0.0003,  0.0130,  ..., -0.0084, -0.0169,  0.0089],\n",
      "        [-0.0027, -0.0216,  0.0026,  ..., -0.0107,  0.0353, -0.0092]],\n",
      "       requires_grad=True))\n",
      "('blocks.32.attn.proj.weight', Parameter containing:\n",
      "tensor([[-1.6584e-03, -8.8515e-04,  9.7378e-04,  ..., -2.2129e-02,\n",
      "          1.0895e-02, -8.1516e-03],\n",
      "        [ 2.5879e-02, -1.7441e-02,  1.6180e-03,  ..., -8.0476e-04,\n",
      "         -1.6075e-03,  2.0615e-02],\n",
      "        [ 1.8390e-02,  9.2619e-03,  4.9616e-03,  ...,  8.1377e-07,\n",
      "         -3.9151e-03,  8.1127e-03],\n",
      "        ...,\n",
      "        [-2.2124e-03, -7.8843e-04, -3.5624e-03,  ..., -5.1830e-04,\n",
      "          2.0115e-02,  1.0891e-02],\n",
      "        [ 2.3967e-03,  2.4056e-02, -7.1427e-03,  ...,  1.6058e-02,\n",
      "         -1.0049e-03, -1.5787e-02],\n",
      "        [ 1.1434e-02,  8.4165e-03, -1.5735e-02,  ..., -8.0714e-04,\n",
      "         -1.2962e-02, -1.3720e-02]], requires_grad=True))\n",
      "('blocks.32.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0321,  0.0319,  0.0056,  ..., -0.0177,  0.0305,  0.0382],\n",
      "       requires_grad=True))\n",
      "('blocks.32.norm2.weight', Parameter containing:\n",
      "tensor([2.1586, 1.8890, 2.0235,  ..., 1.8996, 2.0448, 2.1777],\n",
      "       requires_grad=True))\n",
      "('blocks.32.norm2.bias', Parameter containing:\n",
      "tensor([ 0.5476,  0.8092, -0.9356,  ..., -0.2758,  0.2174,  0.4459],\n",
      "       requires_grad=True))\n",
      "('blocks.32.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0005,  0.0054,  0.0199,  ...,  0.0039, -0.0202,  0.0012],\n",
      "        [-0.0069,  0.0030, -0.0008,  ...,  0.0105,  0.0050, -0.0082],\n",
      "        [-0.0078, -0.0115, -0.0065,  ..., -0.0272, -0.0106,  0.0015],\n",
      "        ...,\n",
      "        [ 0.0007, -0.0127,  0.0035,  ..., -0.0205, -0.0164, -0.0014],\n",
      "        [ 0.0092, -0.0045,  0.0199,  ..., -0.0004, -0.0128, -0.0079],\n",
      "        [ 0.0111, -0.0082, -0.0096,  ...,  0.0057,  0.0064, -0.0022]],\n",
      "       requires_grad=True))\n",
      "('blocks.32.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.6295, -0.2492,  0.0526,  ..., -0.2626, -0.1077, -0.1475],\n",
      "       requires_grad=True))\n",
      "('blocks.32.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0031,  0.0089,  0.0137,  ...,  0.0140, -0.0031, -0.0066],\n",
      "        [-0.0161, -0.0033, -0.0031,  ...,  0.0031,  0.0240,  0.0052],\n",
      "        [-0.0032,  0.0018,  0.0137,  ...,  0.0040, -0.0017,  0.0048],\n",
      "        ...,\n",
      "        [-0.0081, -0.0044, -0.0004,  ..., -0.0050,  0.0137, -0.0023],\n",
      "        [-0.0085, -0.0059,  0.0107,  ..., -0.0021,  0.0055, -0.0021],\n",
      "        [-0.0050,  0.0156, -0.0042,  ...,  0.0017,  0.0039, -0.0059]],\n",
      "       requires_grad=True))\n",
      "('blocks.32.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0540, -0.0604, -0.0950,  ..., -0.0675,  0.1670, -0.0221],\n",
      "       requires_grad=True))\n",
      "('blocks.33.norm1.weight', Parameter containing:\n",
      "tensor([2.0199, 1.8712, 1.9281,  ..., 1.7780, 1.9433, 2.1114],\n",
      "       requires_grad=True))\n",
      "('blocks.33.norm1.bias', Parameter containing:\n",
      "tensor([ 0.4319,  0.8154, -0.7708,  ...,  0.0739,  0.0353,  0.2035],\n",
      "       requires_grad=True))\n",
      "('blocks.33.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.2931,  0.1085, -0.0296,  ...,  0.2087,  0.3511,  0.3537],\n",
      "       requires_grad=True))\n",
      "('blocks.33.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0262,  0.0851,  0.0458,  ..., -0.1449,  0.0570,  0.1556],\n",
      "       requires_grad=True))\n",
      "('blocks.33.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0147,  0.0014, -0.0102,  ...,  0.0019, -0.0005, -0.0284],\n",
      "        [ 0.0045, -0.0054,  0.0084,  ...,  0.0153,  0.0156, -0.0227],\n",
      "        [-0.0075, -0.0043,  0.0137,  ...,  0.0046,  0.0073,  0.0079],\n",
      "        ...,\n",
      "        [ 0.0101, -0.0272, -0.0036,  ..., -0.0121, -0.0092,  0.0098],\n",
      "        [-0.0008, -0.0055, -0.0103,  ..., -0.0046,  0.0165,  0.0131],\n",
      "        [-0.0123, -0.0049,  0.0077,  ...,  0.0075,  0.0126, -0.0043]],\n",
      "       requires_grad=True))\n",
      "('blocks.33.attn.proj.weight', Parameter containing:\n",
      "tensor([[ 0.0010, -0.0113, -0.0143,  ..., -0.0052, -0.0018,  0.0020],\n",
      "        [ 0.0160,  0.0179,  0.0241,  ...,  0.0210,  0.0092,  0.0076],\n",
      "        [-0.0003,  0.0004, -0.0053,  ...,  0.0034,  0.0079, -0.0127],\n",
      "        ...,\n",
      "        [ 0.0177, -0.0063,  0.0040,  ...,  0.0018,  0.0130,  0.0116],\n",
      "        [-0.0016,  0.0046,  0.0232,  ...,  0.0223, -0.0067,  0.0047],\n",
      "        [ 0.0079,  0.0181, -0.0014,  ...,  0.0048,  0.0124,  0.0091]],\n",
      "       requires_grad=True))\n",
      "('blocks.33.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0571,  0.0371, -0.0144,  ..., -0.0162,  0.0550,  0.0390],\n",
      "       requires_grad=True))\n",
      "('blocks.33.norm2.weight', Parameter containing:\n",
      "tensor([2.2888, 2.0021, 2.1541,  ..., 2.0308, 2.2032, 2.3307],\n",
      "       requires_grad=True))\n",
      "('blocks.33.norm2.bias', Parameter containing:\n",
      "tensor([ 0.4355,  0.9612, -0.8471,  ..., -0.2260, -0.0739,  0.3577],\n",
      "       requires_grad=True))\n",
      "('blocks.33.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0025,  0.0028,  0.0028,  ..., -0.0058, -0.0027, -0.0239],\n",
      "        [ 0.0066, -0.0104, -0.0022,  ...,  0.0059, -0.0277, -0.0204],\n",
      "        [ 0.0017, -0.0161, -0.0078,  ..., -0.0091, -0.0254,  0.0061],\n",
      "        ...,\n",
      "        [-0.0248,  0.0074,  0.0053,  ...,  0.0278, -0.0100, -0.0157],\n",
      "        [-0.0028,  0.0153, -0.0064,  ..., -0.0032, -0.0025,  0.0047],\n",
      "        [ 0.0068, -0.0056, -0.0110,  ..., -0.0061, -0.0038, -0.0137]],\n",
      "       requires_grad=True))\n",
      "('blocks.33.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1289, -0.3249, -0.0610,  ..., -0.6116,  0.0131, -0.1124],\n",
      "       requires_grad=True))\n",
      "('blocks.33.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 1.7235e-03, -4.4625e-03,  5.7592e-03,  ..., -1.8296e-02,\n",
      "         -1.1226e-02, -4.6767e-03],\n",
      "        [-9.5154e-06, -7.2462e-03,  3.5365e-03,  ..., -6.0502e-03,\n",
      "         -1.4875e-02, -1.2476e-02],\n",
      "        [-1.0286e-02, -2.3955e-02, -8.8852e-03,  ..., -1.0516e-02,\n",
      "         -2.0125e-03,  1.0026e-02],\n",
      "        ...,\n",
      "        [-5.3148e-04,  3.4510e-03, -1.7868e-02,  ..., -8.6967e-03,\n",
      "          1.3775e-02,  4.2014e-03],\n",
      "        [ 1.5761e-03, -2.5932e-02,  5.9334e-04,  ..., -1.7044e-02,\n",
      "         -1.0122e-02,  2.3381e-02],\n",
      "        [ 3.6594e-03, -5.7835e-03,  1.3743e-03,  ..., -1.4239e-02,\n",
      "         -1.6718e-02,  2.2623e-03]], requires_grad=True))\n",
      "('blocks.33.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0268, -0.0402, -0.0775,  ..., -0.0352,  0.0955, -0.0387],\n",
      "       requires_grad=True))\n",
      "('blocks.34.norm1.weight', Parameter containing:\n",
      "tensor([2.1067, 1.9473, 2.0430,  ..., 1.8552, 2.0644, 2.1889],\n",
      "       requires_grad=True))\n",
      "('blocks.34.norm1.bias', Parameter containing:\n",
      "tensor([ 0.3500,  0.9218, -0.6421,  ...,  0.1427, -0.1003,  0.1443],\n",
      "       requires_grad=True))\n",
      "('blocks.34.attn.q_bias', Parameter containing:\n",
      "tensor([-0.2773,  0.2875, -0.3304,  ..., -0.0786,  0.2981, -0.1377],\n",
      "       requires_grad=True))\n",
      "('blocks.34.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0920,  0.0127,  0.0296,  ..., -0.0011,  0.0324,  0.0651],\n",
      "       requires_grad=True))\n",
      "('blocks.34.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-0.0038, -0.0139, -0.0065,  ...,  0.0041, -0.0124,  0.0030],\n",
      "        [-0.0095, -0.0065,  0.0242,  ...,  0.0159, -0.0308,  0.0037],\n",
      "        [ 0.0029, -0.0065,  0.0325,  ..., -0.0022,  0.0130, -0.0114],\n",
      "        ...,\n",
      "        [ 0.0036,  0.0240,  0.0139,  ..., -0.0122,  0.0041, -0.0183],\n",
      "        [-0.0225, -0.0095, -0.0017,  ...,  0.0099,  0.0012, -0.0072],\n",
      "        [ 0.0060,  0.0040, -0.0063,  ..., -0.0177, -0.0023, -0.0186]],\n",
      "       requires_grad=True))\n",
      "('blocks.34.attn.proj.weight', Parameter containing:\n",
      "tensor([[-4.9402e-03,  4.9212e-04, -4.2816e-03,  ..., -2.3684e-02,\n",
      "          1.4256e-02,  2.4927e-02],\n",
      "        [-1.4833e-03, -6.8065e-03, -4.9166e-03,  ..., -1.4556e-02,\n",
      "         -9.7573e-05, -4.2596e-03],\n",
      "        [ 2.3598e-02, -2.8935e-02, -7.5481e-03,  ..., -1.7219e-02,\n",
      "          1.9841e-03, -3.2929e-03],\n",
      "        ...,\n",
      "        [ 1.0632e-02, -1.6624e-02,  3.8980e-03,  ...,  1.8771e-02,\n",
      "          5.0025e-03, -2.2590e-04],\n",
      "        [-3.2527e-02,  3.4844e-03, -2.3691e-03,  ..., -1.0300e-03,\n",
      "         -4.0078e-03,  9.7225e-03],\n",
      "        [ 1.0677e-02,  6.9685e-03, -3.7095e-03,  ...,  1.7949e-02,\n",
      "          1.2082e-02, -8.1689e-03]], requires_grad=True))\n",
      "('blocks.34.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0801,  0.0805, -0.0582,  ...,  0.0314,  0.0293,  0.0426],\n",
      "       requires_grad=True))\n",
      "('blocks.34.norm2.weight', Parameter containing:\n",
      "tensor([2.4530, 2.1680, 2.2948,  ..., 2.1719, 2.3592, 2.5063],\n",
      "       requires_grad=True))\n",
      "('blocks.34.norm2.bias', Parameter containing:\n",
      "tensor([ 0.3037,  0.9718, -0.5452,  ..., -0.2885, -0.2426,  0.2550],\n",
      "       requires_grad=True))\n",
      "('blocks.34.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[-0.0048, -0.0152, -0.0065,  ...,  0.0049,  0.0010, -0.0011],\n",
      "        [ 0.0002,  0.0191, -0.0101,  ...,  0.0018, -0.0207, -0.0011],\n",
      "        [ 0.0061,  0.0005, -0.0094,  ...,  0.0216, -0.0093,  0.0098],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0304, -0.0181,  ..., -0.0014,  0.0099, -0.0284],\n",
      "        [-0.0080, -0.0256, -0.0065,  ..., -0.0113, -0.0095,  0.0060],\n",
      "        [ 0.0012, -0.0023,  0.0099,  ...,  0.0120, -0.0071,  0.0190]],\n",
      "       requires_grad=True))\n",
      "('blocks.34.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.0145, -0.1521, -0.0152,  ..., -0.3421, -0.0727, -0.1297],\n",
      "       requires_grad=True))\n",
      "('blocks.34.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0032, -0.0102, -0.0012,  ...,  0.0129, -0.0126,  0.0143],\n",
      "        [ 0.0059, -0.0039,  0.0114,  ..., -0.0191,  0.0134, -0.0147],\n",
      "        [ 0.0022,  0.0157,  0.0047,  ..., -0.0048, -0.0031, -0.0034],\n",
      "        ...,\n",
      "        [-0.0035, -0.0123, -0.0064,  ..., -0.0050,  0.0083, -0.0073],\n",
      "        [-0.0203,  0.0164, -0.0107,  ..., -0.0125, -0.0045, -0.0098],\n",
      "        [-0.0012,  0.0044, -0.0170,  ..., -0.0130,  0.0176, -0.0075]],\n",
      "       requires_grad=True))\n",
      "('blocks.34.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0523, -0.0482, -0.0932,  ..., -0.0409,  0.0888, -0.0434],\n",
      "       requires_grad=True))\n",
      "('blocks.35.norm1.weight', Parameter containing:\n",
      "tensor([2.1677, 2.0097, 2.0466,  ..., 1.9008, 2.0619, 2.2517],\n",
      "       requires_grad=True))\n",
      "('blocks.35.norm1.bias', Parameter containing:\n",
      "tensor([ 0.1634,  0.8221, -0.4139,  ...,  0.0524, -0.0966,  0.0466],\n",
      "       requires_grad=True))\n",
      "('blocks.35.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.6270,  0.3432,  0.0058,  ..., -0.1847,  0.2138,  0.3149],\n",
      "       requires_grad=True))\n",
      "('blocks.35.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0296, -0.0049,  0.0756,  ...,  0.0254,  0.0079, -0.0092],\n",
      "       requires_grad=True))\n",
      "('blocks.35.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0131, -0.0138,  0.0021,  ..., -0.0331,  0.0124,  0.0306],\n",
      "        [ 0.0091,  0.0255, -0.0094,  ..., -0.0046,  0.0207, -0.0248],\n",
      "        [ 0.0011,  0.0204,  0.0066,  ..., -0.0100,  0.0064,  0.0042],\n",
      "        ...,\n",
      "        [-0.0090, -0.0107,  0.0152,  ..., -0.0063, -0.0227,  0.0051],\n",
      "        [-0.0043,  0.0120,  0.0029,  ...,  0.0046,  0.0303,  0.0314],\n",
      "        [-0.0067,  0.0023,  0.0268,  ..., -0.0029, -0.0145, -0.0218]],\n",
      "       requires_grad=True))\n",
      "('blocks.35.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0002, -0.0102, -0.0234,  ..., -0.0054,  0.0040, -0.0048],\n",
      "        [-0.0099,  0.0275, -0.0089,  ..., -0.0094,  0.0067,  0.0202],\n",
      "        [-0.0091,  0.0019,  0.0054,  ...,  0.0060, -0.0066, -0.0053],\n",
      "        ...,\n",
      "        [ 0.0503, -0.0058, -0.0073,  ..., -0.0131, -0.0045, -0.0054],\n",
      "        [-0.0084,  0.0043, -0.0085,  ..., -0.0207,  0.0006, -0.0213],\n",
      "        [-0.0028, -0.0065, -0.0002,  ..., -0.0103,  0.0098, -0.0068]],\n",
      "       requires_grad=True))\n",
      "('blocks.35.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0892,  0.2024, -0.0885,  ...,  0.1338, -0.0595,  0.0590],\n",
      "       requires_grad=True))\n",
      "('blocks.35.norm2.weight', Parameter containing:\n",
      "tensor([2.6347, 2.3297, 2.4923,  ..., 2.3552, 2.5013, 2.6761],\n",
      "       requires_grad=True))\n",
      "('blocks.35.norm2.bias', Parameter containing:\n",
      "tensor([ 0.1527,  0.6637, -0.1783,  ..., -0.5706, -0.0603,  0.1048],\n",
      "       requires_grad=True))\n",
      "('blocks.35.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0135,  0.0240, -0.0226,  ..., -0.0010, -0.0119, -0.0054],\n",
      "        [ 0.0169, -0.0029, -0.0011,  ..., -0.0065, -0.0153, -0.0040],\n",
      "        [ 0.0012, -0.0203, -0.0090,  ...,  0.0237, -0.0034,  0.0065],\n",
      "        ...,\n",
      "        [ 0.0168, -0.0108, -0.0222,  ..., -0.0063, -0.0039,  0.0004],\n",
      "        [ 0.0037, -0.0049, -0.0016,  ..., -0.0046,  0.0083, -0.0002],\n",
      "        [ 0.0169,  0.0115, -0.0214,  ...,  0.0099, -0.0079,  0.0152]],\n",
      "       requires_grad=True))\n",
      "('blocks.35.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1075, -0.1427, -0.0135,  ..., -0.3208, -0.1190, -0.5002],\n",
      "       requires_grad=True))\n",
      "('blocks.35.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0019, -0.0040, -0.0090,  ...,  0.0174,  0.0139,  0.0251],\n",
      "        [ 0.0042, -0.0015, -0.0141,  ...,  0.0093,  0.0153, -0.0052],\n",
      "        [ 0.0214,  0.0242, -0.0080,  ...,  0.0125, -0.0114, -0.0290],\n",
      "        ...,\n",
      "        [-0.0055,  0.0018, -0.0097,  ..., -0.0106, -0.0020, -0.0075],\n",
      "        [-0.0042,  0.0147,  0.0297,  ...,  0.0055, -0.0080, -0.0085],\n",
      "        [ 0.0184, -0.0048, -0.0398,  ...,  0.0058,  0.0128,  0.0087]],\n",
      "       requires_grad=True))\n",
      "('blocks.35.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0041,  0.0627, -0.0789,  ...,  0.1308,  0.0524, -0.0397],\n",
      "       requires_grad=True))\n",
      "('blocks.36.norm1.weight', Parameter containing:\n",
      "tensor([2.2053, 2.0156, 2.1169,  ..., 1.9683, 2.1583, 2.3241],\n",
      "       requires_grad=True))\n",
      "('blocks.36.norm1.bias', Parameter containing:\n",
      "tensor([ 0.0900,  0.5841, -0.2355,  ..., -0.2691, -0.0281, -0.0130],\n",
      "       requires_grad=True))\n",
      "('blocks.36.attn.q_bias', Parameter containing:\n",
      "tensor([ 0.1165, -0.7409, -0.5032,  ..., -0.7036, -0.0103,  0.1397],\n",
      "       requires_grad=True))\n",
      "('blocks.36.attn.v_bias', Parameter containing:\n",
      "tensor([-0.0580, -0.0048,  0.0727,  ...,  0.0862,  0.0930, -0.0961],\n",
      "       requires_grad=True))\n",
      "('blocks.36.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 0.0066, -0.0190,  0.0188,  ...,  0.0094,  0.0091, -0.0409],\n",
      "        [-0.0010, -0.0047,  0.0111,  ...,  0.0057,  0.0039,  0.0059],\n",
      "        [-0.0201, -0.0044,  0.0162,  ...,  0.0016,  0.0164,  0.0126],\n",
      "        ...,\n",
      "        [-0.0150, -0.0188, -0.0231,  ...,  0.0030, -0.0280,  0.0083],\n",
      "        [ 0.0212, -0.0353, -0.0248,  ..., -0.0228, -0.0197,  0.0008],\n",
      "        [-0.0044,  0.0351, -0.0044,  ..., -0.0179,  0.0128, -0.0025]],\n",
      "       requires_grad=True))\n",
      "('blocks.36.attn.proj.weight', Parameter containing:\n",
      "tensor([[-1.4651e-02,  1.1570e-02,  1.3881e-02,  ..., -2.8030e-03,\n",
      "         -1.5853e-02,  5.5327e-03],\n",
      "        [ 8.5201e-05, -2.5240e-02, -1.1739e-02,  ..., -2.2839e-02,\n",
      "          1.2433e-02, -2.2855e-02],\n",
      "        [-2.4402e-02,  1.0676e-02,  1.4061e-02,  ...,  7.6347e-03,\n",
      "          3.1255e-02, -1.5383e-02],\n",
      "        ...,\n",
      "        [-2.3681e-03,  6.6074e-03,  3.4109e-03,  ..., -3.2468e-02,\n",
      "          1.2589e-02,  1.2034e-02],\n",
      "        [-1.8299e-02, -5.0036e-06,  7.5474e-03,  ...,  2.8071e-02,\n",
      "          4.2819e-02, -1.3487e-03],\n",
      "        [ 1.8762e-03, -2.5018e-02,  1.5190e-02,  ..., -5.4580e-02,\n",
      "         -2.8561e-02, -3.9941e-03]], requires_grad=True))\n",
      "('blocks.36.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0603,  0.1845, -0.0667,  ...,  0.0469, -0.0285,  0.0504],\n",
      "       requires_grad=True))\n",
      "('blocks.36.norm2.weight', Parameter containing:\n",
      "tensor([2.7321, 2.4513, 2.6308,  ..., 2.4574, 2.6485, 2.7892],\n",
      "       requires_grad=True))\n",
      "('blocks.36.norm2.bias', Parameter containing:\n",
      "tensor([ 0.0379,  0.3686,  0.0098,  ..., -0.7038,  0.1946,  0.0201],\n",
      "       requires_grad=True))\n",
      "('blocks.36.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0078,  0.0207,  0.0166,  ...,  0.0098,  0.0032,  0.0027],\n",
      "        [ 0.0097,  0.0065, -0.0005,  ...,  0.0102, -0.0131,  0.0093],\n",
      "        [ 0.0075,  0.0126,  0.0134,  ..., -0.0072,  0.0206, -0.0096],\n",
      "        ...,\n",
      "        [-0.0013, -0.0209,  0.0100,  ...,  0.0119,  0.0024,  0.0071],\n",
      "        [-0.0117, -0.0128, -0.0119,  ...,  0.0235, -0.0181,  0.0152],\n",
      "        [-0.0036, -0.0014,  0.0055,  ..., -0.0091, -0.0053, -0.0199]],\n",
      "       requires_grad=True))\n",
      "('blocks.36.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1183,  0.0628,  0.2533,  ..., -0.1007, -0.2218, -0.0105],\n",
      "       requires_grad=True))\n",
      "('blocks.36.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[ 0.0233,  0.0052,  0.0062,  ...,  0.0231, -0.0019,  0.0178],\n",
      "        [ 0.0023, -0.0085, -0.0079,  ..., -0.0043,  0.0232, -0.0165],\n",
      "        [ 0.0109, -0.0022, -0.0003,  ...,  0.0261, -0.0407, -0.0091],\n",
      "        ...,\n",
      "        [ 0.0114, -0.0107,  0.0238,  ..., -0.0072,  0.0079, -0.0006],\n",
      "        [ 0.0102,  0.0179, -0.0222,  ...,  0.0028, -0.0114, -0.0242],\n",
      "        [ 0.0405,  0.0082,  0.0014,  ..., -0.0008,  0.0131, -0.0265]],\n",
      "       requires_grad=True))\n",
      "('blocks.36.mlp.fc2.bias', Parameter containing:\n",
      "tensor([0.0124, 0.0074, 0.0675,  ..., 0.2501, 0.0358, 0.0073],\n",
      "       requires_grad=True))\n",
      "('blocks.37.norm1.weight', Parameter containing:\n",
      "tensor([2.3241, 2.0683, 2.2029,  ..., 1.9969, 2.2281, 2.3941],\n",
      "       requires_grad=True))\n",
      "('blocks.37.norm1.bias', Parameter containing:\n",
      "tensor([-0.0052,  0.3948, -0.2416,  ..., -0.4549,  0.0426, -0.1216],\n",
      "       requires_grad=True))\n",
      "('blocks.37.attn.q_bias', Parameter containing:\n",
      "tensor([-0.3095,  0.0472, -0.2801,  ...,  0.0732,  0.6521, -0.0658],\n",
      "       requires_grad=True))\n",
      "('blocks.37.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0007, -0.0004, -0.0571,  ...,  0.0415,  0.0386, -0.0063],\n",
      "       requires_grad=True))\n",
      "('blocks.37.attn.qkv.weight', Parameter containing:\n",
      "tensor([[-1.1390e-02, -6.5648e-03,  6.6570e-04,  ..., -6.2809e-03,\n",
      "         -2.6439e-02, -1.9177e-02],\n",
      "        [-1.6475e-02, -1.5442e-02, -2.9605e-02,  ..., -3.4470e-03,\n",
      "         -1.6563e-02,  3.1803e-02],\n",
      "        [-2.0488e-02,  2.3522e-03, -2.2970e-02,  ...,  1.7501e-02,\n",
      "         -1.0301e-02, -1.2435e-02],\n",
      "        ...,\n",
      "        [-2.1112e-03,  2.1680e-02, -5.8232e-03,  ..., -1.0842e-02,\n",
      "          3.8924e-02,  5.3826e-05],\n",
      "        [ 2.5653e-02,  1.2979e-02, -1.0698e-02,  ...,  4.7140e-02,\n",
      "         -6.2196e-03, -1.5780e-02],\n",
      "        [ 2.4155e-02, -3.5792e-02, -1.4200e-03,  ...,  2.3243e-02,\n",
      "          3.7766e-02,  1.5906e-02]], requires_grad=True))\n",
      "('blocks.37.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0257,  0.0184,  0.0119,  ...,  0.0027, -0.0054, -0.0132],\n",
      "        [ 0.0018, -0.0239,  0.0016,  ...,  0.0006,  0.0061,  0.0013],\n",
      "        [-0.0077,  0.0168, -0.0015,  ...,  0.0146, -0.0267, -0.0320],\n",
      "        ...,\n",
      "        [ 0.0113,  0.0235,  0.0082,  ..., -0.0027, -0.0175,  0.0172],\n",
      "        [-0.0169, -0.0176, -0.0070,  ...,  0.0092,  0.0037, -0.0131],\n",
      "        [ 0.0141,  0.0045,  0.0086,  ...,  0.0004, -0.0110,  0.0296]],\n",
      "       requires_grad=True))\n",
      "('blocks.37.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.0970,  0.1950, -0.2041,  ..., -0.1164, -0.0682, -0.0204],\n",
      "       requires_grad=True))\n",
      "('blocks.37.norm2.weight', Parameter containing:\n",
      "tensor([2.8479, 2.5855, 2.7485,  ..., 2.5860, 2.7653, 2.9025],\n",
      "       requires_grad=True))\n",
      "('blocks.37.norm2.bias', Parameter containing:\n",
      "tensor([-0.0013,  0.1484,  0.2144,  ..., -0.6265,  0.3829,  0.0593],\n",
      "       requires_grad=True))\n",
      "('blocks.37.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 0.0089,  0.0017,  0.0086,  ...,  0.0208, -0.0116, -0.0032],\n",
      "        [ 0.0219, -0.0060,  0.0061,  ..., -0.0005,  0.0071, -0.0038],\n",
      "        [-0.0146,  0.0117, -0.0013,  ..., -0.0418, -0.0150,  0.0046],\n",
      "        ...,\n",
      "        [ 0.0044, -0.0058, -0.0054,  ...,  0.0148, -0.0002, -0.0182],\n",
      "        [ 0.0102, -0.0177, -0.0041,  ...,  0.0147,  0.0076, -0.0208],\n",
      "        [-0.0157, -0.0098, -0.0069,  ...,  0.0104,  0.0080,  0.0132]],\n",
      "       requires_grad=True))\n",
      "('blocks.37.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.1349, -0.0728, -0.1107,  ..., -0.0939, -0.1509, -0.0834],\n",
      "       requires_grad=True))\n",
      "('blocks.37.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0027,  0.0171, -0.0115,  ..., -0.0036,  0.0026, -0.0143],\n",
      "        [-0.0215,  0.0172,  0.0096,  ..., -0.0003, -0.0158, -0.0254],\n",
      "        [ 0.0066, -0.0003,  0.0066,  ..., -0.0216,  0.0079, -0.0152],\n",
      "        ...,\n",
      "        [-0.0032, -0.0004, -0.0014,  ..., -0.0148, -0.0027, -0.0076],\n",
      "        [ 0.0229,  0.0121,  0.0071,  ...,  0.0209, -0.0315,  0.0210],\n",
      "        [ 0.0067, -0.0063,  0.0005,  ...,  0.0166, -0.0023,  0.0226]],\n",
      "       requires_grad=True))\n",
      "('blocks.37.mlp.fc2.bias', Parameter containing:\n",
      "tensor([-0.0178, -0.0434,  0.1063,  ...,  0.2585,  0.0510,  0.0335],\n",
      "       requires_grad=True))\n",
      "('blocks.38.norm1.weight', Parameter containing:\n",
      "tensor([2.2577, 1.9815, 2.1814,  ..., 1.9539, 2.1442, 2.3749],\n",
      "       requires_grad=True))\n",
      "('blocks.38.norm1.bias', Parameter containing:\n",
      "tensor([-0.0609,  0.1744, -0.2269,  ..., -0.6096,  0.1795, -0.1359],\n",
      "       requires_grad=True))\n",
      "('blocks.38.attn.q_bias', Parameter containing:\n",
      "tensor([-0.3386, -0.5323,  0.1113,  ..., -0.2187,  0.2750,  0.0470],\n",
      "       requires_grad=True))\n",
      "('blocks.38.attn.v_bias', Parameter containing:\n",
      "tensor([ 0.0169, -0.0360,  0.0246,  ..., -0.0575, -0.0297,  0.0247],\n",
      "       requires_grad=True))\n",
      "('blocks.38.attn.qkv.weight', Parameter containing:\n",
      "tensor([[ 4.4077e-03, -4.7387e-02,  5.1385e-03,  ...,  1.8001e-02,\n",
      "          1.2398e-02,  1.8792e-02],\n",
      "        [-2.7860e-03,  2.5216e-03, -7.3193e-04,  ...,  4.7048e-04,\n",
      "         -1.0124e-02, -2.9941e-02],\n",
      "        [-8.8384e-03, -4.2523e-02, -6.4178e-03,  ..., -1.5077e-02,\n",
      "          1.0285e-02, -2.0985e-02],\n",
      "        ...,\n",
      "        [ 8.6355e-03,  6.3190e-03, -5.1216e-03,  ..., -3.6052e-03,\n",
      "         -1.5089e-02,  1.7822e-02],\n",
      "        [ 2.4703e-03, -2.3564e-02,  1.2348e-02,  ..., -4.1781e-02,\n",
      "          7.7443e-03, -4.9460e-03],\n",
      "        [ 9.7991e-03, -6.9588e-03, -1.1422e-02,  ..., -3.5252e-05,\n",
      "         -1.1410e-02, -1.7941e-04]], requires_grad=True))\n",
      "('blocks.38.attn.proj.weight', Parameter containing:\n",
      "tensor([[-0.0117, -0.0164,  0.0079,  ..., -0.0114, -0.0133, -0.0194],\n",
      "        [-0.0171, -0.0046, -0.0101,  ..., -0.0181, -0.0246, -0.0151],\n",
      "        [-0.0226,  0.0198, -0.0088,  ...,  0.0036,  0.0110,  0.0086],\n",
      "        ...,\n",
      "        [ 0.0006,  0.0220, -0.0193,  ..., -0.0007, -0.0021, -0.0093],\n",
      "        [-0.0197, -0.0253, -0.0049,  ...,  0.0236,  0.0172, -0.0517],\n",
      "        [-0.0383,  0.0081, -0.0024,  ..., -0.0037,  0.0151, -0.0021]],\n",
      "       requires_grad=True))\n",
      "('blocks.38.attn.proj.bias', Parameter containing:\n",
      "tensor([ 0.1253,  0.2436, -0.1629,  ..., -0.0924, -0.0772,  0.0637],\n",
      "       requires_grad=True))\n",
      "('blocks.38.norm2.weight', Parameter containing:\n",
      "tensor([2.9410, 2.5896, 2.8302,  ..., 2.6686, 2.7927, 2.9041],\n",
      "       requires_grad=True))\n",
      "('blocks.38.norm2.bias', Parameter containing:\n",
      "tensor([-0.1381,  0.0015,  0.3710,  ..., -0.5602,  0.5995, -0.0519],\n",
      "       requires_grad=True))\n",
      "('blocks.38.mlp.fc1.weight', Parameter containing:\n",
      "tensor([[ 2.2528e-02, -2.1211e-02, -1.2201e-02,  ..., -7.0952e-03,\n",
      "         -1.5147e-02, -8.6836e-03],\n",
      "        [ 1.0404e-02, -1.1792e-02, -1.9931e-02,  ..., -2.4126e-02,\n",
      "          1.7221e-03,  2.7975e-02],\n",
      "        [-1.8535e-03,  2.9390e-02, -2.1572e-02,  ..., -1.0985e-02,\n",
      "         -5.1603e-03,  1.1055e-02],\n",
      "        ...,\n",
      "        [-6.7960e-03,  2.4848e-02, -6.1104e-03,  ...,  9.5520e-03,\n",
      "          1.4647e-02, -1.1318e-02],\n",
      "        [-4.9892e-03, -6.0042e-03, -1.2189e-02,  ..., -1.4073e-02,\n",
      "          8.8847e-03,  3.9649e-03],\n",
      "        [ 4.8818e-05,  1.2457e-02, -1.3860e-02,  ...,  1.1948e-03,\n",
      "         -1.2676e-02,  2.3184e-02]], requires_grad=True))\n",
      "('blocks.38.mlp.fc1.bias', Parameter containing:\n",
      "tensor([-0.3894, -0.2158, -0.2476,  ..., -0.2076, -0.2321, -0.2466],\n",
      "       requires_grad=True))\n",
      "('blocks.38.mlp.fc2.weight', Parameter containing:\n",
      "tensor([[-0.0293, -0.0054, -0.0141,  ...,  0.0226,  0.0061,  0.0071],\n",
      "        [ 0.0080,  0.0105, -0.0101,  ...,  0.0270, -0.0121,  0.0151],\n",
      "        [ 0.0292, -0.0114, -0.0133,  ...,  0.0255,  0.0052, -0.0203],\n",
      "        ...,\n",
      "        [-0.0135, -0.0196,  0.0047,  ...,  0.0010,  0.0261, -0.0055],\n",
      "        [ 0.0291,  0.0067, -0.0296,  ...,  0.0102,  0.0405,  0.0101],\n",
      "        [ 0.0105,  0.0285, -0.0111,  ...,  0.0100,  0.0223, -0.0031]],\n",
      "       requires_grad=True))\n",
      "('blocks.38.mlp.fc2.bias', Parameter containing:\n",
      "tensor([ 0.0110, -0.0857,  0.1834,  ...,  0.2448,  0.0873,  0.0033],\n",
      "       requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for param in model.visual_encoder.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# arg --> list of blocks to quantize for ViT/Q-Former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_bits = 8\n",
    "activation_bits = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NBitLinearDynamic(in_features=768, out_features=256, bias=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from layers.nbitlineardynamic import *\n",
    "Q_layer = NBitLinearDynamic(model.vision_proj.in_features, \n",
    "                            model.vision_proj.out_features, \n",
    "                            bias=True,\n",
    "                            weight_bits = 8,\n",
    "                            activation_bits = 32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Q_layer.weight.copy_(model.vision_proj.weight)\n",
    "    Q_layer.bias.copy_(model.vision_proj.bias)\n",
    "    \n",
    "\n",
    "Q_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vision_proj = Q_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NBitLinearDynamic(in_features=768, out_features=256, bias=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vision_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2Qformer(\n",
       "  (visual_encoder): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0-38): 39 x Block(\n",
       "        (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "  (Qformer): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30523, 768)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vision_proj): NBitLinearDynamic(in_features=768, out_features=256, bias=True)\n",
       "  (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Blip2Qformer(\n",
       "   (visual_encoder): VisionTransformer(\n",
       "     (patch_embed): PatchEmbed(\n",
       "       (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "     )\n",
       "     (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "     (blocks): ModuleList(\n",
       "       (0-38): 39 x Block(\n",
       "         (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "         (attn): Attention(\n",
       "           (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "           (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "           (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (drop_path): Identity()\n",
       "         (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "         (mlp): Mlp(\n",
       "           (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (ln_vision): LayerNorm((1408,), eps=1e-05, elementwise_affine=True)\n",
       "   (Qformer): BertLMHeadModel(\n",
       "     (bert): BertModel(\n",
       "       (embeddings): BertEmbeddings(\n",
       "         (word_embeddings): Embedding(30523, 768)\n",
       "         (position_embeddings): Embedding(512, 768)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (encoder): BertEncoder(\n",
       "         (layer): ModuleList(\n",
       "           (0): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (crossattention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (1): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (2): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (crossattention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (3): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (4): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (crossattention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (5): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (6): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (crossattention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (7): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (8): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (crossattention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (9): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (10): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (crossattention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (11): BertLayer(\n",
       "             (attention): BertAttention(\n",
       "               (self): BertSelfAttention(\n",
       "                 (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "               (output): BertSelfOutput(\n",
       "                 (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                 (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (intermediate): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (intermediate_query): BertIntermediate(\n",
       "               (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output_query): BertOutput(\n",
       "               (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (cls): BertOnlyMLMHead(\n",
       "       (predictions): BertLMPredictionHead(\n",
       "         (transform): BertPredictionHeadTransform(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (transform_act_fn): GELUActivation()\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         )\n",
       "         (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (vision_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "   (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "   (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
       " ),\n",
       " VisionTransformer(\n",
       "   (patch_embed): PatchEmbed(\n",
       "     (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "   )\n",
       "   (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "   (blocks): ModuleList(\n",
       "     (0-38): 39 x Block(\n",
       "       (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "       (attn): Attention(\n",
       "         (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "         (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "         (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "       (mlp): Mlp(\n",
       "         (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " PatchEmbed(\n",
       "   (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       " ),\n",
       " Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14)),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " ModuleList(\n",
       "   (0-38): 39 x Block(\n",
       "     (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "     (attn): Attention(\n",
       "       (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "       (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "       (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (drop_path): Identity()\n",
       "     (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "     (mlp): Mlp(\n",
       "       (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Block(\n",
       "   (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (attn): Attention(\n",
       "     (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "     (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "     (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "   (mlp): Mlp(\n",
       "     (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Attention(\n",
       "   (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "   (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "   (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=4224, bias=False),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Linear(in_features=1408, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " Identity(),\n",
       " LayerNorm((1408,), eps=1e-06, elementwise_affine=True),\n",
       " Mlp(\n",
       "   (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " Linear(in_features=1408, out_features=6144, bias=True),\n",
       " GELU(approximate='none'),\n",
       " Linear(in_features=6144, out_features=1408, bias=True),\n",
       " Dropout(p=0.0, inplace=False),\n",
       " LayerNorm((1408,), eps=1e-05, elementwise_affine=True),\n",
       " BertLMHeadModel(\n",
       "   (bert): BertModel(\n",
       "     (embeddings): BertEmbeddings(\n",
       "       (word_embeddings): Embedding(30523, 768)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): BertEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (crossattention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (2): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (crossattention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (3): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (4): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (crossattention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (5): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (6): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (crossattention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (7): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (8): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (crossattention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (9): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (10): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (crossattention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (11): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (intermediate_query): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output_query): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (cls): BertOnlyMLMHead(\n",
       "     (predictions): BertLMPredictionHead(\n",
       "       (transform): BertPredictionHeadTransform(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (transform_act_fn): GELUActivation()\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       )\n",
       "       (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " BertModel(\n",
       "   (embeddings): BertEmbeddings(\n",
       "     (word_embeddings): Embedding(30523, 768)\n",
       "     (position_embeddings): Embedding(512, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (encoder): BertEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (crossattention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (2): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (crossattention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (3): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (4): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (crossattention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (5): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (6): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (crossattention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (7): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (8): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (crossattention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (9): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (10): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (crossattention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (11): BertLayer(\n",
       "         (attention): BertAttention(\n",
       "           (self): BertSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): BertSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (intermediate_query): BertIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output_query): BertOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " BertEmbeddings(\n",
       "   (word_embeddings): Embedding(30523, 768)\n",
       "   (position_embeddings): Embedding(512, 768)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Embedding(30523, 768),\n",
       " Embedding(512, 768),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertEncoder(\n",
       "   (layer): ModuleList(\n",
       "     (0): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (crossattention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (2): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (crossattention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (3): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (4): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (crossattention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (5): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (6): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (crossattention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (7): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (8): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (crossattention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (9): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (10): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (crossattention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (11): BertLayer(\n",
       "       (attention): BertAttention(\n",
       "         (self): BertSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): BertSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (intermediate_query): BertIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output_query): BertOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " ModuleList(\n",
       "   (0): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (crossattention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (1): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (2): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (crossattention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (3): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (4): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (crossattention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (5): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (6): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (crossattention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (7): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (8): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (crossattention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (9): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (10): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (crossattention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (11): BertLayer(\n",
       "     (attention): BertAttention(\n",
       "       (self): BertSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): BertSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (intermediate_query): BertIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output_query): BertOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (crossattention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (crossattention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (crossattention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (crossattention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (crossattention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (crossattention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Linear(in_features=1408, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertLayer(\n",
       "   (attention): BertAttention(\n",
       "     (self): BertSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): BertSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (intermediate_query): BertIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output_query): BertOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertAttention(\n",
       "   (self): BertSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): BertSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " BertSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " Linear(in_features=768, out_features=3072, bias=True),\n",
       " GELUActivation(),\n",
       " BertOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " Linear(in_features=3072, out_features=768, bias=True),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Dropout(p=0.1, inplace=False),\n",
       " BertOnlyMLMHead(\n",
       "   (predictions): BertLMPredictionHead(\n",
       "     (transform): BertPredictionHeadTransform(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (transform_act_fn): GELUActivation()\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     )\n",
       "     (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       "   )\n",
       " ),\n",
       " BertLMPredictionHead(\n",
       "   (transform): BertPredictionHeadTransform(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (transform_act_fn): GELUActivation()\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   )\n",
       "   (decoder): Linear(in_features=768, out_features=30523, bias=True)\n",
       " ),\n",
       " BertPredictionHeadTransform(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (transform_act_fn): GELUActivation()\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       " ),\n",
       " Linear(in_features=768, out_features=768, bias=True),\n",
       " GELUActivation(),\n",
       " LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " Linear(in_features=768, out_features=30523, bias=True),\n",
       " Linear(in_features=768, out_features=256, bias=True),\n",
       " Linear(in_features=768, out_features=256, bias=True),\n",
       " Linear(in_features=768, out_features=2, bias=True)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[module for module in model.modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-38): 39 x Block(\n",
       "      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual_encoder"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
